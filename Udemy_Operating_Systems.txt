=============================================================
=	2.	Operating Systems from scratch - Part 1 (8+ Hours)	=
=============================================================

	12.	Types of scheduler, Context switching
	-----------------------------------------


Context of a process
--------------------
The Process Control Block (PCB) and attributes of a process is collectively called as Context.

Process Control Block (PCB) - Each Process is represented in the Operating System by a PROCESS CONTROL BLOCK
							  (PCB) - also called a TASK CONTROL BLOCK.



Process Control Block (Neso Academy)
------------------------------------
https://www.youtube.com/watch?v=4s2MKuVYKV8
or
https://www.youtube.com/watch?v=4s2MKuVYKV8&list=PLBlnK6fEyqRiVhbXDGLXDk_OQAeuVcp2O&index=18

 -------------------------------
|	Process State				|
|-------------------------------|
|	Process Number				|	Also called as Process ID
|-------------------------------|
|	Program Counter				|
|-------------------------------|
|	CPU Registers				|
|-------------------------------|
|	Memory limits				|
|-------------------------------|
| List of open files			|
|-------------------------------|
| CPU Scheduling information	|
|-------------------------------|
| Memory Management information	|
|-------------------------------|
| Accounting information		|
|-------------------------------|
| I/O Status Information		|
|-------------------------------|
|			........			|
 -------------------------------

Process Attributes:
-------------------
1.	Process Id
2.	Program Counter
3.	Process State
4.	General Purpose Registers
5.	Priority
6.	List of Open Files
7.	List of Open devices
8.	Protection


Operating System Code
---------------------

Long Term Scheduler:
	Move 50 out of 500 Programs from Hard Disk -> RAM

Short Term Scheduler:
	Move Processes from RAM -> CPU

Medium Term Scheduler:
	If RAM is full.
		Move High Priority process from Hard Disk to RAM.
		Move Low Priority process from RAM to Hard Disk.
	
	Swapping
	|
	|--> Swap In
	|--> Swap Out

		OS Code will be in RAM.


	13.	Various times of a process
	------------------------------
	
Point in time	 ->		Arrival time , Completion time
Duration in time ->		Burst Time , Turn around Time , Waiting Time , Response Time

Various times related to a process:
-----------------------------------
1.	Arrival Time
2.	Burst Time (also called Execution time)
3.	Completion time
4.	Turn-around time
5.	Waiting time
6.	Response time
7.	I/O time





	6.	How Input and Output devices work together
	----------------------------------------------

I/O Devices:
============

   CPU			RAM
 -------	 -----------  ---
|		|	|	OS	 	|	 | OS Space
|		|	|  CODE	 	|	 |
 -------	|-----------| ---  ---
			|Calculator	|	 	  |
			|-----------|		  |
			|	010		|		  |
			|-----------|		  |
			|	011	 	|		  |	User
			|-----------|		  |	Space
			|	101	 	|		  |
			|-----------|		  |
			|		 	|		  |
			|-----------|		  |
			|	P4	 	|		  |
			 -----------	   ---

Calculator
 -----------
|			|
|-----------|
|			|
|			|
|			|
 -----------

2 + 3 = 5
010 + 011 = 101


Input Device:
	Keyboard
	
Output device:
	Monitor
	
Both Input Device and Output Device:
	Hard Disk


A program once it is loaded from Hard Disk to RAM, it can undergo either Waiting for some duration of time
or it should have been Executed for some duration of time. or this program should have been undergoing I/O
for some duration of time. In what order this happens is really dependent on the program.
The ordering will be different from one program to another.

For each program / process
	Turn Around Time = Waiting Time + Burst Time + I/O Time
	Turn Around Time = Completion Time - Arrival Time
	


	7.	Program vs Process, States of a process
	-------------------------------------------

	Source Program
		||
		\/
	 --------
	|Compiler|
	 --------
		||
		\/
	Machine Code (Also called as .exe code)	





   CPU			RAM					Hard Disk
 -------	 -----------  	 -------------------
|		|	|	OS	 	|	|					|
|		|	|  CODE	 	|	|	GoogleChrome.exe|
 -------	|-----------| 	|	(Process)		|
			|Calculator	|	|					|
			|-----------|	|	GoogleChrome.exe|
			|	010		|	|	(Process)		|
			|-----------|	|					|
			|	011	 	|	|	GoogleChrome.exe|
			|-----------|	|	(Program)		|
			|	101	 	|	|					|
			|-----------|	|	MSWord.exe		|
			|		 	|	|					|
			|-----------|	|					|
			|	P4	 	|	|					|
			 -----------	 -------------------
	
GoogleChrome.exe Program is saved in Hard Disk.
Once you open it can create one or more GoogleChrome.exe processes which are still saved in Hard Disk.
In some point in time GoogleChrome.exe process is moved in to RAM and can be in any state.

For example: The company Google has developed a software through a program..
That is what we mean by a program. And that is available in .exe format in our hard disk.
Now whenever this program has been executed, or this program has been opened by my computer.
A new copy of this program will be created and this is what we mean by a process.
See, We can open Google Chrome in multiple Tabs/Windows. Right.?
For example: I can open 2 google chrome Windows at the same time. Right?
Now what will happen is.. For this program two instances of Google Chrome's program will be created inside the hard disk.

In above diagram one GoogleChrome.exe (Program) and two GoogleChrome.exe (Process) is created.

For a Single GoogleChrome.exe Program, Multiple GoogleChrome.exe process can be created.

This two Programs/Process will be moved into the RAM and then it will execute, it will undergo I/O.

.
.
In most of the Text books, Program and Process are used interchangeably.
.
.

States of a Process
-------------------
1.	New state
2.	Ready state
3.	Running state
4.	I/O state
5.	Terminated state
6.	Suspend Ready state
7.	Suspend wait state
.
.
Once the process reaches Terminated state. We will remove the process from the RAM completely. Fine!


	8.	Degree of Multiprogramming
	------------------------------

		For this example, And Let us assume that, it needn't be always true.
		But just for this example.. Let us assume that, all processes will have the same size. 

		Size of RAM = 4GB
		Size of a Single Process = 4 KB
		Most of the time size of all processes = 4 KB
		Maximum number of processes that can be placed in RAM = Size of RAM / Size of a Single Process = 2 pow 32 / 2 pow 12
			= 2 pow 20 process

1 Byte = 8 bits.
1 KB = 2 pow 10 Bytes
1 MB = 2 pow 20 Bytes
1 GB = 2 pow 30 Bytes
1 TB = 2 pow 40 Bytes


		CPU Efficiency = Useful time of CPU / Total time of CPU

	9.	Types of Operating Systems
	------------------------------

		1.	Batch OS
			RAM will take only one process at a time, after completion it will pick other.
		2.	Multiprogramming OS
			One CPU One Core will have multiple processes.
			Concurrent Processing
		3.	Multiprocessing OS
			More than One CPU or One CPU with Multiple Cores
			Parallel Processing 


		Parallel Processing (More Cost) will be faster than Concurrent Processing (Less Cost).

		All Our Computers are Multi Processing Operating Systems.
			Octa Core Processor (8 Processor which are placed in our Computer)
			/Quad Core Processor (4 Processors which are placed in our Computer)


	10.	An Important point to note
	------------------------------
		
		Among these three OS's.. Throughout this course we will be using only one OS.
		And that is nothing but Multiprogramming OS.. Which means there is only one CPU inside our computer.
		And our RAM can have more than one process at a time.


	11.	Process Control block, Attributes of a process
	--------------------------------------------------
	
Program is also called Passive Entity
Process is also called Active Entity

A process will not only contain program but it will also have Stack, Heap, Datapart.

 ___________________
|					|
|		Stack		|
|		 ||	   		|
|		 \/			|
|-------------------|
|		 /\			|
|		 ||			|
|		Heap		|
|___________________|
| 					|
| Static Variables  | (Also called as Data Part)
| Global Variables  |
|___________________|
|					|
|		Program		| (Also called as Code Part)
|___________________|


All function calls and its local variables are stored in Stack.
 ___________________________
|			f3()			|
|							|
|	f3 function call		|
|	and its local variables	|
|___________________________|
|			f2()			|
|							|
|	f2 function call		|
|	and its local variables	|
|___________________________|
|			f1()			|
|							|
|	f1 function call		|
|	and its local variables	|
|___________________________|


A Variable which is defined within a function is called a Local Variable.
Now for local variables, the space will be allocated within the Stack.
All function calls will be stored within the Stack.

Program is full of functions.


Now there is no fixed space for Stack or Heap.
Which means, some programs may need more space for Stack.
Which means, It might have a lot of function calls. Where as some function calls may need more space for Heap
Which means, those programs will have more dynamic memory allocation.
So they are actually dynamic.. Which means, the Heap will be growing upwards.
Whereas Stack will be growing downwards.

Some programs may need more space for Stack.
Some programs may need more space for Heap.


Dynamic Memory Allocation
-------------------------
In C Programming , we use 2 function calls.
 malloc()
 calloc()
This functions are used to dynamically allocate memory.
Allocating memory at Runtime.


For every process we have Process Control Block (PCB)
If we have 10 process, we have 10 Process Control Block (PCB)
 


Process Attributes:
-------------------
1.	Process Id
2.	Program Counter
3.	Process State
4.	General Purpose Registers
5.	Priority
6.	List of Open Files
7.	List of Open devices
8.	Protection



















	54.	Basics of Memory Allocation
	===============================

Size of one register = one word
Entire Memory (RAM) is divided in to Words
With in a word 
	we can place instruction
	or we can place data
	
In computer memory we store only 2 things either in RAM, Registers or Hard Disk.
	1.	Instruction
	2.	Data (It can be a number, letter, sentence, image, audio file, video file)
	
	Everything is stored as 1's and 0's.
	
	Program is a collection of instructions.
	
	Instruction is nothing but a part of the program/Line of a program with a little difference.
	
	Some computers use two words to represent the instruction.
	Some computers use three words to represent the instruction.
	
	But as of now lets assume that for every word its exactly one instruction.
	Most of the text books follow this convention.
	
	We assume that, every word of a computers memory will have exactly one instruction.
	
	Some computers use 1 word = 4 bytes, Some computers use 1 word = 8 bytes. Its always power of 2.
	Size of RAM = Size of Single Word = Size of Hard Disk = Size of Register = Power of 2
	
	2 pow m words = m bits
	
	CPU always ask for a word, it never asks for program or data or instruction.
	CPU never asks for a program or data or instruction or what ever it is.
		




	Computer Organization Architecture
		Address Bus , Data Bus
	
	Bus is a collection of wires.
	Our registers of CPU will be connected to RAM through a set of 3 wires.
	You can think of it like a set of 2 wires.

	One wire is used for sending address. Called as Address bus.
	Address bus is a collection of wires.. through which our CPU will be able to send the
	address to the registers.

	Similarly we have something called Data bus.
	Data bus is again a collection of wires. which are actually used in order to send data from RAM to CPUs
	So using this bus our CPU is able to communicate with the RAM and get the data.












=================================================================================
=	5.	Operating Systems Final Part (4): File Systems & Threads (10+ Hours)	=
=================================================================================




 ============================================================
||	Section 11 - Kernel, System calls, Modes of execution	||
 ============================================================









	49.	Difference between Kernel and Operating System
	--------------------------------------------------
	

   CPU			RAM
 -------	 --------  --
|		|	|		 |	 | OS Space		(System Process)	May be Kernel Space (Kernel Process)
|		|	|	OS	 |	 |
 -------	|------- | --	--
			|	P1	 |		  |
			|--------|		  |
			|		 |		  |
			|--------|		  |
			|	P2	 |		  |	User
			|--------|		  |	Space	(Application Process)
			|	P3	 |		  |
			|--------|		  |
			|		 |		  |
			|--------|		  |
			|	P4	 |		  |
			 --------		--


OPERATING SYSTEM KERNEL (Most frequently accessed OS code can be called as KERNEL which is maintained in RAM) --> is a part/subset of OPERATING SYSTEM.  

Let us consider the RAM of our computer, okay?
And it has lot of processes.
Also, it has a very important process which is nothing but operating systems. Right?

Our operating system is also one of the processes. In fact,
We also see it as system process. Whereas, these processes, we can say are application processes. OK?

Fine! Now, one important question I want to ask you is, See I have told that in 
the beginning addresses of the RAM, we will be maintaining the operating system. Right? 

In introduction to operating systems, we have seen this point.

Now, one question I want to ask you is, whether this is the complete code of our operating system 
or only a part of the operating system.
We have seen that our operating system is nothing but a code.
It is the large code and it will be having a lot of functions, right?
Now my question is, whether we are maintaining the complete operating system code over here,
or only a part of it? Whether we are maintaining the complete operating system code over here or
we will maintain only a part of it? Right?
That's my question.

So the answer is, in most of the implementation, see it can really vary depending on implementation,
but in most of the implementations we're using today we will never maintain the complete Operating System
program inside the RAM.
Always, right? See, if necessary we can maintain the complete code inside the RAM.
Right?
But in most of the cases, or I can tell that only a part of the operating system.
code will be always maintained in the RAM. Let us assume this part is maintained completely
inside the RAM. Whereas, the remaining part will be loaded into the RAM only if necessary, right? Only if necessary.

See, if you take the Operating System program there be a lot of functions, right?
For example, one of the functions is short term scheduler, one of the functions is long term scheduler,
one of the functions is memory management unit, one of the functions is filesystem.
Likewise, we have a lot of functions in the operating systems, right? Now, out of all the functions, only
a few functions will be frequently accessed by the CPU.
Right?

Will be frequently accessed by the CPU. Now, what I mean to say is, let us assume that we have
four processes inside the RAM, right? P1, P2, P3 and P4. Let
us assume, all these four processes are in ready state which means they are waiting to be picked by the
CPU for execution.

Right? Now, our CPU has four choices and
it doesn't know which process to execute next, right? In that case, whatever
CPU will do? Our CPU will take the short term scheduler function in the operating system and
then it will execute it, right? In case, if it executes the short term scheduler function of our
Operating System's code, it will be able to understand which process among these four should be picked
next, right?

Which means the logic to select one of the processes in the RAM will be present in that short term scheduler
function. Once the execution of short term scheduler functions over by the CPU, our CPU will
be able to decide which process to execute next.
Let us assume, it has decided that it needs to execute process P2, right?
Let us assume process P2's execution is completed, right? Once its execution
is completely done, obviously we will completely remove the process from the RAM, right?
Now, our CPU is again in a confusion or dilemma, whether it should pick
P1 or P3 or P4. Again it will execute the short term scheduling function and it will decide one of the
three processes.
Let us assume, it has decided P3, right? Now, once its execution is done it will again be in a dilemma,
right?

So again it will execute the short term scheduler and decide which process to execute next. See, why am
I saying all those points? One point you need to get from this is our CPU is accessing the short term scheduler
again and again. Whenever it has the confusion on which process to execute next, it is immediately accessing
the short term scheduler function, right? 

So our CPU is accessing the short term scheduler again and
again. So it is very important for us to maintain the short term scheduler function inside the RAM.
Right? Inside the RAM. Whereas, in case if we don't have short term scheduler function inside,
Our CPU might want to go to the hard disk every time when it wants the short term scheduler.
Right.

And that is going to take a lot of time. And that is going to waste a lot of time.

So whenever we switch on the computer short term scheduler will be loaded inside the RAM and that
function will be maintained in the RAM till we shut down the computer, right? Till we shut down the computer.
This is a very important point. Not just short term scheduler, whatever, functions we have seen so far in operating
systems,
those are the most important functions. See, if you take the operating system's code, there will
be millions of lines of code.
It is not a simple program.
There will be millions of lines for the operating system program.
And obviously we cannot see each and every function of operating system.
And so we don't do that
in our bachelor's degree.
OK?
What we do is,
we only study the most important functions of operating systems, long term scheduler, short term
scheduler, medium term scheduler,
file systems, then we have something like this disk scheduling algorithm.
Then we have a lot of functions in memory management.
We have a lot of functions.
These functions are very very important and those functions will be executed by the CPU very frequently.
OK?
So we maintain those set of functions which are very important inside the RAM.
Always! Right?

Which means once we switch off the computer those important functions will be loaded inside the RAM
and it will be inside the RAM till the computer is turned off, right? Till the computer is turned off.

Now, what about the other functions, right? Are there functions which will be least frequently accessed
by the CPU?
OK?
These functions will not be present in the RAM always but they will be loaded in case if necessary.
Let us assume, there is a function named F5.
Right? Function named F5 and it is not present in the RAM.
Now, in case if our CPU wants to execute this function we will load this function inside the RAM.

We will load this function inside the RAM. Over here in the beginning addresses of RAM.
Now, let's come to a very important question.
It is very very important actually.
It has been asked in a lot of interviews.



What do we mean by a kernel of operating systems?
See, many people generally get confused between OPERATING SYSTEMS and KERNEL.

Okay? They think that both of them are exactly the same.
The answer is No.
They are not exactly same.

Our KERNEL is nothing but a part of the operating system. Okay?
Our KERNEL is nothing but a part of the operating system.

This complete program is what we mean by operating systems.
Right? Now, this complete code is not the kernel.
Only a part of the operating systems program, we say it as kernel and this part is nothing but the most
important part of our operating system.

What do you mean by most important part of our operating system?
These functions are very very important for the functioning of our computer.
Or I can say that in case if I group the set of all the functions, which will be frequently accessed
by the CPU again and again. In case
If a group all of them together I can say it as the OS KERNEL or the OPERATING SYSTEM'S KERNEL.

Are you getting the point?
This is the complete operating system program out of which only a few functions are very important and
they will be always maintained in the RAM, right? And that set of functions is what we mean by the kernel
right?

In simple I can tell you that, out of the complete operating system's code we will be maintaining
the kernel inside the RAM, always. Whereas, the other functions will be loaded into the RAM only if
necessary, okay?

See, what are all the functions our kernel will have. A kernel will have something like memory management
unit, it will have file systems, it will have long term scheduler or short term scheduler, are all these
things.


And one more very very IMPORTANT FUNCTION which our kernel will have is DEVICE DRIVER,
Right?
See, If you take any hardware device in our computer it needs something called as DRIVER
SOFTWARE. Right? It needs something called as driver. Without driver software,
none of your computer bots will work. 

Let us assume that, you have opened
your mobile phone.
You have opened your mobile phone and your mobile phone will have some operating system, right?
Something like ANDROID OPERATING SYSTEM.

Now, let us assume, we have the camera symbol in your screen, right? Camera logo in your screen
Now, once you click this icon, immediately your will mobile phone's
camera is getting turned on, right? Now, how is it possible?
That is possible because of the driver software which is driving your camera inside your mobile phone.
Not just camera, you can take any hardware part you have in
your computer or mobile phone, it works only because of the DRIVER SOFTWARE. Right? 

You can take a Bluetooth headphone.
It is being connected to your computer because of the driver software, right? You can take any hardware part in your computer,
It works only because of a driver software. There will be a driver software for every hardware part in your computer.
Okay?
And all those driver functions will be present inside the kernel, right? It will be present inside the
kernel.

So I have told you that, there's a lot of functions inside the kernel, right? File systems, memory management then device drivers,
all these things.
OK? So where some functions are not frequently accessed by the CPU and those functions, we don't say it
as kernel, right? So I think you are getting the difference between OPERATING
SYSTEMS and KERNEL.

So what's the summary of this video? Though
our operating systems have millions of lines of program we will not be maintaining the complete program
inside the RAM, always. Rather we will be maintaining only the kernel of the operating system inside
the RAM, always.
Which means once we turn on the computer, our operating system's kernel will be loaded inside the RAM
and it will be removed from the RAM, only during the turn off phase.

Which means only if we
turn off the computer,
this part will be removed from the RAM.
Right?

Until then it will be present in the RAM and our operating system will also be having some other functions
apart from the kernel and these functions will be loaded into the RAM, only if
necessary. Fine!














	50.	System Calls, User Mode vs Kernel Mode
	------------------------------------------
	
 CPU			RAM				Monitor		
 -------	 -----------  	 ---------------
|		|	|	OS	 	|	|				|
|		|	|  KERNEL	|	|				|
 -------	|-----------| 	 ---------------
			|P1 scanf	|					
			|-----------|	 	Keyboard	
			|			|	 ---------------
			|			|	|				|
			|		 	|	|				|
			|-----------|	 ---------------
			|P2 a=2	 	|					
			|-----------|		Mouse		
			|		 	|	 ---------------
			|			|	|				|
			|		 	|	|				|
			 -----------	 ---------------
	
Fine.
Let's see this.

See I have taken 2 processes named P1
and P2 over here.
And you know how the PROCESS CONTROL BLOCK will look like.
Right?
Which means we will be having STACK,
Will be having HEAP. We will be having CODE SEGMENT where
the PROGRAM of this PROCESS will be present.

Also we will be having.
We will be having the DATA SEGMENT, right? Which means we will be having STATIC VARIABLES, GLOBAL
VARIABLES, all these things.
Right? Fine!

And also we will be having the set of files which can be opened by this process.
All these things. OK?
We have seen already.

What do we mean by PROCESS CONTROL BLOCK.
Now, one point I want to ask you here is, even this process will also have all of these things, right?

STACK, HEAP, CODE, DATA, all these things.

Now, tell me can this process access the Data or Code or whatever of P2 or
not, right? See, always remember this point.
Your process cannot access the PCB of another process directly. It will never be able to do it.

That's what we have seen as PROTECTION.
Right?
That's what we mean by PROTECTION.

And this is one of the most important functionality which is being provided by our operating system.
Right?
So in case if this process tries to access the contents of this process directly, our operating system
will not allow such an action.
Right?
If it tries to access it, it will not be able to do it.
Fine!

Now,
then how we it will happen? See, there will be some instances where a process might want to access
the data of some other process, right? There might come a scenario. I'll give you an example.

Okay? I'll give you a simple example.
See if you take the I/O devices we have in our computer, either monitor or a keyboard or mouse or printer
or whatever, all the devices will be having buffer associated with it.
Right? Buffer associated with it which means in case if I press a key in my keyboard then it's
then it's ASCII code.

I don't want to get into that.
Let us assume, I am typing A in my keyboard.
In that case, it's ASCII code will be moved to the buffer of keyboard.

And then this data will be picked by our CPU when needed, right?
This is how it generally happens.

Similarly, if you take any I/O device
it works with the help of a buffer, right? With the help of a buffer.

Now, what might happen is, let us assume this process P1 will be having a program.
Right? Inside the code segment.
Now, let us assume that, inside the code we have something called as scanf,
Right? Let us assume, it is a C program, right?
You know what is meant by scanf in C program? Right?
See, scanf will get the input from the user when executing, right?
So in case, if I use scanf, then we will be getting the input from the user and the user will be giving
the input using the keyboard. Right?
Using the keyboard.

Now, let us assume I am giving a value something like 3 as the input, right? Now in case if I type 3,
that value will be placed in the buffer of keyboard.
Fine?

Now, what should happen is, in order to continue the execution of this process, it needs to take this data
in the buffer of keyboard.

See, I have already told you that, your process, apart from its process control block, it cannot access other
data directly. Right? It will never be able to do it.

Now this process needs to access this data.
How will it do? Right?
How will it do?

See this is one of the instances.
Similarly, your process might want to take that data or might want to write the data into the
monitor's buffer so that it can be displayed, right? Similarly, it
might want to take the data from the mouse, right? All these things can happen.
Also, there might arise a situation where your process might be trying to access the data of some
other process. Right?

Let us assume that, there is a variable named as a equal to two in this process, right?
Even this data might want to be accessed by this process.
Right?
There might come a situation like that. In that case,
What will this process do?
Right?

One thing is that this process will not be able to access the data
apart from its process control block. See, in case if a process wants to access the data within the process
control block, it will be obviously be able to do it. Fine!

But if it wants to access other parts outside of its PCB, how will it be able to do? Right?
That's what we're going to see in this video.

See for that it should contact the operating system.
Right? It should contact the operating system.
See, I'll give you a simple example, right? Now, what this process needs to do is, it needs to get this data, right?
So what it will be doing is, it will be contacting the operating system. Contacting the operating system
Now, what our operating system will do is, it will move this data from the keyboard into this process.
Right? Into its process control block so that this process will be able to continue execution further.

Right? Will be able to continue execution further. Fine! Now, how this will happen? Right? How this will
happen?
So what that process will do is, in case if it wants to access the data of some other process.

See, one thing is that this data belongs to this process.
Similarly, there will be lots of data inside this process and it belongs to this process.
Also, the I/O devices which we have in the computer will be having buffer and those buffers will be
having some data, might have some data, right?

And all those thing belongs to the operating system.
Right? operating system is also a process, right?
So all these things are belonging to the process operating system.

Now, this process is trying to access the contents of another process.

Either the CONTENTS OF OPERATING SYSTEM PROCESS or THE CONTENTS OF SOME OTHER USER PROCESS like P2,
right? Now,
How will this happen?

For that it will be contacting the operating system.
Now, how will it do?

By using something called as SYSTEM CALLS, right? By using something called as SYSTEM CALLS. 
SYSTEM CALL is a SPECIAL TYPE of FUNCTION CALL, right? It is a SPECIAL TYPE of FUNCTION CALL.
What do you mean by this is. See, You know how our operating system will look like, right?
It is a big code, fine? And it will be having lots of functions. Right?
It will be having a lot of functions.
Now, in order to fetch the data of keyboard, there will be a function inside the operating system.
Similarly, in order to fetch the data of the buffer of mouse, there will be a separate function which should
have been written specifically for the mouse, right?
Similarly, for any I/O device there will be a function, right? Also, in order to transfer data
between user processes,
Again, we will be using a specific function inside the operating system.
Right?


And that function will be able to transfer the data. So what we will be doing is, this function,
this user process, since it wants to get the data off the buffer of keyboard, it will be making a system
call using which we will be contacting our function of operating system.
Right?
See, it is just like a function call.
Let's assume, the function f1 has been written specifically for keyboard.
Right? Now, what will happen is, this process will be calling F1, right?
This is
what we mean by SYSTEM CALL. See, why do.

I say that SYSTEM CALL is a SPECIAL TYPE OF FUNCTION CALL.
It is very simple.
OK?

Let us assume, I have a C program something like this, right? I have a C program and some lines of code
and I'm calling function F2 inside function F1, right? Let us assume
F2 is also present here.
Right? F2 is also present here. See, now what has happened is, F1 is calling function F2.
This is nothing but a FUNCTION CALL.
This is nothing but a FUNCTION CALL but we cannot say this is a SYSTEM CALL,
assuming that this is also one of the USER PROCESSES.

Or you can think of it like, both the functions are present in the same
program. Right? 
BOTH THE FUNCTIONS ARE PRESENT IN THE SAME PROGRAM AND THIS PROGRAM IS A USER PROGRAM.
Right? It is a USER PROGRAM.

So what's happening is, we are making a function call and this function call is actually calling
a user process, right.?
So we cannot say this function as a system call.
We cannot say that, right? 

But here what's happening is, we are calling the function.
This process is calling a function using a function call and this function call
is actually calling the function inside operating systems, right? Now, it is calling a function inside
the operating system.
So since we are calling a function inside the operating system, we can say this function call as a SYSTEM
CALL, right?
We can say this FUNCTION CALL as a SYSTEM CALL.

See, you can think it something like this.
Let us assume, this is set of all
Function calls, right?
This is a complete set up of all function calls.

Now, there will be a lot of functions inside it.
Right?
There will be a lot of functions inside it.
Now,
Out of all these function calls there'll be SOME FUNCTIONS which will be SYSTEM CALLS. Right?

There'll be some functions which will be system calls. Which functions? Only those function calls which
are calling the functions of operating systems.
Okay? We can say such functions as system calls.
OK?
So that's why I told you that, SYSTEM
CALL is a type of FUNCTION CALL.
Right? It is a SPECIAL TYPE of FUNCTION CALL. I think you're getting the point.

It is one of the mostly asked to question in interviews.

Okay? The difference between SYSTEM CALL and FUNCTION CALL. See, analyze this point SYSTEM CALL is a type
of FUNCTION CALL.
Okay? But FUNCTION CALL is not a type of SYSTEM CALL.

I think you are getting the point. Function call is not a type of system call. Now, what has happened here
is, this process
P1 was being executed by the CPU, fine? Now, while execution it had an instruction something like
scanf.
Fine?
So it needs to get the input from the keyboard.
So what this process will do is,
This process will make a system call. Right?
Now, once we make the system call, this fuction
F1 of
Operating systems will execute. Right? This fucntion
F1 of operating system will
execute.

Now,
Because of the execution of this function inside the operating system,
this data will move to the process.
Right? This data will move to the process.

Now,
Once it is done,
What will happen is, after executing this complete function we will again return back to this process.
Right? Now, we can continue the execution because we have the data.
We have the data.
This is how it generally happens, right?
So one thing you need to get from this video is, your process can access its PCB at any
time. Right? It doesn't need to contact the operating system.

You can access it directly. In case if it tries to ACCESS ANY DATA or CONTENTS OF SOME OTHER PROCESS
it can be ANOTHER USER PROCESS or it
can be there BUFFERS of I/O DEVICES which are MAINTAINED by OPERATING SYSTEM. 

It can be
anything. In case if it wants to access anything outside its PCB, it needs to contact the operating system
right?

THE ONLY WAY OF CONTACTING THE OPERATING SYSTEM FOR THE USER PROCESS, IS THROUGH SYSTEM CALL.

See, what you mean by USER PROCESS? USER PROCESS is the APPLICATION PROGRAM which
we write. You can think of it like a C program or a JAVA program we write. Or you can think of it like an
application program, something like Microsoft Word, Photoshop, power point. All these are programs, right?
And all these programs we can say them as USER PROCESSES 

Whereas, we can say our OPERATING SYSTEM PROGRAM as SYSTEM PROCESS, okay? These are user processes. Whereas, this
is a system process, right? Fine! This is fine. Now, one important point I want to tell

you is,
Our computers can execute a program in 2 modes, right?




There are two modes in which a program can be executed. It can be either in USER MODE,
or it can be in KERNEL MODE, right? It can be in USER MODE or KERNEL MODE. See, KERNEL MODE is also called as SYSTEM MODE.
Some people even say it as PRIVILEGED MODE, right? KERNEL MODE or SYSTEM MODE or PRIVILEGED MODE.


KERNEL MODE, SYSTEM MODE, PRIVILEGED MODE


Anything is fine.
Now, what I meant to say is, see, our CPU can execute only one program at any given time. (MULTI PROGRAMMING)
Right? Our CPU can execute a SINGLE PROGRAM at any given time.

And that program can be executed either in USER MODE, or in KERNEL MODE, right? Now, what
the difference between both the modes?

It is very simple. In case if I'm executing a program in user mode. See,
what will happen is, we will be having a register in the CPU.
Right?
It is also called as MODEBIT.
Right?
It is also called as MODEBIT. We will be maintaining a single bit and this bit can be either 0 or it can be 1, right? 

Now, what will happen is, in case its value 0 it will be working
in one mode, right? Whereas, in case if its value is one it will be working in other mode, right?
This is how it happens.
Fine! Now, our CPU can execute a program at any given time, either in USER MODE or KERNEL MODE.


Right? Now, what's the difference between USER MODE and KERNEL MODE? See,

1.
	In case, if our CPU is executing a process using KERNEL MODE then that program can access
	any HARDWARE DEVICE, right? It can access any HARDWARE DEVICE. 

	Also, it can access any process as PCB, right?
	Always remember this point. Right? Let us assume, CPU is executing a program at
	this point of time and it is executing in KERNEL MODE, right?

	If that is the case, then during execution it can access other process as PCB. It can definitely do that.
	Also, it can access all the I/O devices. It can access any hardware device it wants. Right? It will be able to
	do it. Fine! 

2.
	Now, in case if I say that the program is executing in USER MODE, what it means is that
	program can only access the PCB of itself.
	Let us assume, our CPU executing process P2 in USER MODE, right?
	If that is the case then while execution I can only access the PCB of process P2.
	I will never be able to access the PCB of SOME OTHER PROCESS or any HARDWARE DEVICE, right? 

	It will never be able to do it. See in case if it wants to access the contents of other process
	or some I/O device, what will it do? It will make a SYSTEM CALL, right? It will make a SYSTEM CALL. Fine!

I think you should be getting a doubt right now. Anyway! I will explain you, okay? So a program can be


executed in 2 MODES, either in USER MODE or KERNEL MODE.


Fine?


1.	Now, one important point I want to tell you here is, always remember that in USER MODE, we will

	only be executing the USER PROGRAM, right? We will be only executing the USER PROGRAM. 

2.	Whereas, in KERNEL MODE we will be only EXECUTING THE KERNEL of our OPERATING SYSTEM. Right?

That is a very important point.

OK?

In KERNEL MODE
we will be only executing. See, what is meant by KERNEL? KERNEL is nothing but a part of our
operating system code, right? Part of our operating system code.

Now,

In KERNEL MODE, we will be one executing the KERNEL. Whereas, in USER MODE, we will be executing only USER

PROGRAMS, right? We will be executing only USER PROGRAMS.



So why are we doing this?
SEE, WHY CAN'T WE EXECUTE A USER PROGRAM IN KERNEL MODE, RIGHT?

Why can't we do that?


See, the problem here is THERE MIGHT BE SOME ERROR IN OUR USER PROGRAM, right?

Obviously, if you take any software, where the developers are developing, obviously they can have some
errors, right?
And what might happen is, because of those errors our COMPLETE COMPUTER MIGHT CRASH.
Or I can also say that our SYSTEM WOULD MOVE to HALT MODE. Right?
If that is the case, then we are in some serious trouble.

Our computer will completely halt.
That's the problem.

OK?

So exactly for that reason what they have told is, see, in KERNEL MODE we can access any hardware device,
any process's data, right? So In case we are executing in KERNEL MODE, since we can access any of the
devices,
always remember that we will be only accessing the KERNEL OF OUR OPERATING SYSTEM.

Whereas, in USER MODE you can execute any program.

Why?
Because even if this program is having some errors, it will only destroy this program. Right?
It will not destroy other program or any hardware device. Right?

(LIKE JAVA PROCESS OR JVM PROCESS during OutOfMemoryException)
(NOT SURE WHETHER HIGH CPU USAGE OF A JAVA/JVM PROCESS WILL KILL THE JAVA/JVM PROCESS)

Because in USER MODE we can only access its one PCB.
Now, in case if this program is having some errors, obviously it will only spoil this program.
It cannot access other processes or other hardware devices, right?
That's the advantage we get.

So in USER MODE we will be only EXECUTING USER PROCESSES. Whereas, in KERNEL MODE
we will be executing the KERNEL of our OPERATING SYSTEM. Right? KERNEL of our OPERATING SYSTEM.

Fine!

This is fine.






Now, how this will happen?

Let me give you a summary. Okay?

Let us assume, we are executing process P1, right? Obviously user processes will only be
executing in user mode, fine?
So we are executing process P1 in user mode.
Right? Now, let us assume that suddenly this process needs to get the data of keyboard, right? Or it wants to
get the data of some other process.
Now what will happen? Now,
what will happen is, this process will be making a SYSTEM CALL, right? Which means it will be calling the
FUNCTION OF OUR KERNEL or OPERATING SYSTEM, right?

See, this is operating system, kernel is some part of it. Right?
Let us assume that, the system call which it makes, will always be inside the kernel.
See, operating system is a big program out of which
kernel is a part of it.
Right? Kernel is a part of it.
Now, any system call we make, will be present inside the kernel.
Right? You think of it like that. It will be present inside the kernel. Now, since this function is present inside
the kernel,
Once we make a system call, this function inside the kernel should be executed, right? It should be executed.
Now, what will happen because of this? 

Analyze the point. In case if I want to EXECUTE OUR OPERATING SYSTEM
or the KERNEL, I need to move to KERNEL MODE, right?
I need to move to KERNEL MODE. So in USER MODE I will not be able to access these data, right?
Only because of that, I have called the operating system. Now since I have called the operating
system, obviously our mode will change, right?

Which means in case if it is in user mode, we should have changed into kernel mode, right?
We should have changed into kernel mode. Now, since we are in
kernel mode, this operating system program can access all these things. Either hardware devices
or some other process, right?
So what it will do is, this program will be executed by the CPU.

This function will be executed by the CPU because of which this data will be moved to this process.
Right?
And what will happen? After the execution of this function we will be again going to this process. Right?
We will be again going to this process.

Now, again since we have moved to user process, even our mode will change, right? We will be again going
back to user mode, right? Now, since we have gone to user mode, our user process
would start executing, right?

Because it can proceed with the execution because it has got the data, right? It has got the data.
So this is how our processes will be working.
Right? Our processes will be working.

SO THE IDEA IS SIMPLE. 

1.	If a user process wants to access any data within its process control block, it
	can directly do that.
	It doesn't need to call the operating system. Fine? 

2.	Whereas, in case if it wants to access the contents of some other process, then it needs to call the operating system using system call.

	Right?

	Once we make the system call, obviously the function inside the operating system needs to execute.
	So in order to do that, our mode needs to change from user mode to kernel mode, right? User mode to kernel mode.


Now, since we have moved to KERNEL MODE, our operating system function will obviously be able to access any
I/O device as it wants. Right? Or any process as it wants.
So it will be taking the DATA and then giving it to the process.
Fine?

Now, once the function's execution is done, we will again be executing this process
and before that, our MODE will be changing from KERNEL MODE TO USER MODE, right? KERNEL MODE to USER MODE.

Now, this program can start executing.
Right?
This program can start executing.
So I think you have got a good idea of what do we mean by SYSTEM CALL
and what do we mean by TWO MODES, right?
USER MODE and KERNEL MODE. Fine!
















  
  
  


	51. Context Switching vs Mode Switching
	---------------------------------------

 	CPU					RAM		
 --------	 	 ------------------- 
|		 |		|	  OS KERNEL		|
|		 |		|  		   			|
 --------		|-------------------|
				|		P1 			|
 --------		| 200 instructions	|
| a = 3  | R1	|-------------------|
 --------		|					|
 --------		|					|
| b = 2  | R2	|		 			|
 --------		|-------------------|
 --------		|		 P2 		|
|  1010  | PC	| 50 instructions	|
 --------		|-------------------|
 --------		|					|
|  |  |  | 		|		 			|
 --------		 -------------------
  Flags



		Context Switch
	--------------------
   ||				   ||
   \/				   \/
---------------------------------- User Mode (m = 1) (User Program or Application Program)
-->	\				   /\ --->	/\
	 \				   /		|
	  \				  /			|	Mode Switch
	   \			 /			|
	   \/ --------> /			\/
---------------------------------- Kernel Mode (m = 0) (Kernel Program which is a part of Operating System Program)


PC -> PROGRAM COUNTER


Fine! Now, let's see a very interesting topic which is mostly asked in a lot of interviews.

What is the difference between CONTEXT SWITCHING and MODE SWITCHING, right?

Let's see that. See we have already seen what do we mean by CONTEXT SWITCHING, right? We have seen in a basic way, right?
We didn't see the exact concept but we have seen what do we mean by CONTEXT SWITCHING. Right?

Let us assume, our CPU is currently executing user process P1. Right?
And let us assume that P1 is having a total of two hundred instructions, right?
Process P1 will be having a program and that program is having exactly 200 instructions.
Let us assume that, process P2 is having something like 50 instructions, right? 50 instructions. 


See, what
is the difference between instruction and line of a program?
We will see that later. Okay?
We will see in the computer organization. 

You can think of an instruction as a line of a program. Though it is not exactly correct,
It actually helps in understanding the concepts.
OK? So understand that an instruction is nothing but a line of a program.


Fine! Now, CPU is executing process P1.
Let us assume that, it has executed 50 instructions so far, right? 50 instructions so far and our scheduling
algorithm has preempted process P1 and it has scheduled process P2.
This is what we mean by context switching, right?

This is what we mean by context switching which means we are SWITCHING THE PROCESSES, right? Our CPU
was executing P1, now it has switched to process P2.

This is what context switching means. But how does context switching take place? Right?
That's what we're going to see here.

See if CPU have executed 50 instructions of process P1 and if it is going to process P2, it should
save the set of registers which has been created
while executing process P1, right?
See, while executing the first 50 instructions of process P1
our CPU should have created some set of registered values.
For example, it has maintained a variable something like a = 3, b = 2.
Something like that. Right? It should have maintained some set of values. See, not only these variable names
we would also maintain something called as register file.
Or I can say that a set of special registers, something like program counter, there is a register
called as program counter. We will see in computer organization architecture.
But understand that this register will always hold the address of the next instruction
I need to execute in this process, right? See, since CPU has executed 50 instructions in process.
P1, obviously it will hold the address of the next instruction, right?
Let us assume, the next instruction is present in address 51, right? It is present in address 51. So it is
just remembering the next instruction number
that need to execute, right? 

That's what program counter will do. Likewise, we will be having a lot of things.
There is something called as flags.
There is something called as flags where we will be maintaining a set of bits, okay? We will again see that
a bit later in computer organization. But understand that CPU while executing a process, while executing
the first 50 instructions of process P1, it should have created a set of registers and flags, right?
Set of register and flag values.

Now, whenever I'm moving from process P1 to process P2. Or whenever I'm switching between processes.
I need to definitely save all these register values.
Right?
Why?
Because after some time, when I try to execute process P1, I need to continue the
place where I left out. Or the instruction number where I left out. Let us assume,
I have pre-empted P1 and have scheduled process P2 and P2 is executing, right? Let us assume,
after executing 10 instructions of process P2, we have pre-empted P2 and our scheduling
algorithm has again scheduled the process P1, right? In that case, we
need to continue from the next instruction. See, in case if we have executed 50 instructions
we need to continue from the 51st instruction, right? Now, how will I know the address of the next instruction?
That will be present inside that program counter. See, program counter will not hold the instruction number,
okay? Please make it very clear program counter will not hold the instruction number, it will hold the
address of the next instruction, right?

This is actually misleading.

Okay? This is actually telling the instruction number. Let us assume that instruction number 51 is present
at address thousand and one, right? 1 0 1 0 right? Something like this. If this is the case, then I should
be continuing from this address, right? I should be continuing from this address.

Now, while I'm continuing from this instruction, from instruction number 51 I should be knowing all these
values right?
Else I will not be able to execute it. See, while executing the first 50 instructions I have created these
register values, right?
Now, let us assume that the 51st instruction is something like C = a + b, right?

Now, in order to perform this operation I need to definitely know the value of a and b, right? Which I should
have stored while executing the first 50 instructions.
This is the exact reason we will be storing all the registers and flags of process P1 inside the RAM.
Inside the RAM.

Now, how it will be stored?
We will see that later.
Okay?
Don't worry about it.
That will be covered when we are seeing about COMPUTER ARCHITECTURE.
There is something called as STACK DATA STRUCTURE. We will see that a bit later.

So CONTEXT SWITCHING is nothing but, in case if there is a context switching from process P1 to process P2,
first,
I need to store the set of registers and flags of process P1 inside the RAM.
Right? Once that is done I need to do the PROCESS SWITCHING right? PROCESS SWITCHING.

Now, what might happen is, I could have executed some few instructions of process P2 before, right?
So I should have created some set of registers while executing process P2.
Right? Now, whenever I'm switching from process P1 to P2, I need to restore the register values and flags of process P2,

Right?
Let me assume that I have started executing process P2,
I have executed 10 instructions and our scheduler is again scheduling process P1, right? Now, what
I will do is, first point is I will save the registers and flags of process P2 inside the RAM, fine? So that it
will be useful later fine?
Once this is done, I will be restoring the register values of process P1, inside the CPU registers. See,
these registers are created inside CPU register.
these registers are created inside CPU registers.

Whenever, I'm switching from one process to another I will be moving this inside the process control block
right? Inside the process control block.
Now, whenever I am executing this process I will be
restoring the values again to the CPU registers. See, you can think of
CPU register something like a rough paper, right? While writing an exam we will be doing
the computations inside a rough paper and then we will be writing the answer in the original sheet.
That's what we're exactly doing.
You can think of CPU registers like a rough paper right?
So this is how context switching will happen. In case, if I'm switching from process P2 to process
P1, I need to save the registers and flags of process P2 and then I need to restore the registers
and flags up process P1.
Right?

And in between PROCESS SWITCHING will happen which means, in case if I'm switching
from P2 to P1, I need to give P1 to the CPU, right? So that it will START EXECUTING.
This is how CONTEXT SWITCHING will happen.


See, one important point you need to understand here is, who will do all these things?
Will do all these things?
See, I am saying that we need to store the contents of P2 or registers and flags of P2
and restore the registers and flags of P1, right? Now, who will do all these things.

All these things are being done by our operating systems.
Or I can tell that all these things are being done by our SHORT TERM SCHEDULER and DISPATCHER right?
We have already seen that. SHORT TERM SCHEDULER.

See, this is our OPERATING SYSTEM PROGRAM, fine?
Let us assume this is our KERNEL.
Then inside the KERNEL there will be something
there will be a function for SHORT TERM SCHEDUER and DISPATCHER, right?

Either maintained in a single function or maintained in 2 functions. That is not important
here.
So this function will hold the CODE, in case if I execute this core this saving of registers and restoring
of registers will take place, right?
Fine!

But before that, in order to do that I need to definitely execute the code of operating system.
I need to execute the function
The short term scheduler function of the kernel.
Now, how this will happen? See,
I have already told you that, WE CAN EXECUTE THE KERNEL ONLY IN KERNEL MODE, right?
Similarly, WE CAN EXECUTE USER PROGRAMS ONLY IN USER MODE, right?

Now, let us assume, I am context switching from P2 to P1. Now, whenever I
was executing process P2, I was executing them in user mode, right?
Fine!
Now, whenever I am doing context switching, that has to be done by our operating system.
That has to be done by our operating system which means by the execution of this function.
Now, in order to do that, we will be switching from USER MODE to KERNEL MODE, right?

See,
generally for KERNEL MODE we
will be having the MODE bit as 0, right? For USER MODE
we can have the MODE BIT as 1. THOUGH THIS CAN VARY DEPENDING ON IMPLEMENTATION IN MOST OF THE TEXT BOOKS.

this is what has been followed, right?

For USER MODE we are maintaining the MODE BIT as 1. Whereas, for KERNEL MODE we are maintaining
the MODE BIT as ZERO.
Since I was executing process P2 in user mode, I will be having the mode bit as 1, right?
Now, since I need to execute this function I will be moving from user mode to kernel mode. Right?
I will be moving from user mode to kernel mode. Now, what I will do is, I will execute this complete function
right? Which is present in operating system in kernel mode. Now, you know that in kernel mode we can access
anything. That is fine. When I execute this complete function,
All of these register values will be stored inside the RAM, right?
Fine! Now, once this is done I need to start executing process P1.
See, I'm moving from P2 to P1. I executed P2. I executed this function.
Now, I need to start executing process P1, right? Because our scheduler has scheduled process P1.

Now, what I will do is,
See, I have executed the function in kernel mode.
Now, I will be switching from kernel mode to user mode, right?
Why?
Because this function, this user program can be executed only in user mode, right?
Only in user mode.
Now, once this is done, I will start executing the user process P1 in user mode. Right? Are you
getting the point? I was executing P2 in user mode, fine?

Now I did a mode switch.
This is what we mean by mode switch.
Right? We are switching from user mode to kernel mode. Fine! Now, after doing mode switching, I am executing
the kernel program, right?

And once this is done I am again doing another mode switching. Right?
This is also mode switching. Switching from kernel mode to user mode.

Once this is done I am starting the second program or the process
P1. Right? In user mode.

This is how context switching will happen.
Right? Context switching will happen.
So one important point you need to understand is, see, this complete procedure is what we mean by context switching.

Are you getting the point? This complete procedure is what we mean by context switching.
See, what do we mean by context switching? Switching between user processes, right?

Switching between user processes.

Now, in order to do a single context switch between user processes I am doing exactly 2
mode switches, right? One mode switch from user mode to kernel mode and one mode
switch from kernel mode to user mode.

This is what we mean by mode switching, right?
This is what we mean by mode switching.

 ===================================================================================================================
|																													|
|	See this is a very important point.																				|
|																													|
|	1.	Okay? Understand the point. Switching between USER PROCESSES is what we mean by CONTEXT SWITCHING.			|
|																													|
|	2.	Whereas, SWITCHING BETWEEN A USER PROGRAM AND A KERNEL PROGRAM is what we mean by MODE SWITCHING, right? 	|
|																													|
|	We are switching from USER MODE to KERNEL MODE. 																|
|																													|
|	One																												|
|																													|
|	mode switch. And we are switching from kernel mode to user mode. Right?											|
|																													|
|	This is what we mean by MODE SWITCHING. SWITCHING between USER and KERNEL PROGRAMS is what we mean by MODE		|
|																													|
|	SWITCHING. Whereas, 																							|
|																													|
|	SWITCHING BETWEEN TWO USER PROGRAMS, is what we mean by CONTEXT SWITCHING 										|
|																													|
|	and a single context switch involves 2 mode switches, right? 													|
|	2 mode switches. See, along with this we will also be maintaining this											|
|																													|
|	mode bit, right? We will always be maintaining it. Initially it was in user mode so it was having a value		|
|																													|
|	one. Now, whenever I turn to kernel mode its value will become zero.											|
|																													|
|	Now, again when I turn from kernel mode to user the mode this will again become one.							|
|																													|
|	Right?																											|
|																													|
|	This is just a single bit in order to indicate that mode of our CPU, right? The mode in which the processes		|
|																													|
|	are executing. Fine!																							|
|																													|
 ===================================================================================================================
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
	52. Problem
	-----------

Fine.

Let's solve this problem.

The time taken to switch between user and kernel modes of execution be t1.
Okay?
While the time taken to switch between two user processes be t2. Now, which of the following is true?

A. t1 > t2
B. t1 = t2
C. t1 < t2



They're just asking whether t1 is greater than t2 or is t1 equal to t2 or t1 is less than t2.
Okay? I think this question is very simple for you with the concept we have learned in the previous
video.
See, they're saying that t1 is nothing but changing of modes, right? Mode switching which means some
user mode to kernel mode. This duration of time is what they mean by t1. Right?
Its what they mean by T1. Or this duration. Anyone of them. Okay?
Either this one or this one and what they are telling about t2 is,

It is nothing but the time taken
to switch between two user processes which means they are saying the context switching time. See,
switching time is the total duration.
Right?
Starting from this time till this time.

This is what we mean by context switching time which means initially we will be turning from user mode
to kernel mode
and then we will be executing the short term scheduler program in the kernel and then we will be
turning from kernel mode back to user mode.
Okay?
The total duration of time.

This is what we mean by context switching, right? Important point is in context switching
time we
have exactly 2 mode switching times.
Right?
Two mode switching times along with it we have some additional time.

Okay? So if you compare one mode switching time and one context switching time, definitely the context
switching time will be greater than mode switching time, okay?

See they are not even comparing 2 mode switching times.
They're simply comparing a single mode switching time and a context switching time.
So definitely context switching time will be more than the mode switching time.

OK?

So the answer for this problem is, so they have given that t1 has mode switching time, okay?
And t2 is context switching time.
So t2 has to be greater than t1, right? It has to be greater than T1.
This can also be written as t1 is less than T2.

Right?
This is the answer for this problem.

I think you're getting the point, okay?
This concept is very important and it has been asked in a lot of interviews.

Okay?
So please be aware of it. Fine!























 ============================
||	Section 13: Threads		||
 ============================
















	57. Difference between stack memory and heap memory
	---------------------------------------------------

PCB (Process Control Block) of P1
---------------------------------

		 -------------------
		|					|
		|					|	Heap Segment (DYNAMIC MEMORY)
		|					|
		|-------------------|
		|					|
		|	f3() e= f=		|
		|	f2() c= d=		|
		|	main() a= b=	|	Stack Segment (STATIC MEMORY) (Stack Memory) (Stack Data Structure) 
		|___________________|
		|					|
		|  Static Variables	|	Data Segment
		|  Global Variables	|
		|___________________|
		|					|
		|	Machine Code	|	Code Segment
		|					|
		|___________________|
		
		
					 ----------
Source Program ---> | Compiler | ---> Machine Code
					 ----------
			  /\					/\
			  |		 				|
			   ---- Compile Time ---

main()
{
	int a,b;
	----
	f2();
	----
	----
}

f2()
{
	int c,d;
	----
	----
	f3();
	----
	----
}

f3()
{
	int e,f;
	----
	----
}

Stack -> Only top of the Stack can be accessed.

"STACK SEGMENT OF THE PROCESS CONTROL BLOCK IS USED FOR ONLY 2 PURPOSES.
1.	TO MAINTAIN LOCAL VARIABLES IN OUR PROCESS
2.	WE ARE GOING TO REMEMBER THE ORDER IN WHICH WE ARE MAKING THE FUNCTION CALLS



For now, let's understand the difference between STACK SEGMENT and HEAP SEGMENT.
See, this is the process control block of a process. Right?
And it will be having a code segment, data stack segment, stack segment and heap segment.
Okay?
Now, in case if you can understand the difference between stack segment and heap segment.
It will be very easy to understand THREADS. That's the reason I'm making this video.
Okay?
Just try to get a rough idea.
Okay!

This is actually a topic which will be discussed in detail in data structures and algorithms.
Anyway!
I have taken it so that it will be easier to understand THREADS.
Fine,

Let us assume this is how
we are having the source program, okay? SOURCE PROGRAM or HIGH LEVEL PROGRAM.
It can be present in any language like C or C++, Java, Python or whatever!

Okay, now what will happen is this source program will be given to something called

as COMPILER.

Okay? It will be given be something called as COMPILER.

 ---------------------------------------------------------------------------------------------------------------
|																												|
|	Now what is meant by compiler? COMPILER is a SYSTEM SOFTWARE just like OPERATING SYSTEM, even				|
|																												|
|	COMPILER is also a SYSTEM SOFTWARE.																			|
|																												|
|	Now what the software will do is it will be converting the SOURCE PROGRAM into something called as MACHINE	|
|	PROGRAM.																									|
|																												|
|	Okay, into something called as MACHINE PROGRAM, which means ONES and ZEROS. Our entire code will be			|
|																												|
|	converted into 1's and 0's. Fine!																			|
 ---------------------------------------------------------------------------------------------------------------

Now,

 -----------------------------------------------------------------------------------------------
|																								|
|	this time period which the COMPILER takes to convert the SOURCE PROGRAM to MACHINE CODE		|
|																								|
|	is what we mean by COMPILER TIME.															|
|																								|
|	Okay? This is what we mean by COMPILER TIME.												|
|																								|
 -----------------------------------------------------------------------------------------------

Now, where this machine code will be present? Okay, this machine code will be placed in the code segment of the PCB.

This machine code will be placed in the CODE SEGMENT of the Process Control Block (PCB).

Fine, now what will be present in the data segment?

See, in case if this program has some STATIC or GLOBAL VARIABLES, in case if it has those, then those

variables will be included inside the data segment.

Okay? Inside the data segment. It will only contain static variables and global variables.

So what is meant by global variables? Global variables are variables which are not declared inside any

function.

Okay?

Which are not declared inside any function!

If you see this, in case if I have something like

int (a,b) over here.

This is not a global variable.

Why?

Because it is declared inside a single function.

Okay? In case if a variable is not declared inside

any function, then we say it is global variable .. anyway it is not very important to understand coming to operating

system.

Okay? Our main intention of taking this video is to understand the difference between heap segment and stack

segment.

Okay, fine!

So global and static variables will be maintained here.

Okay?

Don't worry too much about this.

Fine, now what will be present in stack segment.

Okay?

That's what we're going to see what will be presented STACK SEGMENT or STACK MEMORY.

Okay?

See this is a complete,
this is what has been allocated inside the RAM

for a SINGLE PROCESS, so all these things are memory which are allocated for a SINGLE PROCESS

by our OPERATING SYSTEM.

Okay?

Now, let's understand stack segment.

Let us assume that here I have a variable something like int (c,d) and let us assume here

I have variable something like int(e,f) and as I have told you,

these are local variables Okay? because they are declared inside a single function

Okay?

Now, these variables can be used only inside this function.

Okay?

That's the reason we are saying it as local variables. In case

if you try to use these variables outside the function then we will be getting a COMPILATION ERROR.

Okay?

Now, what do we mean by COMPILATION ERROR?

Whenever compiler is trying to convert source program to machine code

and in case let us assume, you have used to something like, you are printing 'a'. Okay, you are trying to

print 'a' over here.

Now, what will happen

because you don't worry about the syntax. I am not focusing on it now if you try to print

'a' over here.

It will definitely throw an error because the variable 'a' has not been declared inside the function.

Okay? It is not declared inside the function. So this variable which is declared inside this function can

be used only within this function.

Okay? because of this we will be getting a COMPILATION ERROR.

Now, what do we mean by COMPILATION ERROR?

Whenever the compiler converts the source program to machine code, it will throw an error.

It will easily detect this variable. It will find out that this variable has not been declared.

Fine!

This is a COMPILATION ERROR.

This is fine.

Now what will happen here?

See let me convert this as main function.

Okay? It is not function F1.

Let us assume, it is main function.

As you know, in C programming language we will start executing all events from the MAIN FUNCTION.

Okay? we will always start executing from the MAIN FUNCTION.

Now what will happen here is we are starting with this function right?

Our process

We are starting,

this is code of our process.

Now we are starting to execute this program.

What will happen?

Initially, we are executing the MAIN FUNCTION.

So what we will do is, in stack segment we will add a single entry for the MAIN FUNCTION.

Okay? We will add a single entry for the MAIN FUNCTION! A single entry has been added for the MAIN FUNCTION.

Now why are we doing this?

For every function we are executing, an entry will be added

to the stack segment.

 ---------------------------------------------------
|	This record is also known as ACTIVATION RECORD	|
 ---------------------------------------------------

Okay?

an entry of the ___

This is how our stack will be present.

Okay?

 ---------------------------------------------------------------------------------------
|																						|
|	This is how our stack will be present, it is a DATA STRUCTURE. In STACK SEGMENT,	|
|																						|
|	we will be always following stack DATA STRUCTURE. Okay, STACK DATA STRUCTURE! 		|
|																						|
|	IT IS A VERY IMPORTANT POINT TO UNDERSTAND.											|
|																						|
|	Please note to this point. In stack segment,										|
|																						|
|	these will be following STACK DATA STRUCTURE right?									|
|																						|
|	Which means, see, this is not the structure of our memory.							|
|																						|
|	Please get this point.																|
|																						|
|	This is not the structure of our memory.											|
|																						|
|	THIS IS THE STRUCTURE IN WHICH WE ARE ADDING ENTRIES TO THE MEMORY.					|
|																						|
|	Our memory will always look exactly like this.										|
|																						|
|	It will be having simply words. Now, in case... let us assume						|
|																						|
 ---------------------------------------------------------------------------------------

I want to use from this address to this address stack memory.

How can I do that?

It is very simple!

I should be inserting the values only in this order.

Okay?

Which means let us assume I'm adding an entry, first entry over here

Second entry over here.

Third entry over here, fourth entry over here.

And our stack is completely full, right? Now in case, if I want to remove the elements

from this memory I can only access the fourth element.

Okay? This is how stack memory works.

Okay, in case if I have inserted 4 elements over

here I can only access the top of the stack. I cannot access any other entry

Now in case if I delete this entry, this will become the top of the stack okay?

Then I will be able to access only this entry.

I cannot access this entry directly.

In case if I can remove this entry, I will be obviously able to access this entry.

This is how stacked DATA STRUCTURE works.

Now what I have done is in this memory I am storing.

Let us assume this is the region which has been allocated to the stack segment of this process.

Okay now I can add these entries into the segment in the form of stack.

Okay? in the form of stack. Now, in case if I want to remove this, I would be able to remove this.

Now we can access only this entry, if I can remove this entry obviously I would be able to access

only this entry.

Okay?

 -----------------------------------------------------------------------------------------------------------------------
|																														|
|	This is how stack DATA STRUCTURE works, see not only stack, you take any DATA STRUCTURE whether						|
|																														|
|	heap or binary heap or trees or graphs or whatever it is... the memory will look exactly like this.					|
|																														|
|	The way in which we are storing the data only that can vary, okay?													|
|																														|
|	This is what we learn in DATA STRUCTURE.																			|
|																														|
|	Okay?																												|
|																														|
|	DATA STRUCTURE, THE STRUCTURE IN WHICH WE STORE THE DATA IN THE RAM OF OUR COMPUTER IS WHAT WE MEAN BY				|
|	DATA STRUCTURES.																									|
|																														|
|	Okay?																												|
|																														|
|	Anyway, let's not think about data structures at this point of time.												|
|	What I want to tell you here is in stack segment we will be adding entries only in the form of stack Okay? we will	|
|	be following the stack data structure but coming to heap segment, 													|
|																														|
|	THERE IS A DATA STRUCTURE CALLED AS HEAP. WE WILL NOT BE FOLLOWING													|
|	HEAP DATA STRUCTURE FOR THIS HEAP SEGMENT.																			|
|																														|
|	Okay?																												|
|																														|
|	THERE IS ABSOLUTELY NO RELATION BETWEEN HEAP SEGMENT IN OUR MEMORY AND HEAP DATA STRUCTURE.							|
|																														|
|	Okay?																												|
|																														|
|	HEAP DATA STRUCTURE.																								|
|																														|
|	THIS IS A BIG CONFUSION.																							|
|																														|
|	Many students actually get confused																					|
|																														|
|	here.																												|
|																														|
|	Okay?																												|
|																														|
|	It is actually																										|
|																														|
|	the terminologies misleading okay?																					|
|																														|
|	so don't get confused!																								|
|																														|
|	There is no relation. Anyway,																						|
|																														|
 -----------------------------------------------------------------------------------------------------------------------


let's see about stack segment right now!

Now what will happen is since we have started executing the MAIN FUNCTION we have added an entry for

MAIN FUNCTION.

Right? Now what we will do is in MAIN FUNCTION. In this entry which has been created

for the MAIN FUNCTION we will be having exactly

these variables named A and B. Okay? Let us assume, A has taken some value

It will be present here.

B has been taking some value which will be present here.

Let us assume that in our computer for a single integer

WE ARE ALLOCATIONG FOUR BYTES OF DATA, OKAY? FOUR BYTES OF MEMORY

It can vary depending on implementation.

SOME COMPUTERS WILL GIVE ONLY TWO BYTES FOR AN INTEGER

SOME COMPUTERS WILL GIVE ONLY FOUR BYTES FOR AN INTEGER

Okay? It really depends on the IMPLEMENTATION.

Let us assume that here we are allocating only 4 bytes.

Okay? so 4 bytes will be allocated for the variable here to store its value and four bytes has been

allocated to the variable B to store its value.

Okay?

Fine! Now what'll happen,

this main function will be executed from the code segment.

Okay how? By our CPU, it will fetch instruction by instruction and then it'll start executing.

Okay? let us assume we are executing in this order.

Okay,

 ---------------------------------------------------------------------------------------------------------------
|																												|
|	ANYWAY WE WILL BE EXECUTING ONLY THE MACHINE CODE															|
|																												|
|	OKAY? WE WILL NOT BE EXECUTING THE SOURCE CODE, ANYWAY JUST TO UNDERSTAND THIS I'M TAKING THIS SOURCE CODE	|
|																												|
|	OKAY? IT WILL BE EXACTLY THE SAME AS THIS.																	|
|																												|
 ---------------------------------------------------------------------------------------------------------------

Anyway we will be executing only the machine code

Okay? we will not be executing the source code, anyway just to understand this I'm taking this source code.

Okay? It will be exactly the same as this.

Fine, we are executing this function line by line,

Fine

we have executed it. now once we see a function called to function

F2

What we will do?

This is very important part,

Okay?

We are making function F2 ___

Now immediately I will start executing from this line.

Okay?

I will start executing from this line.

Now once I start executing this function an entry will be added to the stack for the function F2.

Okay? For the function F2. Why? because I am going to execute function

F2.

Okay?

So an entry has been added for the function F2.

 -----------------------------------------------------------------------------------------------------------
|																											|
|	THE IMPORTANT POINT YOU HAVE TO NOTICE HERE IS															|
|																											|
|	Now I will not be able to access this entry directly.													|
|																											|
|	Why?																									|
|																											|
|	Because I'm not supposed to access this function directly without executing this function I cannot go	|
|																											|
|	back to this function okay?																				|
|																											|
|	See how the execution will generally happen.															|
|																											|
|	See this code.																							|
|																											|
 -----------------------------------------------------------------------------------------------------------

We are executing this program, suddenly I am getting a function call to function F2

So I will go to this function.

Okay I'll go to this function.

Now in general what we will do is we will complete the execution of function F2 and then we will return

to the next line over here.

Okay? we have stopped here

so I am starting to execute from this line.

This is all generally happens but here we are having another function call so we will execute this complete

function on seeing this function call and going to this function,

I will start executing till this point. I'm seeing this function call, I'll be going to

function F3 and I will be executing the complete function.

Here I don't have any function call.

Let us assume like that once its execution is done I will start executing from this line.

Okay?

Because I have already

executed till this line and I went to this function on seeing this line. So I start executing from this

line and I will complete the execution.

Once it's done I will again go back to this line and then I must complete this execution again.

This is how this program will execute.

This is the order in which we will be executing the program.

Now how the stack entries will be added is initially we executed this function fine.

When I started executing this function and entry for the main() has been added.

Now, once I make a function call and they start executing this function an entry has been added for

function F2.

The reason we're adding to the top of the stack is because till I complete execution of this function.

I should not be able to access this function.

Okay?

Exactly for that reason.

In case I have completed execution of function F2 this entry will be automatically

deleted or removed.

Okay?

Only after that I will be able to access this entry. Only after that I will be able to start

executing this function.

Okay? I think you're getting the point.

So on seeing this function call,

I will start executing this function now because of this, entry will be added to the

stack memory for the function F3. The important point I want to tell you

here is

Here we have two variables named c and d. Okay? so for variable c and d exactly

four bytes of memory will be allocated.

Okay? It can have any value depending on, it really depends on the code we have here.

Whatever values we're going to have.

Okay?

You can take any value. Now since I'm executing function F3 for variables e and f, exactly

4 bytes of

data will be allocated Okay?

Exactly 4 bytes of data will be allocated.

So this is how the execution will happen.

Okay? Now what will happen because of this

Once we complete the execution of function F3

we will remove this line or we will stop from the stack.

Okay?

This line will be deleted. If I delete this line, then this entry will become the top of the stack.

Okay?

No I will execute this remaining part and then I will remove this line.

Okay?

And once I will start executing this code from this line

and once it is done I would remove this line.



THIS IS WHAT WILL WE PRESENT IN STACK MEMORY DURING THE EXECUTION OF THE PROGRAM.



So important point you need to get from this from this is, "STACK SEGMENT OF THE PROCESS CONTROL BLOCK

IS USED FOR ONLY 2 PURPOSES.

One thing is that it is used to

HOLD THE LOCAL VARIABLES IN OUR PROCESS"

Okay? these are all the local variables, all these local variables are present when the corresponding function

was being executed.

Okay?

Once the execution of the function is over we are going to delete that entry from the stack.

That's for sure!

Okay? so one functionality of stack segment is "TO MAINTAIN THE LOCAL VARIABLES IN OUR PROCESS" to maintain

the local variables.

Now another functionality of the stack segment is

"WE ARE GOING TO REMEMBER THE ORDER IN WHICH WE ARE MAKING THE FUNCTION CALLS"

Okay?

Remember the ORDER OF FUNCTION CALLS or THE SEQUENCE OF FUNCTION CALLS. Either ORDER OF FUNCTION CALLS or

SEQUENCE OF FUNCTION CALLS.

so what do you mean by this is initially, I was executing main(),

Then I was going to function F2 then, I was going to function F3. Right? now

this has to be executed first and then this one and then this one. Okay? Just to remember the order in which we

are making the function calls.

We are using the stack memory.

We are using the stack memory.

So these are the only 2 information

we maintain in the stack memory.

Apart from that we don't maintain anything else inside the stack memory.
information alert
Schedule learning time
Learning a little each day adds up. Research shows that students who make learning a habit are more likely to reach their goals. Set time aside to learn and get reminders using your learning scheduler.

























	58. Difference between stack memory and heap memory continued
	--------------------------------------------------------------

PCB of P1 (Address Space of P1)
-------------------------------

		 -------------------
		|			 ---	|
		|	1000 -> |	|	|	Heap (DYNAMIC MEMORY) (Heap Memory)
		|			 ---	|
		|-------------------|
		|					|
		|					|	Stack (STATIC MEMORY) (Stack Memory)
		|					|	
		|___________________|
		|					|
		|  	p = 1000		|	Data Segment
		|  					|
		|___________________|
		|					|
		|					|	Code Segment
		|					|
		|___________________|
		

f1()
{	
	int a;
	int *p;
	p = malloc (size of (int))
	----
	----
}

ALWAYS REMEMBER THE POINT THIS CODE WHICH CPU IS EXECUTING CAN ACCESS THE STACK
MEMORY DIRECTLY.

OKAY IT CAN ACCESS THE STACK MEMORY DIRECTLY BUT IT WILL NEVER BE ABLE TO ACCESS THE HEAP MEMORY DIRECTLY.


 ===============================================================================================================
||	Fine.																										||
||																												||
||	Before seeing about HEAP MEMORY I want to discuss one important point coming to STACK MEMORY. 				||
||																												||
||	See, STACK MEMORY is also called as STATIC MEMORY.															||
||																												||
||	It is also called as STATIC MEMORY whereas, HEAP MEMORY is also called as DYNAMIC MEMORY.					||
||																												||
||	See, what is the difference between STATIC and DYNAMIC, in general?											||
||																												||
||	See in case if something changes according to the situation then we say it is DYNAMIC. Right ! In general	||
||	Whereas, if something doesn't change according to the situation.											||
||	Which means it remains as it is always.																		||
||	Then we say it is STATIC. Right !																			||
||																												||
 ===============================================================================================================



For example, if you take web pages there are two types of web pages: one is static web page
And other one is dynamic web page.

Why?

See, In case if a Website changes according to the situation then we say, it is a dynamic website. Right !
For example, you can take websites which display scores: cricket scores, football scores or the
websites which display the news. Okay, the current affairs.
These web pages change according to time.
In case, if you take the cricket
website like cricbuzz

Don't know how many of them follow cricket but this website will actually keep refreshing the page and
it'll be changing the scores right according to the situation.
So it is definitely a dynamic website.

See, one simple example I can give you is Facebook. Okay even Facebook if you see Facebook depending
on the person who is logging in into Facebook server the web page which is displayed varies. Right !
In case if I log in to the Facebook page then the web page will be different.
Comparing to someone else log in. Right !
So, it is definitely a dynamic web page because it changes according to the situation, depending
on who is logging in.

Whereas, if you take static web page it will never change !
it will never change! Okay, it will remain as it is. Always ! See that is the basic difference between
static and dynamic.


1.	 ====================================================================================================================
	||																													||
	||	NOW, WHY DO WE SAY THIS MEMORY A STATIC MEMORY. I WILL TELL YOU.												||
	||																													||
	||	OKAY. SEE, YOU KNOW THAT INITIALLY WE WILL BE HAVING A SOURCE PROGRAM. RIGHT!									||
	||																													||
	||	AND THIS SOURCE PROGRAM WILL BE GIVEN TO A COMPILER AND THIS WILL BE CONVERTING									||
	||																													||
	||	THIS WILL BE CONVERTING THE SOURCE PROGRAM INTO MACHINE CODE. RIGHT ! THEN THIS TIME WE SAY IT AS COMPILE TIME.	||
	||																													||
	||	OKAY, THIS TIME WE SAY IT AS COMPILE TIME																		||
	||																													||
	 ====================================================================================================================

2.	 ========================================================================================================
	||																										||
	||	NOW, ONCE THE PROGRAM IS COMPILED IT WILL BE PLACED IN THE CODE SEGMENT.							||
	||																										||
	||	THE MACHINE CODE WILL BE PLACED IN THE CODE SEGMENT. RIGHT!											||
	||																										||
	||	I HAVE TOLD YOU. NOW WHAT WILL HAPPEN IS OUR CPU WILL BE FETCHING THE MACHINE CODE LINE BY LINE		||
	||																										||
	||	OR INSTRUCTION BY INSTRUCTION AND THEN IT WILL BE EXECUTING THIS PROGRAM. RIGHT !					||
	||																										||
	||	THIS IS WHAT WE MEAN BY RUN TIME.																	||
	||																										||
	||	OKAY. THIS IS WHAT WE MEAN BY RUN TIME. 															||
	||																										||
	||	THE TIME WITH WHICH THE CPU EXECUTES THE PROGRAM IS WHAT WE MEAN BY RUN TIME.						||
	||																										||
	||	IT IS ALSO CALLED AS EXECUTION TIME.																||
	||																										||
	 ========================================================================================================

3.	 ============================================================================================
	||																							||
	||	OKAY. BUT INITIALLY WE WILL BE COMPILING THE PROGRAM.									||
	||	THIS IS WHAT WE MEAN BY COMPILE TIME.													||
	||	THIS IS WHAT WE MEAN BY RUN TIME.														||
	||																							||
	||	IF AN EVENT HAPPENS DURING THE RUN TIME THEN WE WILL SAY IT IS DYNAMIC. 				||
	||	OKAY, WE SAY IT IS DYNAMIC.																||
	||																							||
	||																							||
	||	WHEREAS, IN CASE IF AN EVENT HAPPENS BEFORE THE RUNTIME THEN WE SAY IT IS STATIC. OKAY	||
	||	IT MAY NOT BE ONLY IN THE COMPILE TIME													||
	||	IF SOMETHING HAPPENS BEFORE THE RUNTIME WE SAY IT IS STATIC 							||
	||																							||
	 ============================================================================================


WHY? I WILL TELL YOU.

OKAY. SEE, IF YOU SEE THE
SYACK SEGMENT
I HAVE ALREADY TOLD YOU THAT.
HERE, WE WILL BE MAINTAINING AN ACTIVATION RECORD FOR EVERY FUNCTION. RIGHT ! ACTIVATION RECORD FOR EVERY
FUNCTION AND THE AMOUNT OF SPACE WHICH HAS TO BE ALLOCATED FOR THE STACK MEMORY SECTION OF A PARTICULAR
PROCESS WILL BE DECIDED DURING THE COMPILE TIME.
OKAY.

It will be decided during the compile time which means let us assume for this process P1
our compiler has decided that 1 MB of Space (1 megabyte) of space has to be allocated to the STACK
MEMORY of this particular process. Okay
It can vary depending on process the size can vary depending on process and since
the compiler has decided during the compile time in case IF I WANT MORE SPACE DURING THE
RUN TIME I WILL NOT BE ABLE TO MODIFY THE SIZE OF THE STACK MEMORY. Okay
I will not be able to do that.

See that's the reason we say this as STATIC MEMORY because see on the other part under the usage of the STACK MEMORY
we can also say it is STATIC MEMORY allocation. Okay, STATIC MEMORY allocation because the amount
of space which has been allocated for this memory has been DECIDED BEFORE THE RUN TIME.
See, it is just a prediction.
Okay, this decision is just a prediction which is being done by the compiler.
Most of the times it'll be correct.
Still it can be wrong.
Okay.

So, since they have decided it before and it cannot be changed according to the situation. See,
only during the run time we will exactly know the amount of space we need whether the STACK SEGMENT or
the heap segment or data segment or code segment or whatever, not code segment, actually
if you take anything we will be knowing the exact size of our data which we
are maintaining here.

We will know that only during the run time. right ! so here they are deciding it during the compile time.
THE AMOUNT OF STACK SPACE AND THIS SPACE CAN NEVER BE MODIFIED SO WE SAY IT IS STATIC MEMORY. Okay, we say it is
static memory.

Now,



WHAT DO WE MEAN BY DYNAMIC MEMORY?



Okay
HEAP is also called as DYNAMIC MEMORY because, now during the... see initially
The compilation has been done and it has been placed and then running will happen. Okay
AND NOW DURING THE COMPILATION PHASE NO DECISION WILL BE TAKEN ABOUT THE SIZE OF THE HEAP MEMORY. Okay, about
the size of the HEAP MEMORY.
No space will be allocated for the HEAP MEMORY.
Only during the run time depending on the amount of memory we need the amount of space will be allocated.
Okay, the amount of space will be allocated. See, only during the run time
we will exactly know the amount of space we need to allocate. Right !

So this decision will be taken according to the situation. In case if
this process needs only 2 MB of memory in order to run the program,
then we will be only allocating 2 MB. In case if it needs more space as it keeps running
it might need more space.
Right !

In case if it needs the space then that space will be provided by the HEAP MEMORY.
Okay, it is also called as a FREE POOL OF MEMORY. Okay, HEAP MEMORY is also called as a FREE POOL OF MEMORY which means
the amount of space I need to allocate for a process is not fixed.
or it is not limited

	 ====================================================================================================================
	||																													||
	||	Okay, it is not limited. It can get as much memory as possible for the heap segment of a particular process.	||
	||	Obviously, the size is limited by the amount of RAM... okay, we have, that is fine. But apart from that			||
	||	we don't have any condition something like stack memory. Coming to stack memory,								||
	||	we might have a large amount of RAM space which is free															||
	||	Still, in case the compiler has decided that I'm going to allocate only 1 MB space for the stack				||
	||	memory then that cannot be modified during the run time even if there is a need.								||
	||	OKay even if there is a need.																					||
	||	So, this is the reason we say it as a HEAP MEMORY.																||
	||																													||
	 ====================================================================================================================

OKay.... fine.
Now, what we will be having in HEAP MEMORY? Okay, what we generally do?
See, while running a program we might create various data structures. Right !

For example, if you can think of it, a linked list. Okay
You can think of it a linked list whether it be a linked list or a tree or a graph or a
or
You can think of any data structures you want. They will be generally created inside a program. Right ! They will be
creating inside a program and that will be generally created inside the HEAP MEMORY.
Okay, that will be generally decided inside the HEAP MEMORY.
I have already told you that what will be present inside the stack memory.

Stack memory will only contain the local variables. Right ! It will not contain anything else.
Obviously, it will also remember the order of function calls.
But apart from that it will not be having anything else.
All other things which we create inside a program will be present inside the HEAP MEMORY. Okay

One.... I see in case if I want to
I want to explain you exactly how HEAP MEMORY works.
I need to explain you POINTERS and STRUCTURES.
Okay, it is a big topic in C programming language or data structures. Okay, so I don't want to take

that

Anyway, I will give you a rough idea.
Okay, I'll give you a rough idea. See, let us assume that we have created a POINTER VARIABLE.
Okay, we have created a pointer variable.
Now what do we mean by pointer variable?
A variable which will hold the address of some memory location. We can say it is a pointer variable.
Okay.

Now why am I
Why am I
given
Why have I given here as integer? because this pointer is going to point the memory location which is holding
an integer. Okay

that... See
For example let us assume, I don't want to get into this in a much more advanced level but try to
understand this.
This pointer will be pointing to an integer.
Okay. And it will be holding the address of a memory location which will be having an integer.

That's what we mean by integer pointer.
Fine. Now what can happen is I have something
called as malloc

Okay, I don't want to explain malloc exactly.
I'm just giving you an idea. Okay
Generally, generally we will be allocating some space.
Let us assume that they have
We have allocated size of a
single integer.
Okay.

Size of a single integer. See this syntax is definitely wrong.
Okay, we do something called as type casting but I don't want to explain the concepts of C
programming over here.
Okay, so that's the reason I'm explaining it in a simple manner by taking a simple syntax. Fine !

Using this function we allocate the space inside the HEAP MEMORY. Okay
Always remember the point we have only two functions in C programming language.
One thing is malloc and other one is
Calloc

Okay.
It is a slight modification to malloc
Okay.
Apart from that nothing.
Now,
These two functions are only used in order to allocate space inside the HEAP MEMORY. Okay
These functions are only used inside the HEAP MEMORY.

For example, I want to create a linked list inside this
HEAP MEMORY.
Okay. Now, how this will happen?
It is very simple, we will be creating nodes.
We will be creating nodes.
One node will be present in some address
For example at address 2000.
let us assume that the next node is present in address 3000. Okay
Now, how both of them will be connected?

Both of them will be connected by a pointer which is placed over here, okay. See linked list is nothing but non-contiguous
allocation.
Okay it is non-contiguous allocation.
We will see all these things in data structures so don't need to worry about it but understand that
this is how a linked list will be present there will be the number of nodes in side the link list depending
on the requirement.

Now what we generally do is the starting address of this linked list will be placed inside
the stack memory. Okay, it will be placed inside the stack memory.
See, what this malloc will do is I am not going to explain exactly but I'm giving you the rough
idea okay.
This malloc will allocate the amount of space which is present here inside the HEAP MEMORY. Okay, it will allocate it.

Here, I have mentioned that size of a single integer. Right ! Size of a single integer.
Let us assume in our computer,
An integer takes 4 bytes
Okay it can vary depending on implementation but let us assume depending on the compiler as well. Now,
let us assume that they have allocated 4 bytes for an integer in our computer they allocate 4 bytes
for an integer. So, what will happen is exactly four bytes of space will be allocated inside the HEAP MEMORY.

Okay, 4 bytes of space will be allocated inside the HEAP MEMORY. Now, how can I access this four bytes.
Let us assume that it is holding some integer, something like 2.
Okay. Now,

How am I,
How will I be storing this value to this location that we will see that later. Okay

We don't need to worry about it.
Fine, we have allocated using malloc okay.

Using this line we have allocated it. Fine
Now, how can I access this later, if necessary.

Okay.
For that,
We will always be maintaining a
pointer inside the stack memory.

See this, here int *P Right !
What do we mean by this?

This is definitely a local variable. Right !
Though it is a pointer variable, it is a local variable because it has been declared inside a function.
Right ! Now, what this variable can do?
This variable can hold the address of some memory location, right ! Now,
This malloc, generally what it will do is it will be allocating some space inside the HEAP MEMORY
And this function will always be returning the starting address of the memory location which it has
allocated.

Okay.
See this is a library function.
Standard library function. For example,
this is almost similar to a system call. Okay, In a system call we will be making a function
call to the function in operating system. Right !

Similarly, here this malloc will be a library function which will
be present in your C program.

Okay. In your
C Programming library that library function will be present.
Now we're making a function call to one of the functions there in the standard library and that function
will execute that malloc function will execute because of which some amount of space will be allocated
inside the HEAP MEMORY and that function will always be returning the starting address of the memory allocated.
Okay. So, let us assume it is some address.

Okay.

Now once we allocate this, this address will be present inside the P which is a pointer
variable.
Okay, because this variable can definitely hold the address and since it is a local variable some amount
of space will be allocated for the variable P.
Okay this will be holding the address. Let us assume
this address is 1000. Okay So, this 1000 will be present over here.
Okay, 1000 will be present over here.
Now, why are we doing this?

1.
	 ================================================================================================================
	||																												||
	||	ALWAYS REMEMBER THE POINT THIS CODE WHICH CPU IS EXECUTING CAN ACCESS THE STACK								||
	||	MEMORY DIRECTLY.																							||
	||																												||
	||	OKAY IT CAN ACCESS THE STACK MEMORY DIRECTLY BUT IT WILL NEVER BE ABLE TO ACCESS THE HEAP MEMORY DIRECTLY.	||
	||																												||
	 ================================================================================================================

2.
	 ================================================================================================================
	||																												||
	||	OKAY IT WILL NOT BE, IT WILL NEVER DO THAT. WHAT IT															||
	||	WILL DO IS, IT WILL GO TO THE STACK MEMORY																	||
	||	IT WILL GET THE STARTING ADDRESS OF THE MEMORY LOCATION WHICH I NEED TO ACCESS AND THEN USING THIS			||
	||	ADDRESS.																									||
	||																												||
	||	IT WILL BE GOING TO THE HEAP MEMORY IN ORDER TO ACCESS THE DATA. OKAY, IN ORDER TO ACCESS ANY STRUCTURE		||
	||	WHICH IS PRESENT IN THE HEAP MEMORY.																		||
	||	THIS IS HOW																									||
	||	THIS IS HOW ACCESSING THE HEAP MEMORY WILL HAPPEN. OKAY														||
	||																												||
	 ================================================================================================================
	 
So in simple.... See, it need not be just a single variable.
Okay here I have just

aIlocated an integer in the HEAP MEMORY.

We can do that even for a linked list. Now, for a linked list

What will I do.

Again it is very simple.

This starting address will be written by the malloc,

which I will store it in a pointer variable.

Okay, that will be maintained inside the stack.

It need not be just integer variable or linked list, it can be trees graphs or whatever.

Okay, but the starting address will always be written because we will always be using either

malloc or calloc

Okay, Fine.

And that will be present in a pointer variable which will be present inside the stack and that will be

present in the stack because it is a local variable.

Okay

It is a local variable.

I think you're getting a rough idea.

See if you try to understand it

Exactly !

It will take some time.

Okay, we'll see that in C programming language or data structures. Please don't worry about it

right now!

As of now, we are trying to understand the concept of threads.
Okay, for that these things can help you understand better.
This is not actually compulsory.
If you take most of the courses or most of the text books they will not be explaining these
things when explaining about threads. Okay but I'm giving you a rough idea so that it will be easier
for you to understand the concept of threads. Okay

	 ===================================================================================================================
	||																													||
	||	FINE.																											||
	||	SO, THE DIFFERENCE BETWEEN STACK MEMORY AND HEAP MEMORY IS: STACK MEMORY IS STATIC								||
	||	BECAUSE BEFORE RUN TIME THE AMOUNT OF SPACE WHICH I NEED TO ALLOCATE FOR A PARTICULAR PROCESS FOR THE STACK		||
	||	SEGMENT WILL BE DECIDED.																						||
	||																													||
	||	OKAY.																											||
	||	AND THEN THAT DURATION WILL BE TAKEN BY THE COMPILER DURING THE COMPILE TIME.									||
	||																													||
	||	WHEREAS, HEAP MEMORY IS CALLED AS DYNAMIC BECAUSE DEPENDING ON THE AMOUNT OF SPACE I NEED IN THE RUNTIME		||
	||	THE AMOUNT OF MEMORY WILL BE ALLOCATED.																			||
	||																													||
	 ====================================================================================================================

Okay.
See, here I have allocated these many bytes of data for this linked list.
Now, during the running I might create another node in the HEAP MEMORY and
this might be pointing to this. Right !
I can always insert it.

Why?
Because in HEAP MEMORY I can expand the size of the structure as I want. Right ! because it is not limited
unlike stack memory.
Fine.

So, HEAP MEMORY is dynamic because the amount of space which I need is decided during the run time.
This is one difference. Another difference is in stack memory we will be generally having
only local variables and function calls. Okay But in HEAP MEMORY we will be allocating
the structure.
using malloc
and this will be giving returning address and that address will be present inside a pointer variable which
will be always maintained inside the stack memory.

Okay.

	 ============================================================================================================
	||																											||
	||	AND ONE MORE DIFFERENCE IS THIS CODE SEGMENT CAN ACCESS THE												||
	||	STACK MEMORY DIRECTLY BUT IT WILL NOT BE ABLE TO ACCESS THE HEAP MEMORY DIRECTLY						||
	||	RATHER IT WILL GO TO STACK MEMORY GET THE STARTING ADDRESS AND THEN IT WILL GO TO THE HEAP MEMORY IN	||
	||	ORDER TO ACCESS THE STRUCTURE. OKAY																		||
	||																											||
	 ============================================================================================================

So even if you didn't understand this video exactly,
don't worry about it. We will see that in C programming as of now, let's focus on threads.


























	59. Understanding Threads and Single Threaded Process
	-----------------------------------------------------

PCB of Single Threaded Process P1
---------------------------------

		 -------------------
		|					|
		|					|	Heap Segment (DYNAMIC MEMORY)
		|					|
		|-------------------|
		|					|
		|					|	Stack Segment (STATIC MEMORY) (Stack Memory) (Stack Data Structure) 
		|					|
		|					|
		|___________________|
		|					|
		|  					|	Data Segment
		|  					|
		|___________________|
		|					|
		|					|	Code Segment
		|					|
		|___________________|
		

PCB of Multi Threaded Process P1
--------------------------------

|		  |			|			|
|		  |			|			|
|---------|---------|			|
|  Stack  |  Stack  |			|
|---------|---------|			|
|Registers|Registers|			|
|-------------------------------|
|			  Heap				|
|-------------------------------|
|			  Data				|
|-------------------------------|
|			  Code				|
 -------------------------------
 
 USER LEVEL THREADS
 KERNEL LEVEL THREADS
 
 Program
  ----------
 |	1.		|
 |	2.		|
 |	3.		|
 |	4.		|
 |	5.		|
  ----------
 
1. -> 2. -> 3. -> 4. -> 5.		==>		This is a single sequence of execution of this program.

If there is a While loop in 3rd line:

1. -> 2. -> 3. -> 5.			==>		This is a different sequence of execution of this program.

	 ============================================================================================
	||																							||
	||	FINE. NOW, LETS SEE ABOUT THREADS														||
	||	SEE, ONE THING I WANT TO TELL YOU BEFORE THAT IS, WE HAVE TWO TYPES OF THREADS. OKAY	||
	||	ONE THING IS USER LEVEL THREADS,														||
	||	ANOTHER THING IS KERNEL LEVEL THREADS.													||
	||																							||
	 ============================================================================================
	
	NOW, WHATEVER WE'RE GOING TO SEE HERE WE ARE SPEAKING ABOUT USER LEVEL THREADS. OKAY
	===================================================================================	


Once you understand this, understanding this will become much more easier.
Okay.
It is very easy to understand.
Fine.

Now,
Before seeing about threads

Exactly
I want to tell you
What do we mean by a sequence. Okay, a sequence of execution.
See, this is how your process will look like.
Right !

And this process will be definitely having a code segment. Now, a code is nothing but a set of instructions.
Right !
It is a set of instructions. Let us assume that this code has five lines of program.
Okay, just for an example. There will be thousands of lines of code but just for an example, let us assume that
we have exactly five lines of code placed over here.
Okay, five lines of code placed over here.

	 ========================================================================================================
	||																										||
	||	NOW, THIS CODE CAN BE EXECUTED IN A LOT OF SEQUENCES. RIGHT ! THIS CODE CAN BE EXECUTED IN A LOT	||
	||	OF SEQUENCES.																						||
	||																										||
	 ========================================================================================================
 
 
Let us assume that, we have a while loop in instruction number three.
Okay instruction number three. Now, let us assume that in that case what will happen is, that in case if
I execute something like instruction number 1 followed by instruction number 2 followed by instruction
number 3 followed by instruction number 4 followed by instruction number 5.


THIS IS A SINGLE SEQUENCE OF EXECUTION OF THIS PROGRAM.


Right ! This is a single sequence of execution of this program.
Let us assume that, I have a loop somewhere over here. Okay
And it is saying that only if you satisfy this condition you need to execute fourth line.
Okay
If you don't satisfy this condition you should be going directly to fifth line.

Okay. Now, let us assume that we are executing this code again.

And when I'm executing this code this while loop we are getting false for a while loop. See, how a while loop

will look like? While loop will have a condition if this condition is true we will execute the next line

If it is false we will not execute the next line.

Okay

Now, what I mean to say is when I'm executing this code,

Let us assume that, I'm getting a false for this while loop.

Okay.

In that case, I will skip the next line and I will be going to fifth line. Okay, which means I am saying

that I would be executing 1st line followed by 2nd line followed by 3rd line followed by 5th

line followed by 5th line.



THIS IS A DIFFERENT SEQUENCE OF EXECUTION OF THIS PROGRAM. RIGHT!

THIS IS A DIFFERENT SEQUENCE OF EXECUTION OF THIS PROGRAM.



So, for a single program I can have more than one sequence of execution. See,

It is not just about while loop, we can take for loop or we can take if else class. For example, for one

of the programs I might see, let us assume we have if class and else class. Okay

If class and else class. For one of the sequence I will be executing the if class whereas, in case if I execute

the else class

I'm getting a new sequence. Okay

So, because of these statements like While, if else, for loop, all these things I

I might be getting more than one sequence of execution for any given program.

	 ============================================================================================================
	||																											||
	||	OKAY, FOR ANY GIVEN PROGRAM. NOW, THIS SEQUENCE OF EXECUTION IS WHAT WE MEAN BY A THREAD.				||
	||																											||
	||	OKAY, IS WHAT WE MEAN WE MEAN BY A THREAD, WHICH MEANS FOR ANY GIVEN PROGRAM I CAN HAVE MORE THAN ONE	||
	||																											||
	||	SEQUENCE OF EXECUTION.																					||
	||																											||
	 ============================================================================================================



Now in case, if I follow this sequence of execution I can say it as a thread or as incase if I follow

this sequence of execution it is another thread.

Okay. It is not exactly the definition for thread anyway,

we will see that.

Now, just to understand why we need to learn about threads let's take our server example.

okay. We have already seen the server example

Let us assume that this server is in listen mode. Okay

Which means as of now the server didn't get any request from the client.

In that case, this server will definitely be in

Listen mode. Right!


				 ================================
				 <==>	FORK SYSTEM CALL	<==>
				 ================================


NOW, WHAT WE WERE DOING IN FORK SYSTEM CALL? let us assume that, there is a client A who is requesting



a web page from the server.

Okay, who is requesting a web page from the server.

Now, what this server will do is, in case if you are following FORK SYSTEM CALL a new process will be

created and this process will be servicing the client.

Okay, this process will be servicing the client.

Now let us assume that, a new client is asking for a webpage.

Okay, his name is B.

In that case, what will I do?

Again, I will be creating a new process using the FORK SYSTEM CALL.

This process would be creating a new process using the FORK SYSTEM CALL.

And this process will be servicing this client.

Okay, this process would be servicing this client.



SEE ONE THING I WANT TO TELL YOU HERE IS, EVERY PROCESS AT ANY GIVEN TIME IS PERFORMING ONLY A SINGLE

TASK.

OKAY. IT IS PERFORMING ONLY A SINGLE TASK WHICH MEANS THIS PROCESS IS ONLY SERVICING THE CLIENT A.



Okay, which means it is going to check what web page client A is asking for.

And depending on that it will fetch the web page and give it to the client.

Okay.

Similarly, if you take this process it is also performing only one task which is nothing

but servicing client B.

Okay, servicing client B.

Now tell me one point, how client A will be serviced by this process?

Okay.

How client A will be serviced by this process?

Some code, this code will be executed in a single sequence.




PLEASE OBSERVE THIS POINT VERY CAREFULLY, THIS CODE, SEE THIS PROCESS WILL DEFINITELY BE HAVING THE SAME

CODE. RIGHT !

THE CODE WHICH IS PRESENT HERE WILL ALSO BE PLACED OVER HERE.

IT WILL ALSO BE PLACED OVER HERE. THE COMPLETE CODE SEGMENT WILL BE PLACED IN ALL THREE PROCESSES.

RIGHT! NOW, THIS PROCESS OBVIOUSLY WILL BE EXECUTING THE SMALL PIECE OF CODE WHICH IS USED

FOR LISTEN MODE WHICH MEANS IT IS WAITING FOR SOME CLIENT. OKAY, FOR THAT A SMALL PROGRAM,




Let us assume it is written inside a while loop. Okay, it will be

keep on executing this while loop.

Just to check whether we have any request or not. It will go and check the port whether

we have a request or not. If it is not present, will again go and check.

Okay.

This is what this process will be doing. In this process

we will have the complete code but still we will be executing only a small piece of code which we maintain

in order to perform the listen action. Okay

Listen action

What about this process?



THIS PROCESS WILL ALSO BE HAVING THE COMPLETE CODE BUT WE WILL BE EXECUTING THIS PROGRAM IN SOME SEQUENCE

TO SATISFY THIS CLIENT.



Right ! To satisfy this client. Also here though we have the complete code,

this code will be executed in some sequence and that

And that's because of that execution of that sequence.

It will be servicing

client B. Okay, client B !




NOW, UNDERSTAND THIS POINT CAREFULLY THOUGH THE PROGRAM IS SAME FOR ALL THESE PROCESSES, WE FOLLOW

DIFFERENT SEQUENCE OF EXECUTION FOR EVERY PROCESS.




Right!

Which means we might follow this sequence of execution in order to service client A.

Right ! By service, I mean satisfying the request. Right ! It is asking for a webpage, we are

giving the web page, that is what I mean by servicing the client. Fine.

So, in order to satisfy client A we are following this sequence of execution. In order to satisfy client

B we are following this sequence of execution.

Similarly, for listen mode we are following another sequence of execution.

Okay.



SO EFFECTIVELY WHAT I MEAN TO SAY IS, THOUGH THE PROGRAM IS SAME FOR ALL THE PROCESSES WE FOLLOW

DIFFERENT SEQUENCE OF EXECUTION THAT EVERY SEQUENCE OF EXECUTION WILL BE PERFORMING EXACTLY ONE TASK. RIGHT !

IT WILL BE PERFORMING EXACTLY ONE TASK. WHY? BECAUSE THE TASK OF THIS SEQUENCE OF EXECUTION IS TO BE LISTEN

MODE. RIGHT!



Whereas, this sequence of execution is taking care of client A. This sequence of execution is taking

care of client B. Right!

	 ================================================================================================
	||																								||
	||	SO ONE THING I CAN TELL YOU FROM THIS IS, "A PROCESS BY DEFAULT IS SINGLE THREADED." OKAY	||
	||																								||
	||	THIS IS A VERY IMPORTANT POINT. A PROCESS BY DEFAULT IS										||
	||																								||
	||	SINGLE THREADED, WHICH MEANS EVERY PROCESS WILL HAVE AT LEAST ONE THREAD. RIGHT!.			||
	||																								||
	 ================================================================================================


At least one thread! whatever we have seen, See, we have been seeing about process for a long time. Okay

since the beginning introduction video of this course.

We have been seeing about process now whatever we have seen till now

are single threaded process. Okay

What do you mean by single threaded process?




THOUGH, WE HAVE THE COMPLETE PROCESS CONTROL BLOCK THIS CODE SEGMENT WILL BE EXECUTED IN A SINGLE SEQUENCE

AT ANY GIVEN TIME.

OKAY.

IN ORDER TO PERFORM A SINGLE TASK. OKAY, IN ORDER TO PERFORM A SINGLE TASK.

FOR EXAMPLE, THOUGH WE HAVE THE COMPLETE CODE WILL BE EXECUTING THIS CODE IN A SINGLE SEQUENCE

IN ORDER TO SERVICE THIS CLIENT.

WE WILL NOT BE EXECUTING IN MORE THAN ONE SEQUENCE.




Okay, this code

So, what do you mean by thread?




A THREAD IS NOTHING BUT A SINGLE SEQUENCE OF EXECUTION.

RIGHT! NOW, THIS PROGRAM IS EXECUTED IN A SINGLE SEQUENCE OF EXECUTION.

SIMILARLY, THIS PROGRAM IS EXECUTED A SINGLE SEQUENCE OF THE EXECUTION.

SO, ALL THESE THREE ARE THREE DIFFERENT PROCESSES. RIGHT! SEE, BY DIFFERENT PROCESSES I MEAN THEY

THIS WILL EXECUTE INDEPENDENTLY OF THIS ONE. RIGHT!

SIMILARLY, THIS WILL EXECUTE INDEPENDENTLY OF THIS ONE. BUT ANYWAY THE PROCESS CONTROL BLOCK WILL BE SAME

FOR ALL THREE PROCESSES.

RIGHT! NOW, EVERY PROCESS HAS EXACTLY ONE THREAD.

WHY I SAY THAT? BECAUSE EVERY PROCESS CODE WILL BE EXECUTED IN EXACTLY ONE SEQUENCE IN ORDER TO

PERFORM A SINGLE TASK.




Okay.

IN ORDER TO PERFORM A SINGLE TASK. NOW, BECAUSE OF THIS WE SAW TWO DISADVANTAGES.

Right!

1.
	 ================================================================================================================
	||																												||
	||	WHICH MEANS, SEE ALL THESE PROCESSES WILL BE EXECUTED CONCURRENTLY.											||
	||																												||
	||	RIGHT, WHICH MEANS I WILL EXECUTE THIS PROCESS FOR SOME TIME, THEN I WILL PERFORM CONTEXT SWITCHING AND		||
	||																												||
	||	I WILL EXECUTE THIS PROCESS BUT SOME TIME, THEN I WILL PERFORM CONTEXT SWITCHING AND WILL BE EXECUTING		||
	||																												||
	||	THIS PROCESS. RIGHT! BECAUSE OF THIS THE																	||
	||																												||
	||	FIRST DISADVANTAGE IS																						||
	||																												||
	||	WE HAD CONTEXT SWITCHING OVERHEAD. RIGHT!																	||
	||																												||
	||	WE NEED TO PERFORM A LOT OF CONTEXT SWITCHES IN ORDER TO EXECUTE THESE THREE PROCESSES AND THIS CONTEXT		||
	||																												||
	||	SWITCHING TIME IS AN OVERHEAD.																				||
	||																												||
	 ================================================================================================================
2.
	 ====================================================================================================================
	||																													||
	||	THE SECOND DISADVANTAGE WE SAW HERE IS THE AMOUNT OF MEMORY IS GETTING WASTED A LOT.							||
	||																													||
	||	OKAY, BECAUSE THE SAME PROGRAM IS WHAT WE'RE GOING TO MAINTAIN HERE NOT ONLY PROGRAM YOUR DATA WILL BE			||
	||																													||
	||	SAME FOR ALL THESE PROCESSES.																					||
	||																													||
	||	NOW, WHY DO YOU WANT TO HAVE MULTIPLE COPIES OF THE SAME PROCESS CONTROL BLOCK FOR ALL THE PROCESSES. RIGHT!	||
	||																													||
	||	BECAUSE OF WHICH WE GOT THE MEMORY PROBLEM. RIGHT!																||
	||																													||
	||	WE'RE WASTING A LOT OF MEMORY.																					||
	||																													||
	||	PLEASE MAKE DETAILED NOTES OF THESE POINTS. OKAY																||
	||																													||
	||	I'M JUST WRITING IT IN SHORT.																					||
	||																													||
	||	FINE.																											||
	||																													||
	 ====================================================================================================================


				 ===================================
				 <==>	MULTITHREADED PROCESS	<==>
				 ===================================

Now these disadvantages can be overcome in case, if we are following MULTITHREADED PROCESS. Okay



SEE, BUT HERE WE ARE FOLLOWING SINGLE THREADED PROCESS.

I THINK YOU'VE GOT THE EXPLANATION.

WHY?

BECAUSE EVERY PROCESS WILL BE HAVING A SINGLE THREAD.

WHAT THEY MEAN BY SINGLE THREAD? SINGLE SEQUENCE OF EXECUTION.

EVERY CODE WILL BE EXECUTED IN A SINGLE SEQUENCE OF EXECUTION AT ANY GIVEN TIME.




Now we will be trying to execute the same program in multiple sequences within a single process. See,

here you might say that this process is presenting three different...

This process control block will be presenting all three processes and we are following three different

sequence of execution. Right!

This is true, but for every sequence of execution, we have created a new process. Right!

This is a single threaded process,

this is a single threaded process, and this is a single threaded process. 




BUT WHAT WE WILL BE DOING IN MULTI THREADED PROCESS IS,





WE WILL BE CREATING ONLY ONE PROCESS. OKAY

WE WILL BE CREATING ONLY ONE PROCESS AND YOU KNOW THAT THIS PROCESS WILL BE HAVING THE PROCESS

CONTROL BLOCK.

AND THIS CODE SEGMENT WILL BE EXECUTED IN DIFFERENT SEQUENCES.

OKAY.





WE ARE NOT MAINTAINING MULTIPLE COPIES OF THE SAME PROCESS, JUST LIKE THIS.





WE ARE MAINTAINING ONLY SINGLE COPY OF THE PROCESS AND THIS CODE SEGMENT WHICH IS PRESENT HERE

THIS CODE SEGMENT WILL BE EXECUTED IN MULTIPLE SEQUENCES CONCURRENTLY WHICH MEANS IN ORDER TO

SERVICE CLIENT A THE SAME CODE WILL BE EXECUTED IN A SEQUENCE.

SIMILARLY, IN ORDER TO SERVICE CLIENT B THE SAME CODE WILL BE EXECUTED IN A DIFFERENT SEQUENCE AND BOTH

OF THEM WILL BE DONE CONCURRENTLY WHICH MEANS THIS CODE WILL BE EXECUTED IN A SEQUENCE.



Let us assume, we are following sequence

S1

to service client A, sequence S2 to service client B.

Okay. Now, we are executing the same program in two different sequences.

Now, let us assume we are following sequence

S3 to be in listen mode. 

	 ========================================================================================================================================
	||																																		||
	||	OKAY NOW WHAT WILL HAPPEN IS WE WILL BE EXECUTING																					||
	||																																		||
	||	THIS SEQUENCE FOR SOME TIME, OUR CPU WILL BE EXECUTING THIS PROGRAM IN THIS SEQUENCE FOR SOME TIME. 								||
	||																																		||
	||	IT WILL PERFORM CONTEXT SWITCHING AND THEN IT WILL EXECUTE THIS SEQUENCE FOR SOME TIME AND THEN THEY WILL PERFORM CONTEXT SWITCHING	||
	||																																		||
	||	AND THIS MIGHT EXECUTE THIS SEQUENCE FOR SOME TIME, THIS SEQUENCE FOR SOME TIME, LIKEWISE. RIGHT!									||
	||																																		||
	||	THAT IS WHAT I MEAN BY CONCURRENTLY. OKAY																							||
	||																																		||
	||	SEE, BECAUSE OF THIS WE ARE GOING TO SAVE A LOT OF MEMORY. RIGHT !																	||
	||																																		||
	||	ONE THING IS THAT WE'RE GOING TO SAVE MEMORY BECAUSE 																				||
	||																																		||
	||	WE ARE NOT MAINTAINING MULTIPLE COPIES OF THE SAME PROGRAM. 																		||
	||																																		||
	 ========================================================================================================================================




WE ARE MAINTAINING ONLY ONE COPY BUT WE ARE FOLLOWING DIFFERENT SEQUENCE OF EXECUTION THAT EVERY

SEQUENCE WILL BE PERFORMING A SINGLE TASK. RIGHT!

I think you are finding it difficult to understand anyway we will get into this in detail.

Okay, I'm just giving you an overview.

So, this disadvantage can be overcome because of this concept.

Okay.

Also we can overcome this disadvantage because we are not having multiple processes. Right!

RATHER, WE HAVE MULTIPLE THREADS WITHIN A SINGLE PROCESS. RIGHT!

So there will not be any need for context switching.

Okay.

Anyway we will see about this in detail.

Okay.

I think you understood what we mean by a sequence of execution and what is meant

by a single threaded process.

WHATEVER WE HAVE SEEN SO FAR IS A SINGLE THREADED PROCESS.

Okay. Now,

Let's see about multithreaded process and let's see what advantages we get because of multithreaded

process.

Okay.

This is how multithreaded process would look like. Fine
information alert
Schedule learning time
Learning a little each day adds up. Research shows that students who make learning a habit are more likely to reach their goals. Set time aside to learn and get reminders using your learning scheduler.




























	60. Multithreading explained 1
	------------------------------

PCB of Single Threaded Process P1
---------------------------------

		 -------------------
		|					|
		|					|	Heap Segment (DYNAMIC MEMORY)
		|					|
		|-------------------|
		|					|
		|					|	Stack Segment (STATIC MEMORY) (Stack Memory) (Stack Data Structure) 
		|					|
		|					|
		|___________________|
		|					|
		|  					|	Data Segment
		|  					|
		|___________________|
		|					|
		|					|	Code Segment
		|					|
		|___________________|
		

PCB of Multi Threaded Process P1
--------------------------------

|		  |			|			|	  <-
|		  |			|			|		|
|---------|---------|			|		|
|  Stack  |  Stack  |			|		PER THREAD ATTRIBUTES
|---------|---------|			|		|
|Registers|Registers|			|		|
|-------------------------------|<--  <-
|			  Heap				|	|
|-------------------------------|	|
|			  Data				|	ARE NOT PER THREAD ATTRIBUTES
|-------------------------------|	|
|			  Code				|	|
 ------------------------------- <--






Fine. Now, Lets see how a multithreaded process will work? Okay
See, this is what we mean by a multithreaded process. Okay, because it has more than one thread.
Anyway I'll explain you.


So let us take our
Server example. Okay, our server program.

	 ========================================================================================================
	||																										||
	||	SO, INITIALLY THE SERVER PROGRAM IS HAVING ONLY ONE THREAD. OKAY, WHICH MEANS IT IS A SINGLE		||
	||																										||
	||	THREADED PROCESS. SEE, ANY MULTITHREADED PROCESS WILL INITIALLY BE A SINGLE THREADED PROCESS.		||
	||																										||
	||	OKAY. AS PER REQUIREMENT THAN WE WILL INCREASE THE NUMBER OF THREADS.								||
	||																										||
	||	SO, INITIALLY IT IS A SINGLE THREADED PROCESS, THE SERVER PROGRAM AND LET US ASSUME THAT AS OF NOW	||
	||																										||
	 ========================================================================================================

it is in

listen mode.

Okay. What do you mean by listen mode?

It is expecting a client's request. Okay As of now no client has requested the server program.

Fine. Now, let us assume that a new client say, A is requesting the server. Okay

A new client say, A is requesting the server. Okay Now, what this will do in case of fork system call? 

	 ====================================================================================================================
	||																													||
	||	If we were using FORK SYSTEM CALL,																				||
	||																													||
	||	this process will create a new process.																			||
	||																													||
	||	Okay, this process will create a new process using FORK SYSTEM CALL and that new process will be servicing		||
	||																													||
	||	this client. Okay, but that will not happen over here because we												||
	||																													||
	||	are following MULTITHREADED PROCESS. Rather than creating a new process,										||
	||																													||
	||	we will be creating a NEW THREAD. Okay																			||
	||																													||
	||	We will be creating a NEW THREAD.																				||
	||																													||
	 ====================================================================================================================

So, Right now

you might not be able to understand these things exactly.

I will explain you better.

Okay

But try to understand these points whatever I'm saying now.

So, a new thread will be created. As of now, we have two threads.

Okay

	 ============================================================================================================
	||																											||
	||	WE HAVE TWO THREADS. NOW, WHAT WILL HAPPEN IS ONE OF THE THREADS WILL BE IN LISTEN MODE JUST LIKE THIS.	||
	||																											||
	||	AND THE SECOND THREAD WILL BE SERVICING THIS CLIENT. OKAY												||
	||																											||
	 ============================================================================================================

Now, let us assume a new client say B

is requesting the server program.

Again, what will happen?

A new thread will be created just like this.

Okay

A new thread will be created and this new thread will be servicing this client. Okay

Will be servicing this client.

Likewise, as per our requirement we will be increasing the number of threads. Okay

	 ============================================================================================================
	||																											||
	||	BUT ONE THING YOU NEED TO UNDERSTAND IS A THREAD WILL BE PERFORMING ONLY A SINGLE TASK. OKAY. IT WILL	||
	||																											||
	||	BE PERFORMING ONLY A SINGLE TASK.																		||
	||																											||
	 ============================================================================================================


Fine.

Now, what has happened here?

Here, I am saying that stack and registers will be maintained for every

thread. Okay, will be maintained separately for every thread.

Whereas, these attributes like heap, data segment and code segment will be shared

between all these threads. Okay

Now, what do I mean by shared between all of these threads?

Okay

These attributes are shared between all these threads.

See, initially we had only a single thread. Okay

and that SINGLE THREAD can access this HEAP MEMORY, STACK MEMORY, DATA SEGMENT as well as CODE SEGMENT.

Okay it can access anything.

Let us assume we have another process just like this.

Okay

	 ================================================================================================================
	||																												||
	||	LET US ASSUME THIS IS PROCESS P1.																			||
	||																												||
	||	LET US ASSUME WE HAVE ANOTHER PROCESS SAY PROCESS P2. NOW, CAN THIS PROCESS ACCESS THESE ATTRIBUTES			||
	||																												||
	||	OF THIS PROCESS?																							||
	||																												||
	||	IT WILL NOT BE ABLE TO DO IT. OKAY, IT WILL NOT BE ABLE TO DIRECTLY ACCESS THE ATTRIBUTES OF THIS PROCESS.	||
	||																												||
	||	AND THAT'S WHAT WE MEAN BY PROTECTION.																		||
	||																												||
	||	OKAY																										||
	||																												||
	||	THAT'S WHAT WE MEAN BY PROTECTION WHICH IS PROVIDED BY OUR OPERATING SYSTEM.								||
	||																												||
	 ================================================================================================================

	 ========================================================================================================================
	||																														||
	||	NOW, WHAT I MEAN TO SAY IS THESE ATTRIBUTES OF THE PROCESS ARE PER PROCESS ATTRIBUTES. OKAY, THESE ATTRIBUTES ARE	||
	||																														||
	||	PER PROCESS ATTRIBUTE OR PER PROCESS PROPERTIES WHICH MEANS THESE ATTRIBUTES										||
	||																														||
	||	CANNOT BE ACCESSED BY ANY OTHER PROCESS. THEY CAN BE ACCESSED ONLY WITHIN THIS PROCESS. 							||
	||																														||
	 ========================================================================================================================

Okay. Now,

What about these attributes?

Initially this thread will not be present. Okay

Initially our server program is in Listen mode.

Let us assume no client has requested the server. In that case, we will be having only the single thread. Okay,

only the single thread and these sections will be present.

See these attributes are also per process attributes.

Okay

Because these attributes cannot be accessed by any other process.

Okay

Now, let us assume a new client has requested the server and because of it we have created this

new thread.

Okay, this new thread.

Now, since I have told that these attributes will be shared between all the threads within the process.

THESE THREE ATTRIBUTES (HEAP, DATA, CODE) ARE NOT PER THREAD ATTRIBUTES.

Okay

They are not per thread attributes which means there is no rule like these attributes can

be access by only one thread. Any thread can access these attributes. Okay

Now, Why

am I sharing these attributes? Okay See, one thing is that we will be

having more attributes here. Okay I'm showing only few attributes over here

But we might have a lot of attributes for example, files opened by this process.

I can have an attribute something like this.

I can have something like signals required to run this process.

Okay I can have a lot of attributes like this but I'm showing only the important ones.

But anyway you should be understanding that except stack and registers all the attributes will be shared

between threads of a process.

 ================================================================================================================
||																												||
||	OKAY EXCEPT STACK AND REGISTERS ALL THE ATTRIBUTES WILL BE SHARED BETWEEN THE VARIOUS THREADS OF A PROCESS.	||
||																												||
 ================================================================================================================

A process can have any number of threads. Okay, the minimum number of threads a process

should have is one but the maximum number of threads really depends on our requirement.

Right.

Since here we need only 3 threads so we have created only 3 threads if we want more threads we will obviously

be able to create it. Right !

Fine.

Now, let me tell you Why these attributes are shared.

Okay, Why these attributes are shared? What do you mean by shared?

Any thread can access them.

Okay.

That's what I mean by shared attributes. See, the code segment has to be a shared attribute.

Why?



BECAUSE YOU KNOW THAT ANY THREAD WILL BE MAKING USE OF THIS CODE IN ORDER TO

PERFORM ITS TASK.

RIGHT !

FOR EXAMPLE, THIS THREAD WILL BE EXECUTING THIS CODE IN A PARTICULAR SEQUENCE SO THAT THIS TASK OF LISTENING

WILL BE PERFORMED.

RIGHT !




The task of listening will be performed. Similarly,

This thread will be executing the same code but in a different sequence in order to service the client A

Okay, in order to service the client A.

Similarly, this thread will be executing this code in a different sequence or in a sequence so that

the client B can be serviced.

Okay, client B can be serviced.

So what I mean to say is all these three threads need to definitely access this code. Right !

So that's the reason we're making this attribute as a shared attribute.





OKAY, SO THE DIFFERENCE BETWEEN PROCESS AND THREADS IS WE WILL BE MAINTAINING CODE FOR EVERY THREAD

RIGHT!

IF WE ARE HAVING A SINGLE THREADED PROCESS AND SO FOR EVERY TASK I WILL BE MAINTAINING A

CODE SEGMENT.

RIGHT!

BUT HERE (FOR THREAD) I AM NOT MAINTAINING A CODE SEGMENT FOR EVERY TASK FOR ALL THE TASKS WITHIN A PROCESS I'M HAVING

ONLY ONE CODE

SEGMENT.

OKAY, I'M HAVING ONLY ONE CODE SEGMENT.

	 ================================================================================================================
	||																												||
	||	ADVANTAGES OF MULTITHREADING OVER FORK()																	||
	||		1.	MULTITHREADING SAVES MEMORY AS WE ARE HAVING ONLY 1 CODE SEGMENT FOR ALL THE TASKS.					||
	||		BUT IN FORK() WE WILL HAVING 1 CODE SEGMENT FOR EVERY SINGLE TASK (BECAUSE WE ARE CREATING 1 SINGLE		||
	||		THREADED PROCESS FOR EVERY TASK AND EVERY SINGLE THREADED PROCESS WILL HAVE A CODE SEGMENT)				||
	||																												||
	 ================================================================================================================


So because of this what advantage we're going to get we are going to save a lot of memory.

Okay, because I'm not maintaining multiple code segments for every task.

Fine, this is fine Now, Why am I sharing

the data segment?

Okay. See, what do I mean by data segment?

We will be having something like static variables, another thing is global variables

Right!

Another thing is global variables.

If you see global variables these variables has to be accessed throughout the program.

Right!

They can be accessed anywhere within the program. See, let us assume that

we have exactly three functions.

Okay.

let us assume we have a function something like main.

Fine.

We have a function something like F1. Fine! And we have a function something like F2. Right!

we have a function something like F2.

Now, let us assume that

Let us assume that we are having a global variable something like int a. Okay, see always remember that

if global variables are not initialized any value they will be automatically initialized to a value

zero.

Okay. See, though I have declared the variable, I have not initialized

any value. Right!

In case if I don't do that, it will be taking a value of 0 for this variable automatically.

Okay. This is the default value for a global variable. Anyway, let's see that in C programming.

Don't worry about it.

So what I meant to say is here we have exactly three functions. Right!

Let us assume that this thread needs to execute the main function and then function F1. Right!

See, any C program will start executing from the main function.

So,

Okay.

So, let us assume both the threads are starting execution from the main function.

Fine.

Now, let us assume that here we have something like if else.

Okay, here we have something like

if else. Fine, and in if class I'm calling the function F1 and in else class

I'm calling the function F2.

Okay. I'm calling the function F2. Now, this...

let us assume for this thread I'm actually executing

a main function and function F1.

Okay. And let us assume for this thread I'm executing main function and function F2. Okay, main function

and function F2.

So here what's happening is,

this thread is executing these two functions.

This thread is executing these two functions

and this variable, this global variable can be accessed anywhere within the program.

Right!

For example, I can print the variable A over here or I can even update the value

value of A.

Okay.

I can update the value of A. Also, I will be able to update the value of A over

here.

Right!

So what I

What I want to tell you is this thread as well as this thread needs to access the

might want to access the variable. Right! global variable.

So we need to definitely make it as a shared attribute. Okay because it can be accessed by any thread

within a program.

Right!



SO WE NEED TO MAKE SURE THAT IT IS SHARED ATTRIBUTE. SEE IN CASE IF I MAKE IT AS A PER THREAD ATTRIBUTE ONLY ONE

THREAD WILL BE ABLE TO ACCESS THE STATIC AND GLOBAL VARIABLES. RIGHT!

SO, THAT'S THE REASON I'M MAKING IT AS A SHARED VARIABLE.



See, even if you take static variables I don't know I think you are aware of static variables. See,

coming to static variables,

We need to remember the value of the variable throughout the execution of the complete program. Right!

throughout the execution of the complete program.

So because of this we might want to remember the value of static

variable at any given time.

And also we might access the static variable anywhere within the program.

Okay.

I don't want to get into static variable, Exactly.

Or I'll make a separate video for this but understand that for static

and global variables we're making it as a shared attribute because it can be accessed by any thread

within the program.

Right, any thread within the program.

Fine.

Now, what about the heap section?

This is very easy to understand. Right!





See, there is a difference between STACK MEMORY and HEAP MEMORY.
===============================================================

Okay let me explain you.

There is a big difference between stack memory and heap memory. Let us assume this is the total memory.

Okay

This is the total memory.

And let us assume this space is allocated to the stack memory and this space is allocated to the heap

memory.

Okay

Heap memory.

Now, how data will be stored inside the stack memory?

For example, for process P1 some amount of space will be allocated for the stack memory.

Right! Now, process P1 cannot access any other space it cannot increase the size of stack

Stack section. Right! It will not be able to do that but coming to heap memory we will not be doing anything

like this.

For example, if I want to allocate some space heap

Let us assume it is starting from address thousand I'm placing a node. Okay

Let us assume I'm placing a node at three thousand. Okay

Now both these let us assume both the nodes are.

Let us assume both the nodes are connected.

Okay, let us assume this data structure is present for this thread.

Okay, this data structure is present for this thread.

Similarly, I can maintain a data structure for this thread something like it is present in address thousand and five.

Okay, it is present in address thousand and five. It is present in address two thousand nine hundred.

Let us assume both of them are connected.

Okay, both of them are connected.

So what I mean to say here is here we are making it very clear for stack memory that in case if I allocate



IF I HAVE ALLOCATED SOME AMOUNT OF SPACE FOR A PARTICULAR TASK FOR A STACK MEMORY.

IF I HAVE ALLOCATED IT THEN THAT CANNOT BE USED BY ANY OTHER THREAD OR ANY OTHER TASK. OKAY, IT

WILL NOT BE ABLE TO DO IT. NOW, WHY STACK MEMORY IS A PER THREAD ATTRIBUTE?



We will see that.

Okay.

Don't worry about it. But coming to heap memory,

there is nothing like that.

Okay.

The entire heap memory can be used by any task as we want. Okay, as we want

we will be able to do it. Now generally we will be storing the data inside the heap memory.

Okay, the data which we are working with.



	 ====================================================================================================================
	||																													||
	||	LET US ASSUME THE SERVER PROGRAM.																				||
	||																													||
	||	OKAY. IF YOU TAKE THE SERVER PROGRAM																			||
	||																													||
	||	OBVIOUSLY IT WILL BE FETCHING THE WEB PAGES RIGHT FROM THE HARD DISK											||
	||																													||
	||	NOW, WHERE THE WEB PAGE WILL BE PLACED IN THE RAM?																||
	||																													||
	||	IT WILL BE DEFINITELY PLACED IN THE HEAP MEMORY.																||
	||																													||
	||	OKAY, IT WILL BE DEFINITELY PLACED IN THE HEAP MEMORY.															||
	||																													||
	||	SIMILARLY, IF YOU TAKE MICROSOFT WORD. LET US ASSUME THIS PROCESS IS MICROSOFT WORD.							||
	||																													||
	||	NOW, THERE ARE DOCUMENTS WHICH WE TYPE WHICH HAS TO BE INITIALLY PLACED IN THE RAM. RIGHT! SEE, IF YOU WANT TO	||
	||																													||
	||	PROCESS THE DATA WE NEED TO DEFINITELY PLACE IT INSIDE THE RAM ONLY AFTER THAT WE MIGHT WANT TO					||
	||																													||
	||	MOVE TO THE HARD DISK.																							||
	||																													||
	||	RIGHT! NOW WHILE I WANT TO PLACE THE DATA IN THE RAM, WHERE WILL I PLACE?										||
	||																													||
	||	I WILL DEFINITELY PLACE INSIDE THE HEAP MEMORY IN SOME DATA STRUCTURE.											||
	||																													||
	||	IT CAN BE LINKED LIST OR TREE OR GRAPH OR WHATEVER.																||
	||																													||
	||	OKAY, IT WILL BE PLACED IN SOME DATA STRUCTURE.																	||
	||																													||
	||	SO, ONE THING IS THAT THIS DATA HAS MIGHT WANT TO BE ACCESSED BY MORE THAN ONE THREAD.							||
	||																													||
	||	OKAY.																											||
	||																													||
	 ====================================================================================================================





They might want to be accessed by more than one thread. See,

Let me give you an example for a server program

Now, what's happening is let us assume...

Let us assume this thread is in listen mode.

Okay, and let us assume this thread is servicing client A. Okay, let us assume we have only one client

as of now and let us assume client B is requesting a new webpage. Okay

It is requesting for a new web page.

Let us assume that the webpage which B is requesting for is exactly same as that of A.

Okay. It is definitely possible, right ! Two people can access the same webpage.

Two people can ask for a same page to the server.

Right!

This is obviously possible.

Now, what will we do for this thread?

Okay, what will we do?








One thing is that this thread should have already fetched the web page from the database out from the hard

disk. Right! and it should have definitely placed in the RAM.

And it should have been sending it to the client. Right!

It should have been sending it to the client.

Now, do I want

this thread also to again go to the hard disk and

get the webpage?

It is unnecessary. Right! Because this webpage has been already fixed by this thread.

Now, what I will be doing is that

See, one thing is that the webpage which was fetched by this thread will be maintained inside the heap

memory in some data structure. Right!

Now, what I will do is I will make this thread to access that webpage inside the heap memory

so that even this thread will also be able to service the client without accessing the database. Right!

Without accessing the database.

Now, how that will be implemented? It is very simple.

Let us assume, in heap memory I have maintained a linked list of data. Okay, I have maintained a linked

list of data.

Now, how this thread will be accessing this data? By using a pointer which will be maintained in stack

section. Right!

We have already seen that. That's the way we will be able to access the data inside the heap memory. Right!

So, the pointer will be placed in the stack section and that pointer will be pointing to this

node. Right! Will be pointing to this node.

See,

What do I mean by pointing to this

node? The starting address of this will be present inside the stack memory. Right! Now, in case if I want to make this

new thread to access the structure of this data what should

I do?

It is very simple. In the stack section I will be maintaining a pointer and that pointer will be pointing

to this node.

Right! will be pointing to this node. So I can create as many threads I want.

And in case if necessary I can make all of them to point to the same structure, right! by having a pointer

inside the stack section.

So one thing I want to tell you here is this heap section should also be shared between multiple

threads of a process. Okay

Might want to be, so that's the reason we are maintaining it as a shared attribute. Right! that's the reason

we are maintaining it

as a shared attribute. 





 ==============================================================================================================================
||																																||
||	||	SEE, IF YOU WANT YOU CAN EVEN TAKE MICROSOFT WORD EXAMPLE RATHER THAN													||
||	||==========================================================================================================================||
||	||	THE SERVER EXAMPLE. LET'S TAKE THE MICROSOFT WORD EXAMPLE. RIGHT! LET US ASSUME THIS PROGRAM							||
||	||	IS MICROSOFT WORD. NOW, MICROSOFT WORD WHICH YOU'RE USING TODAY IN YOUR COMPUTER WILL BE CREATING MULTIPLE				||
||	||	THREADS AT ANY GIVEN TIME.																								||		
||	||	OKAY, THOUGH YOU ARE USING THE MICROSOFT WORD AS A SINGLE SOFTWARE, YOU HAVE CLICKED THE								||
||	||	SINGLE ICON MULTIPLE THREADS WILL BE CREATED INSIDE YOUR COMPUTER IN ORDER TO PERFORM THE TASK WHICH					||
||	||	YOU ARE DOING.																											||	
||	||	ONE SIMPLE EXAMPLE I CAN GIVE YOU IS LET US ASSUME YOU HAVE OPENED MICROSOFT WORD AND YOU HAVE TYPED SOME LETTERS.		||
||	||	OKAY, YOU'VE TYPED SOME TEXT. NOW, WHEN YOU ARE APPLYING FORMATTING FOR THAT TEXT A NEW THREAD WILL						||
||	||	BE CREATED.																												||
||	||	OKAY, JUST TO FULFILL THE TASK OF APPLYING FORMATTING TO THE TEXT A NEW THREAD WILL BE CREATED. OKAY					||
||	||	SIMILARLY, IN ORDER TO SAVE THE FILE WHICH YOU ARE CREATING A NEW THREAD WILL BE CREATED. RIGHT!						||
||	||	SIMILARLY, LET US ASSUME IT FOR AUTO CORRECTION. SEE, WHEN YOU TYPE IN MICROSOFT WORD THERE IS AN AUTO CORRECTION		||
||	||	FEATURE. RIGHT!																											||
||	||	IN CASE IF YOU LEAVE SOME ERRORS IT WILL AUTOMATICALLY POINT OUT. AGAIN FOR THAT A NEW THREAD							||
||	||	WILL BE CREATED. RIGHT!																									||
||	||	THAT IS HOW ANY SOFTWARE WHICH YOU WORK IN COMPUTER WILL WORK. IT WILL CREATE MULTIPLE THREADS WHERE					||
||	||	EVERY THREAD WILL BE PERFORMING A SINGLE TASK BY EXECUTING THIS CODE IN ITS OWN SEQUENCE. RIGHT! WHICH SEQUENCE?		||
||	||	THAT SEQUENCE REALLY DEPENDS ON WHICH TASK WE NEED TO PERFORM. RIGHT!													||
||	||	SO THAT'S THE REASON I'M TRYING TO... NOW, LETS TAKE THE MICROSOFT WORD EXAMPLE THE TEXT WHICH I'M TYPING				||
||	||	MIGHT WANT TO BE ACCESSED BY MULTIPLE THREADS. RIGHT!																	||
||	||	FOR EXAMPLE, IN ORDER TO APPLY FORMATTING TO THIS TEXT THIS THREAD NEED TO ACCESS THIS HEAP MEMORY						||
||	||	OR THE DATA INSIDE THE HEAP MEMORY. RIGHT! THE DATA WILL BE PRESENT IN SOME DATA STRUCTURE.								||
||	||	SIMILARLY, IN ORDER TO APPLY AUTOCORRECTION TO THIS TEXT DOCUMENT														||
||	||	AGAIN THIS THREAD NEEDS TO ACCESS THIS DATA. RIGHT! SO, THAT'S THE REASON WE ARE MAKING HEAP MEMORY						||
||	||	AS A SHARED ATTRIBUTE BECAUSE IT HAS TO BE ACCESSED BY MULTIPLE THREADS WITHIN A PROCESS.								||
||																																||
 ==============================================================================================================================




Right!

Fine.

So,

Aa

One thing you need to remember is except stack and registers all the attributes will be shared between

multiple threads within a process. Right!

Fine.

No let me tell you why stack memory and registers are per thread attributes and they are not shared

attributes. Right! They are per thread

attributes and not shared attributes.

I will explain you. Fine. Now, why I have explained these points? See here,

Let us assume this thread has created this data structure.

Okay, this thread has created this data structure.

Let us assume this thread has created this data structure. Right!

Now, in case if a new thread comes next

then what I can do is this thread can access either

this thread's data structure or this thread's data structure.

Okay, that's the reason I have taken this heap memory just to explain you. Okay

Which means heap memory will be maintained in general, okay which can be accessed anywhere within the program

which means it can be accessed by any thread within the program.






























	61. Multithreading explained 2
	------------------------------


PCB of Single Threaded Process P1
---------------------------------

		 -------------------
		|					|
		|					|	Heap Segment (DYNAMIC MEMORY)
		|					|
		|-------------------|
		|					|
		|					|	Stack Segment (STATIC MEMORY) (Stack Memory) (Stack Data Structure) 
		|					|
		|					|
		|___________________|
		|					|
		|  					|	Data Segment
		|  					|
		|___________________|
		|					|
		|					|	Code Segment
		|					|
		|___________________|
		

PCB of Multi Threaded Process P1
--------------------------------

|		  |			|			|	  <-
|		  |			|			|		|
|---------|---------|			|		|
|  Stack  |  Stack  |			|		PER THREAD ATTRIBUTES
|---------|---------|			|		|
|Registers|Registers|			|		|
|-------------------------------|<--  <-
|			  Heap				|	|
|-------------------------------|	|
|			  Data				|	ARE NOT PER THREAD ATTRIBUTES
|-------------------------------|	|
|			  Code				|	|
 ------------------------------- <--
 	
	
	main() -> f1 -> f2 -> f3	==>		Thread 1 sequence
	main() -> f2 -> f1 -> f3	==>		Thread 2 sequence
	
	
	
Now, why we cannot share stack memory and registers between threads of a process? Okay, between threads

of a process.

See, if you take stack for a particular thread what will happen?

It really depends on the sequence in which we execute this code. Right! the sequence in which we execute

the code.

See, let us assume this code has main function and also it has function something like F1

F2,

F3, okay. These are the four functions which are

present in this code.

Now, let us assume that for this thread, this thread follows a sequence something like main followed by

F1 followed by F2 followed by F3. Okay

This is the sequence in which this thread is executing this code in order to perform its task. Okay

Now, let us assume that this thread is following a sequence something like main followed

by F2 followed by F1 followed by F3. Okay

This is definitely possible. Right!

This is definitely possible.

	 ====================================================================================================================
	||																													||
	||	NOW, THE SEQUENCE IN WHICH WE EXECUTE THE PROGRAM CAN VARY DEPENDING ON THE THREAD WE ARE EXECUTING. RIGHT!		||
	||																													||
	||	DEPENDING ON THE THREAD WE ARE CONSIDERING. RIGHT!																||
	||																													||
	||	SO THAT'S THE REASON I'M SAYING THAT SEE, BECAUSE OF THIS EVEN THE CONTENTS OF STACK CAN VARY. RIGHT!			||
	||																													||
	 ====================================================================================================================

For example, if you take this thread, for this thread

In stack we will be having main first followed by F1 followed by F2 followed by F3.

Okay. This is the order in which we will be placing the activation records. Obviously within the activation records

We will be having the local variables declared within the function. Right!

That is fine, but this is the order in which we will be placing the activation records.

	 ============================================================================================================================
	||																															||
	||	WHEREAS, IF YOU TAKE THE STACK FOR THIS THREAD WHICH IS FOLLOWING THIS ORDER											||
	||																															||
	||	OF EXECUTING FUNCTIONS, HERE THE ORDER IN WHICH WE WILL BE PLACING THE ACTIVATION RECORDS WILL BE COMPLETELY DIFFERENT.	||
	||																															||
	||	RIGHT!																													||
	||																															||
	 ============================================================================================================================




Something like main followed

by F2 followed by F1 followed by F3. Okay

So, the way in which we are executing the program can vary

or the sequence in which we are executing the code can vary and depending on that the stack can vary.

Right! our stack can vary. Not only the sequence in which we are executing the functions, not only the activation



RECORDS, EVEN THE LOCAL VARIABLES VALUE CAN CHANGE. RIGHT!



See, I don't know whether you are able to understand why local variables value can change depending on

which thread is executing the code. Right!

I don't know whether you are able to understand it.

I think you will be able to understand it only if you are very comfortable with C programming language.

Okay. So anyway,

So let me give you a rough idea okay.

I don't want to leave it here.

Let us assume we have a function F1.

Right!

We have a function F1

Let us assume that we have given int a.

Okay.

And let us assume we are updating it something like a=a+1

Okay

Now, let us assume that we are having a main function. Fine, we are having a main function and let us assume that

that we are calling function F1

from the main. Okay, calling function F1 from main. Fine and let us assume this is the code.

Okay, this is the code we are having.

Now, tell me one point

Let us assume that both the threads are executing the main function followed by F1. Right!

Obviously if it starts executing main function it will be executing F1. Right! because for both the threads we

are calling a function F1. There is no condition here.

Fine.

Now, let us assume that... Now, what will happen is let us assume this thread is executing from main function.

See, any C program will start executing from main function.

Okay. Now, we're calling function F1. Fine Now because of this what will happen is, see I'm considering only

this thread.

Okay, let's see the stack..

Let's see the stack. Now what will happen is this function's activation record will be placed inside

okay, this function's activation record will be placed inside.

Now let us assume, see, let us assume the value which has been declared is 2. Okay, int a = 2

Now, what will happen

We will be placing a variable a= 2. Okay

Now let us assume that we are executing the next instruction because of which

what will happen this value of 2 will become 3.

Okay, this value of 2 will become 3.

Now let us assume that we have preempted this thread. Or

Let us assume our CPU is executing these threads concurrently.

Okay. Let us assume we have preempted this thread.

Now, how that will happen?

We will see that a bit later.

Okay.

Let us assume we have preempted this thread and we are scheduling this thread. Okay, our CPU is executing

this thread.

Now what will happen is... Let us assume we are starting execution

from main.

Fine.

Even for this thread.

Now, what will happen? An activation record

will be placed for function F1

Fine.

We will be placing a= 2. Right!

This is very very important.

Though, we have the value equal to 3 here.

Here we will be placing a= 2 because for this thread we will be starting execution from the beginning. Right!

It doesn't matter what this thread is doing. Right! It doesn't matter

These threads will actually execute independently.

Right! Now, you can clearly understand that the values of local variables can be different depending on

which thread is

executing. Right! so there is no point in sharing the stack in the stack section between threads of a

process.

Okay, I think you're getting the point.

Fine. Now, what about registers?

See, by registers I mean set of all registers, either you take CPU registers something like program counter,

accumulator, all these things. Okay you don't need to worry too much about it but I think you are

aware of program counter.

Okay



	 ====================================================================================================================
	||																													||
	||	IF YOU TAKE CPU REGISTERS LIKE PROGRAM COUNTER, ACCUMULATOR OR IF YOU TAKE GENERAL PURPOSE						||
	||																													||
	||	REGISTERS, WHAT DO YOU MEAN BY GENERAL PURPOSE REGISTERS? REGISTERS WHICH ARE USED MAINLY FOR CALCULATIONS.		||
	||																													||
	||	THAT'S WHAT WE MEAN BY GENERAL PURPOSE REGISTERS. 																||
	||																													||
	 ====================================================================================================================




Whether you take addition for example, if you want to

add two numbers

What will you do?

For example, let us assume we have two general purpose registers.

Now what we will do is, incase if we want to add two numbers we will place 2....

Let us assume the two numbers are 2 and 3.

Okay.

Now, we will place both the operands inside the register so that we will be able to add them using the

arithmetic and logic unit.

Okay.

We will be able to do that and then we will be able to store the result in one of the registers.

Okay. See, you don't need to worry too much about it. By general purpose registers

I mean registers which we will be using in order to perform arithmetic and logic operations. Right!

which means additions, subtractions all these things. In order to store the

operands we are using the registers.

Okay.




THESE REGISTERS WE CAN SAY IT AS GENERAL PURPOSE REGISTERS. NOW EITHER THE VALUES OF GENERAL PURPOSE

REGISTER OR CPU REGISTERS THAT CAN VARY DEPENDING ON WHICH THREAD IS EXECUTING OR DEPENDING ON THE

SEQUENCE IN WHICH WE ARE EXECUTING THE PROGRAM.





Right! See, even the stack section can vary depending on the order in which we are

executing the function. Right! executing the program. Depending on the sequence in which we are executing

the program.

Here, the sequence in which we are executing the program is different for both these things. Right!

That's the only reason the contents of stack can vary.

Also, the values of local variables can vary. 




RIGHT! THE SAME EXPLANATION EVEN HOLDS FOR REGISTERS. RIGHT! DEPENDING

ON THE SEQUENCE IN WHICH YOU EXECUTE THE CODE THE CONTENTS OF REGISTERS CAN DEFINITELY VARY. OKAY




One simple example I can give you is program counter. Right! program counter.

Now, let us assume both the threads are executing this code. Right! both are executing this code.

Now let us assume our scheduler has scheduled this thread

Okay

And what will happen, our program counter, let us assume it has executed till this line

Okay

It has executed this function and it has executed this line and it is about to

execute this line. Right! Now a program counter of this thread will be holding the address of this

instruction. Right! it will be holding the address of this instruction.

Let us assume that this thread has not yet started execution. Right!

In that case, the program counter of this thread will be holding the address of

this instruction. Okay, it will be holding the address of this instruction.

So from this, it is very clear that the values of registers can vary between threads.



===============================================================================================
OKAY, IT CAN DEFINITELY VARY BETWEEN THREADS EVEN THE VALUES IN WHICH WE ARE STORING IN GENERAL
PURPOSE REGISTERS CAN DEFINITELY VARY. RIGHT!
===============================================================================================

Let us assume that in if class, in the code we have, in if class we are performing addition.

Okay. Let us assume that, performing addition. Whereas, in else class we are performing subtraction.

Okay. We are performing subtraction.

Let us assume that for this thread we are executing the if class which means the condition getting satisfied

and we're executing this line.

Whereas, for this thread we are executing the else class. Right!

Now, I have told you that in order to perform addition I need to store the values of a and b over here

and c somewhere...





Let us assume we are placing another register in order to store the value of c.

Okay.

Now, depending on which instruction we are executing the value of this register can definitely

vary. Right!

So, depending on the thread we are executing the values of registers can definitely vary. Right!

Either general purpose register or CPU register something like program counter.

See, I think you are able to understand why program counter value can vary depending on

the sequence in which we are executing the program or depending on this scheduler.



	 ====================================================================================================
	||																									||
	||	RIGHT! CPU SCHEDULER. INCASE IF OUR CPU SCHEDULER SCHEDULES										||
	||																									||
	||	THIS THREAD FOR A LONG PERIOD OF TIME.															||
	||																									||
	||	OBVIOUSLY IT SHOULD HAVE EXECUTED MORE NUMBER OF INSTRUCTIONS.									||
	||																									||
	||	IN CASE IF OUR CPU SCHEDULER																||
	||																									||
	||	HAS NOT SCHEDULED THIS THREAD FOR A LONG PERIOD OF TIME											||
	||																									||
	||	THEN IT SHOULD HAVE EXECUTED ONLY FEW INSTRUCTIONS OF OUR PROGRAM.								||
	||																									||
	||	RIGHT!																							||
	||																									||
	||	IN THAT CASE, THE PROGRAM CONTENT VALUE CAN VARY BETWEEN BOTH THE THREADS. RIGHT! 				||
	||																									||
	 ====================================================================================================



So,

one thing I want to tell you here is stack and registers will not be shared between threads.

They will be maintained individually for every thread because these, either stack section or

registers,

the values of them can vary depending on the sequence in which we execute the program.

And you know that the sequence of executing the code will vary from one thread to another.

Right!

That's the reason we are maintaining stack and registers separately for every thread.

Right! I think you're getting the point.

Fine.




SEE, BECAUSE OF THIS THREAD WHAT ADVANTAGE YOU ARE GETTING? RATHER THAN USING PROCESSES, MULTI PROCESSES,

CREATING MULTIPLE PROCESSES USING FORK()  DEFINITELY


1.

	 ================================================================================================================
	||																												||
	||	IT IS GOING TO SAVE A LOT OF SPACE. WHY?																	||
	||																												||
	||	BECAUSE WE ARE MAINTAINING ONLY ONE CODE SEGMENT. RIGHT!													||
	||																												||
	||	WHEREAS, IN CASE IF WE USE FORK SYSTEM CALL AND CREATE MULTIPLE PROCESSES THEN WE WILL BE					||
	||																												||
	||	MAINTAINING A CODE SEGMENT FOR EVERY PROCESS OR IN ORDER TO PERFORM EVERY TASK. RIGHT! NOW, FOR ALL			||
	||																												||
	||	THESE TASKS																									||
	||																												||
	||	WE HAVE MAINTAIN ONLY ONE CODE SEGMENT SO BECAUSE OF THIS DEFINITELY WE ARE GETTING THE ADVANTAGE THAT		||
	||																												||
	||	WE'RE SAVING SOME MEMORY. RIGHT!																			||
	||																												||
	 ================================================================================================================



2.
	  ===========================================================================================================================
	||																															||
	||	FINE. ANOTHER ADVANTAGE IS THAT CONTEXT SWITCHING BETWEEN THREADS IS													||
	||																															||
	||	FAR MORE EASIER COMPARING TO CONTEXT SWITCHING BETWEEN PROCESSES. RIGHT!												||
	||																															||
	||	SEE, IN FORK SYSTEM CALL WE HAVE SEEN THAT WE WILL BE CREATING MULTIPLE PROCESSES. RIGHT!								||
	||																															||
	||	NOW IN ORDER TO PERFORM CONTEXT SWITCHING BETWEEN PROCESSES IT TAKES MORE TIME. RIGHT! WHEREAS, INCASE					||
	||																															||
	||	IF YOU TAKE...																											||
	||																															||
	||	LET US ASSUME WE ARE HAVING A LOT OF THREADS WITHIN A PROCESS															||
	||																															||
	||	LOT OF THREADS WITHIN A PROCESS THEN CONTEXT SWITCHING BETWEEN THEM TAKES VERY LESS TIME. OKAY							||
	||																															||
	||	ANYWAY WE WILL SEE THIS POINT WHEN WE'RE SEEING THE DIFFERENCE BETWEEN USER LEVEL THREAD AND KERNEL LEVEL THREAD.		||
	||																															||
	||	OKAY.																													||
	||																															||
	  ===========================================================================================================================


	 ============================================================================================================================
	||																															||
	||	DON'T NEED TO WORRY ABOUT THIS POINT. 																					||
	||																															||
	||	ONE POINT I WANT TO TELL YOU IS WE HAVE TWO ADVANTAGES BECAUSE OF USING THREAD.											||
	||																															||
	||	1.	ONE ADVANTAGE IS THAT WE ARE SAVING MEMORY WHICH IS VERY OBVIOUS FOR YOU.											||
	||																															||
	||	2.	THE SECOND ADVANTAGE IS THAT CONTEXT SWITCHING HAS BECOME MUCH MORE SIMPLER WHICH WE WILL SEE IT A BIT LATER. FINE	||
	||																															||
	 ============================================================================================================================





























	62. User Level Threads vs Kernel Level Threads
	----------------------------------------------



|		  |			|			|
|		  |			|			|
|---------|---------|			|
|  Stack  |  Stack  |			|
|---------|---------|			|
|Registers|Registers|			|
|-------------------------------|
|			 Data/Heap			|
|-------------------------------|
|			  Code				|
 -------------------------------
 
 
 1.	Creation
 2.	Context Switching
 3.	THERE IS NO FAIR SHARING OF TIME QUANTUM BETWEEN THE THREADS OF A PROCESS
 4.	If USER LEVEL PROCESS has 3 Threads; one Thread out of which need to perform I/O;
 	OS will completely block the USER LEVEL PROCESS, since OS dont know that USER LEVEL PROCESS has 3 Threads.
 	
 	If KERNEL LEVEL PROCESS has 3 Threads; one Thread out of which need to perform I/O;
 	OS will allow other 2 threads of KERNEL LEVEL PROCESS to continue, since OS know that KERNEL LEVEL PROCESS has 3 Threads.




FINE. NOW, LETS SEE THE DIFFERENCE BETWEEN USER LEVEL THREADS AND KERNEL LEVEL THREADS.

See, if you go for any interviews

There is a very high chance of getting a question on this.

Okay, it is very very important but actually it is very simple to understand.

Okay. If you have understood whatever I I have taught so far in threads understanding this video is very

easy.

Okay. So, please pay attention.

I will make it as simpler as possible.



SEE, BEFORE THAT EVERY PROCESS IS SINGLE THREADED BY DEFAULT. RIGHT!

IF YOU TAKE ANY PROCESS IT WILL HAVE AT LEAST ONE THREAD. RIGHT! AT LEAST ONE THREAD.



Initially we will be having only one thread and in case if there is any necessity we

will be adding more threads.

Right!

Fine.

Now,

Why I have written data segment

or heap segment?

Right!

	 ---------------------------------------------------------------------------------------------------------------------------
	|																															|
	|	IN THE PREVIOUS VIDEOS YOU SHOULD HAVE NOTED THAT I WAS WRITING DATA SEGMENT AND HEAP SEGMENT, BOTH OF THEM SEPARATELY.	|
	|																															|
	|	RIGHT! NOW I HAVE WRITTEN BOTH OF THEM TOGETHER.																		|
	|																															|
	|	WHY?																													|
	|																															|
	|	SEE IN SOME TEXTBOOKS THIS IS HOW IT HAS BEEN GIVEN.																	|
	|																															|
	|	THE REASON IS PRACTICALLY MOST OF THE TIMES WE WILL BE STORING STATIC AND GLOBAL VARIABLES INSIDE THE HEAP				|
	|																															|
	|	SECTION.																												|
	|																															|
	|	HEAP MEMORY, RIGHT! INSIDE THE HEAP MEMORY.																				|
	|																															|
	|	SO THAT'S THE REASON I HAVE WRITTEN IT THIS WAY.																		|
	|																															|
	|	OKAY																													|
	|																															|
	 ---------------------------------------------------------------------------------------------------------------------------

So heap memory not only contains the data structure like Linked List, stack ..etc or whatever........, whatever

data structure like linked list or arrays or whatever it will also have the static and global variables

practically.

Okay. So this is the reason in some textbooks it has been given like this. Okay

Whereas, in some textbooks they will write both the data segment and heap segments separately.

Okay. Though theoretically it is possible, practically we will be storing the static and global variables

inside the heap memory. Okay

So that's the reason I have written this way.

Fine.

Now, lets come to the topic.

Okay.

User level threads vs Kernel level threads. Initially we are having only one thread inside this

process.

Okay. Let me name this thread as t1. Now in case if a necessity happens

a new thread will be created and it will be having stack section, registers

all these things. Right!

So, now tell me one point who will create this thread?

Okay.




1.

	 ============================================================================================================================
	||																															||
	||	WHO WILL CREATE THIS THREAD? THERE COMES THE DIFFERENCE BETWEEN USER LEVEL THREADS AND KERNEL LEVEL THREADS. RIGHT!		||
	||																															||
	||	IN CASE IF YOU ARE FOLLOWING USER LEVEL THREADS, A THREAD WILL BE CREATED BY OUR										||
	||																															||
	||	USER PROCESS. OKAY, BY OUR USER PROCESS. 																				||
	||																															||
	||	WHAT DO I MEAN BY USER PROCESS? IT IS VERY SIMPLE.																		||
	||																															||
	||	THE CODE SEGMENT OF THIS PROCESS. OKAY, THE CODE SEGMENT OF THIS PROCESS. ALONG WITH THE CODE, ALONG WITH				||
	||																															||
	||	THE APPLICATION PROGRAM WE WILL ALSO BE HAVING A FUNCTION OR A SMALL FUNCTION WHICH WILL BE								||
	||																															||
	||	WHICH WILL BE RESPONSIBLE FOR CREATION OF NEW THREAD, IF NECESSARY. RIGHT! WHICH WILL BE CREATING THE THREAD.			||
	||																															||
	||	THAT'S THE REASON WE ARE SAYING THESE THREADS AS USER LEVEL THREADS BECAUSE THESE THREADS ARE CREATED					||
	||																															||
	||	BY OUR USER PROCESS. BECAUSE WE WILL BE INCLUDING SMALL LINES OF CODE INSIDE OUR PROCESS								||
	||																															||
	||	WHICH WILL BE RESPONSIBLE FOR THE CREATION OF THREAD. OKAY																||
	||																															||
	 ============================================================================================================================



2.
	 ====================================================================================================================
	||																													||
	||	NOW, WHAT WE WILL BE DOING IN CASE OF KERNEL LEVEL THREADS? RIGHT!												||
	||																													||
	||	IN KERNEL LEVEL THREADS																							||
	||																													||
	||	WE WILL NOT BE HAVING ANY FUNCTION WHICH WILL BE RESPONSIBLE FOR THE CREATION OF THREADS. RIGHT!				||
	||																													||
	||	OUR USER PROCESS WILL NOT CREATE THE THREAD.																	||
	||																													||
	||	RATHER OUR USER PROCESS WHICH MEANS THE CODE WHICH IS PRESENT INSIDE OUR PROCESS WILL JUST MAKE					||
	||																													||
	||	A SYSTEM CALL. OKAY, WILL JUST MAKE A SYSTEM CALL. AND NOW WHAT WILL HAPPEN IN CASE IF WE MAKE A SYSTEM			||
	||																													||
	||	CALL?																											||
	||																													||
	||	IT IS VERY SIMPLE.																								||
	||																													||
	||	MODE SWITCHING WILL HAPPEN WHICH MEANS WE WILL MOVE FROM USER MODE TO KERNEL MODE. NOW, IN THE					||
	||																													||
	||	KERNEL MODE OUR KERNEL PROGRAM WILL BE EXECUTED BECAUSE OF WHICH THE NEW THREAD WILL BE CREATED. OKAY BECAUSE	||
	||																													||
	||	OF WHICH THE NEW THREAD WILL BE CREATED.																		||
	||																													||
	||	SINCE THE THREADS ARE CREATED BY THE KERNEL WE SAY IT AS KERNEL LEVEL THREADS. OKAY, WE SAY IT AS				||
	||																													||
	||	KERNEL LEVEL THREADS.																							||
	||																													||
	 ====================================================================================================================






THE FIRST DIFFERENCE BETWEEN USER LEVEL THREADS AND KERNEL LEVEL THREADS LIES IN THE CREATION OF THREAD. OKAY



It really depends on who creates the thread. 
===========================================

1.

	 ===========================================================
	||															||
	||	In case if the user process itself creates the thread	||
	||															||
	||	we say it as user level threads. 						||
	||															||
	 ============================================================

2.
	 ========================================================================================================
	||																										||
	||	Whereas, incase if the user process just makes a system call										||
	||																										||
	||	which means it invokes operating system and if operating systems program runs and in case because	||
	||																										||
	||	if because of that the thread is created then we can say such a thread as kernel level thread.		||
	||																										||
	||	Okay, kernel level thread.																			||
	||																										||
	 ========================================================================================================



So a process can either follow user level threads or it can follow kernel level threads. Okay

Fine.




 ====================================================================
||																	||
||	1.	So, the first difference is based on creation.				||
||																	||
||	2.	The second difference is based on context switching. Okay	||
||																	||
 ====================================================================




See one more point before this, in creation

which is better whether user level threads or kernel level threads. 
===================================================================


1.
	 ============================================================================================================================
	||																															||
	||	see coming to creation of a new																							||
	||																															||
	||	thread using our user process which we do in user level threads, the time taken for creation will						||
	||																															||
	||	be very very less. Right! the time taken will be very less because we are not calling the operating system				||
	||																															||
	||	Right!																													||
	||																															||
	||	Also there is no need for mode switching, right! From user mode to kernel mode.											||
	||																															||
	||	There is absolutely no necessity for it. Right!																			||
	||																															||
	||	And so creation of user level threads are very easy and it takes very less time comparing to creation					||
	||																															||
	||	of thread by our kernel. Right! creation of our thread by our kernel.													||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||	See the reason is very simple. Right!																					||
	||																															||
	||	In our code																												||
	||																															||
	||	we will be having the logic for the creation of thread.																	||
	||																															||
	||	Now, in case if I am executing that simple code and if the new thread is created it will take very less					||
	||																															||
	||	time because it doesn't need any mode switching.																		||
	||																															||
	||	Also, our operating system doesn't need to execute it. Right!															||
	||																															||
	||	Whereas, in case if I am making a system call then firstly mode switching has to happen from user mode to				||
	||																															||
	||	kernel mode and then our operating system function needs to execute.													||
	||																															||
	||	And after that again mode switching has to happen from kernel mode to user mode. Right!									||
	||																															||
	||	So it is going to take more time so I can tell you that creation of user level threads are far more						||
	||																															||
	||	faster																													||
	||																															||
	||	comparing to creation of kernel level threads. Fine																		||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||	The second difference lies in something called as context switching. Right!												||
	||																															||
	||	See, let us assume that this process is having two threads. Right! This process is having two threads. Now,				||
	||																															||
	||	how.....? you can fill it out, right! stack and registers. Fine															||
	||																															||
	||	Now, how these threads will be executed? Right!																			||
	||																															||
	||	See, threads will be executed exactly like a process. Okay, exactly like a process which means this thread				||
	||																															||
	||	will be executed for some time by our CPU and then context switching will happen and because of							||
	||																															||
	||	which this thread will be executed for some time and then context switching will happen and some other					||
	||																															||
	||	thread will be executed. Right!																							||
	||																															||
	||	This is how our CPU will be executing the threads of a process. Right! exactly like how we execute a process.			||
	||																															||
	||	Fine.																													||
	||																															||
	||	This is fine.																											||
	||																															||
	 ============================================================================================================================









Now,

whenever I am moving from one thread to another

definitely context switching should happen. Right!

Context switching should happen.

Now,

how the context switching will happen?

Okay.






	 ================================================================================================================================
	||																																||
	||	how the context switching will happen? In case if we are following user level threads,										||
	||																																||
	||	See who will perform context switching? Context switching will be performed by our scheduler. Right! scheduler function.	||
	||																																||
	||	We have been seeing this point for a long time.																				||
	||																																||
	||	I think you should be clear about it right now.																				||
	||																																||
	||	So context switching will be performed by the scheduler. Generally we will be having the scheduler function					||
	||																																||
	||	inside our operating system. Right! inside our operating system.															||
	||																																||
	 ================================================================================================================================


Now,

========================================
1.		<==>	USER LEVEL THREADS	<==>
========================================

	 ================================================================================================================
	||																												||
	||	In case of a USER LEVEL THREADS we will not be using the scheduler function inside the operating system.	||
	||																												||
	||	We will never do that. Right!																				||
	||																												||
	||	Obviously... see I will explain you that point a bit later but understand that in case if I want			||
	||																												||
	||	to switch from one thread to another there will be a small function											||
	||																												||
	||	there be a small scheduler function which will be implemented by our application developer					||
	||																												||
	||	or by a user which will be actually performing context switching between									||
	||																												||
	||	threads. Okay, so if I want to switch from one thread to another											||
	||																												||
	||	I'm not going to call the operating system rather I will be having the logic inside my user code			||
	||																												||
	||	and because of the execution of the small function or the small scheduler inside our user code				||
	||																												||
	||	the context switching will happen.																			||
	||																												||
	||	Okay, context switching will happen.																		||
	||																												||
	||	This is how context switching will happen in user level threads. 											||
	||																												||
	 ================================================================================================================



Now,

============================================
2.		<==>	KERNEL LEVEL THREADS	<==>
============================================

	 ================================================================================================================
	||																												||
	||	how context switching will happen in kernel level threads?													||
	||																												||
	||	It is very simple.																							||
	||																												||
	||	Which means in case if I want to move from this thread to this thread, this thread will just				||
	||																												||
	||	make a																										||
	||																												||
	||	will just make a system call.																				||
	||																												||
	||	Okay, will just make a system call and the scheduler function inside the operating system will execute.		||
	||																												||
	||	And because of which context switching will happen.															||
	||																												||
	||	Right! context switching between threads will happen.														||
	||																												||
	||	See, one point I want to add here is I have told you that in user level threads context switching			||
	||																												||
	||	between threads will happen because of user process. Right!													||
	||																												||
	||<==> ---------------------------------------------------------------------------------------------------- <==>||																												||
	||																												||
	||	But anyway, context switching between processes will happen with the help of scheduler inside our operating	||
	||																												||
	||	system. Right! scheduler function in our operating system.													||
	||																												||
	 ================================================================================================================








See,

Let us assume that this is process P1.

Okay, this is process P1. Let us assume we have another two processes something like P2 and P3. Okay

Let us assume that the process P1 has two threads and let us assume

that they are following user level threads.

Okay user level threads. Now,

In case if we want to perform context switching between two threads I will be using the scheduler

function inside our user code.

THAT IS FINE, BUT IN CASE IF I WANT TO PERFORM CONTEXT SWITCHING BETWEEN THESE THREE PROCESSES THEN DEFINITELY

WE SHOULD BE USING OUR OPERATING SYSTEM OR WE SHOULD BE EXECUTING THE SCHEDULER FUNCTION INSIDE

OUR OPERATING SYSTEM.

Okay.

I think it is very clear right now.

Fine.




So the context switching is another big difference.



1.

 ============================================
||											||
||	First point is creation.				||
||											||
||	Who creates user level threads?			||
||											||
||	It will be created by our user program. ||	
||											||
 ============================================

2.

 ================================================================
||																||
||	Who creates kernel level threads? It will be created by the	||
||																||
||	kernel of our operating system.								||
||																||
 ================================================================



Now, 

1.

 ========================================================================================
||																						||
||	how context switching will happen between user level threads?						||
||																						||
||	It will again be implemented by a small function scheduler inside the user program.	||
||																						||
 ========================================================================================

2.

 ============================================================
||															||
||	Whereas, in case of kernel level threads				||
||															||
||	we will be invoking the									||
||															||
||	scheduler												||
||															||
||	scheduler function inside the operating system. Okay	||
||															||
||	In order to perform context switching. 					||
||															||
 ============================================================


AGAIN HERE ALSO CONTEXT SWITCHING WILL BE FAR MORE FASTER IN

CASE OF USER LEVEL THREADS COMPARING TO KERNEL LEVEL THREADS.

WHY?




1.
	 ============================================================================================================
	||																											||
	||	Because if I want to perform context switching in case of KERNEL LEVEL THREADS I need to call the		||
	||																											||
	||	operating system because of which mode switching has to happen which means user mode to kernel mode.	||
	||																											||
	||	So mode switching has to happen and also our operating system needs to execute.							||
	||																											||
	||	And after that mode switching will happen from kernel mode back to user mode.							||
	||																											||
	||	Okay.																									||
	||																											||
	||	It is going to take a lot of time 																		||
	||																											||
	 ============================================================================================================

2.

	 ================================================================================================================
	||																												||
	||	but coming to context switching in USER LEVEL THREADS nothing is necessary.									||
	||																												||
	||	Right! our operating system will not even know that we are performing context switching between threads.	||
	||																												||
	||	Okay.																										||
	||																												||
	 ================================================================================================================



SO CONTEXT SWITCHING AGAIN, CONTEXT SWITCHING IN USER LEVEL THREADS WILL TAKE VERY LESS TIME COMPARING

TO CONTEXT SWITCHING IN KERNEL LEVEL THREADS.

RIGHT!





Kernel level threads. See right now just focus on the difference between user level threads and kernel

level threads. Right!

THE DIFFERENCE BETWEEN THREADS AND PROCESSES WE WILL SEE IN THE NEXT VIDEO.

OKAY.

That is also a very important point. See, important point I want to add

here is

these user level threads....



1.
	 ================================================================================================================
	||																												||
	||	Let us assume here we are following USER LEVEL THREADS. Right! which means these threads are being created	||
	||																												||
	||	by our user program.																						||
	||																												||
	||	If this is the case our kernel or our operating system will not even know that how many threads this		||
	||																												||
	||	process has. Okay, our kernel will never know that. 														||
	||																												||
	 ================================================================================================================

2.
	 ================================================================================================================
	||																												||
	||	Whereas, in case if we are following																		||
	||																												||
	||	KERNEL LEVEL THREADS over here our operating system will definitely know how many threads this process has.	||
	||																												||
	||	Why?																										||
	||																												||
	||	Because those threads are being created by our operating system.											||
	||																												||
	||	Right.																										||
	||																												||
	||	So our operating system will definitely know how many threads this process actually has.					||
	||																												||
	||	Right!																										||
	||																												||
	 ================================================================================================================




	 ================================================================================================
	||																								||
	||	But coming to USER LEVEL THREADS these threads are created by our user program.				||
	||																								||
	||	And so our operating system will not know any details.										||
	||																								||
	||	Our operating system will just see that it is a single process.								||
	||																								||
	||	Right! it doesn't know how many threads this process actually has. okay						||
	||																								||
	||	See, because of this we are going to get some disadvantages in case of user level threads.	||
	||																								||
	||	Okay, we are going to get some disadvantages.												||
	||																								||
	||	See, these two points which we have seen are advantages of user level threads.				||
	||																								||
	 ================================================================================================



	disadvantages in case of KERNEL LEVEL THREAD
	============================================

	 ================================================================================================================
	||																												||
	||	Right! or																									||
	||																												||
	||	I can also say that these are the two DISADVANTAGES of kernel level threads which means for creation of		||
	||																												||
	||	threads it's going to take more time also, for context switching between threads							||
	||																												||
	||	It's going to take more time in case if we are following kernel level threads.								||
	||																												||
	 ================================================================================================================



<==>====================================================================<==>
<==>	Right! Now, let's see the advantages of kernel level threads 	<==>
<==>																	<==>
<==>	which are disadvantages of user level threads. Okay				<==>
<==>====================================================================<==>
	

So, the third point is, there is no fair sharing... please write down these points.

<==>================================================================================<==>
<==>	THERE IS NO FAIR SHARING OF TIME QUANTUM BETWEEN THE THREADS OF A PROCESS.	<==>
<==>================================================================================<==>

Okay, there is no fair sharing.

This is the disadvantage coming to

USER LEVEL THREADS.

Okay. This is the disadvantage coming to USER LEVEL THREADS.

So let me make it clear. Okay

See, here let us assume that here we are following USER LEVEL THREADS.

Okay, here we are following USER LEVEL THREADS which means these threads are created by our user

process.

Let us assume we are having exactly four threads. Okay


================================
<==>	USER LEVEL THREADS	<==>
================================


NOW, I HAVE ALREADY TOLD YOU THAT IN CASE THESE THREADS ARE CREATED BY OUR USER PROCESS THEN

OUR OPERATING SYSTEM WILL NOT KNOW ANY DETAILS ABOUT THESE THREADS. RIGHT!

OUR OPERATING SYSTEM WILL SIMPLY SEE IT AS A SINGLE PROCESS.

IT WILL NOT KNOW ANY DETAILS ABOUT IT.

OKAY.











Now let us assume that we have exactly two processes; one process say P1 another process say P2.

Let us assume P1 is having exactly four threads. Okay

Let us assume P2 is having only

two threads or

let us assume P1 is having ten threads

P1 is having ten threads.

Let us assume process P2 is having only one thread. Okay Now, since....

Let us assume in both the cases we are following user level threads.

Right! user level threads.

So our operating system will not know how many threads process P1 has.

Also it doesn't know how many threads process P2 has. Right! Now, let us assume that we are following time

sharing operating system something like a round robin scheduling algorithm. Right!




We have already seen round robin scheduling algorithm.

What we will do in the round robin?

We will decide on some TIME QUANTUM.

We will decide on some TIME QUANTUM. Let us assume it is 10 ns. Fine and every process will

be executed for 10 ns. Right!

Which means I will execute P1 for 10 ns I will preempt this process and execute

P2 for 10 ns and then I will execute P1 for a 10 ns

P2 for 10 ns

I will keep doing until these processes completes execution. Right!

That is how

round robin scheduling algorithm will work assuming that we have only two processes inside our

computer.

Okay.

That is our assumption.

Fine.

Now, since we have followed

we have followed user level threads for both the processes our operating system doesn't know how many

threads this process has and how many threads this process has.

Right!

So because of which it will be just giving 10 ns to every process. Right!

See, in case if I do 10 ns for ten threads it is a very less time comparing to giving

10 ns for one thread. Right!

So, effectively on average I'm going to get only 1 ns per thread.

Right! 1 ns per thread.

Whereas, for this process I'm getting 10 ns per thread. Right!

So, there is no fair sharing of time quantum between the threads. Right!

One thread is getting only 1 ns.

Whereas, one thread is getting 10 ns. Right!

This is the problem coming to user level threads. Right





====================================
<==>	KERNEL LEVEL THREADS	<==>
====================================

Whereas, in case if we are following KERNEL LEVEL THREADS we don't have such an issue. Right!

Because our operating system definitely knows how many threads this process has and how many threads this

process has. Right!

Let us assume both the processes are following KERNEL LEVEL THREADS. Right!

In that case our operating system definitely knows how many threads this process has and how many threads

this process has.

In that case our operating system will not be scheduling processes

Instead it will be scheduling threads. Right!

It will be scheduling threads.

Let us assume that our...

Let us assume that our....

We are following kernel level threads over here. Right!

In that case what'll happen is our operating system will execute 10 ns for the first thread

over here 10 ns for the second thread, 10 ns for the third thread, 10 ns

for the fourth thread and so on and then it will be giving 10 ns for this thread. Right!

And then again we will start executing all the threads of this process. Right!

This is how time quantum will be assigned for threads in case if you're following

kernel level threads. Right! because our operating system is very clear about the number of threads per process.

Right! in case if you are following

kernel level threds.

So, this is a BIG DISADVANTAGE OF FOLLOWING USER LEVEL THREADS. Right!

This is a big DISADVANTAGE OF FOLLOWING USER LEVEL THREADS.




	 ============================================================================================================================
	||																															||
	||	SO YOU CAN WRITE DOWN THIS POINT. RIGHT!																				||
	||																															||
	||		1.	THERE IS NO FAIR SHARING OF TIME QUANTUM BETWEEN THE THREADS IN CASE IF WE ARE FOLLOWING USER LEVEL THREADS. 	||
	||																															||
	||		2.	BUT WE DON'T HAVE SUCH AN ISSUE COMING TO KERNEL LEVEL THREADS.													||
	||																															||
	||	FINE.																													||
	||																															||
	 ============================================================================================================================





Now,

let's take the fourth.

point.

Let's take the fourth

point.

See,

Let us assume that we are following user level threads. Right! user level threads and we are having exactly 3

threads. Right!

Three threads Fine

Now, let us assume that see,

As you know every thread will be executing this code in some sequence. Right! this thread will be executing this code

in some sequence in order to perform its task.

This thread will be executing this code in some sequence in order to perform its task. Right! Fine.

Now, what can happen is

Let us assume that this thread needs to perform IO. Right! it needs to perform IO which means it has

it has completed some execution by our CPU and

now it needs to read some data from one of the

IO devices. Right!

It can be hard disk

or keyboard, monitor or whatever.

Okay.

It can be any IO device.

Fine.

It needs to perform

either reading or writing of data from some IO device. Right! now what this thread will do?

It is very simple.

It will make some system call to our operating system saying that I need to perform

IO, right!

I need to perform IO.

We have seen all these points in scheduling algorithm. Right!

So, what will happen is our operating system will definitely block the process. Right! or block

the thread. See, let us assume this process

this thread wants to perform IO. Right!

And in that case what will happen.

Our operating system will block this thread. Now, what you mean by block this thread? See, let's forget about threads

Okay.





Let us assume we have exactly three processes.

Okay let us assume we have exactly three processes.

Now, let us assume process P1 has requested for IO.

Okay. It has made a system call from the operating system saying that I need to perform IO.




IN THAT CASE, WHAT OUR OPERATING SYSTEMS WILL DO? IT WILL BLOCK THIS PROCESS. RIGHT! ONLY




these two processes will be considered by our scheduler.

Okay. That is what I mean by blocking a process. See, initially when before this process would make

system call for

IO, what we were doing is all the three processes are in ready queue.

Right!

Which means our scheduler will

consider all three processes before scheduling a process.

But in case if this process has requested IO our operating system will block this

process meaning that this process will not be considered for scheduling to the CPU until it completes

its IO. Okay see, why are we not considering in this process for execution?

The reason is simple.

It needs to perform IO only after that it can execute. Right!

Even if we give us some time to this process, some CPU time to this process it is a waste of time

because this process cannot continue the execution until it completes its IO. Okay

This is what we have seen so far.






Now, let's come back to this point.

Let us assume that this thread needs to perform IO. Okay

Every thread will be executing this code in some sequence.

Fine.



1.
================================
<==>	USER LEVEL THREAD	<==>
================================

	 ====================================================================================================================================
	||																																	||
	||	Now, let us assume this thread (USER LEVEL THREAD) while executing this code wants to read some data from some IO device.		||
	||																																	||
	||	Right!																															||
	||																																	||
	||	In that case this thread will be making a system call to our operating system saying that I need to								||
	||																																	||
	||	I need to perform IO. Okay, I need to perform IO. Now our operating system doesn't know how many								||
	||																																	||
	||	threads this process has. Right!																								||
	||																																	||
	||	It doesn't have any idea about it because these threads are created by our user process. Right!									||
	||																																	||
	||	So, what our operating system will do is our operating system will block this process.											||
	||																																	||
	||	Okay, our operating system will completely block this process. See,																||
	||																																	||
	||	because of the what problem we have?																							||
	||																																	||
	||	These two threads will not be able to execute. Right!																			||
	||																																	||
	||	Why?																															||
	||																																	||
	||	Because our operating system has blocked the complete process. Okay, all the threads will be blocked.							||
	||																																	||
	||	Now, even though this process needs to execute it will not be scheduled by the scheduler.										||
	||																																	||
	||	Why?																															||
	||																																	||
	||	Because our scheduler will not consider this process itself because this process has been blocked								||
	||																																	||
	||	by our operating system. Right!																									||
	||																																	||
	||	It has been blocked by our operating system. Why? because our operating system doesn't know how many threads					||
	||																																	||
	||	this process has, because they are created by our user process																	||
	||																																	||
	||	or user code. Okay																												||
	||																																	||
	||	User code.																														||
	||																																	||
	 ====================================================================================================================================




2.
================================
<==>	KERNEL LEVEL THREAD	<==>
================================
	
	 ============================================================================================================
	||																											||
	||	But we don't have such an issue coming to kernel level													||
	||																											||
	||	threads. Okay																							||
	||																											||
	||	coming to kernel level threads.																			||
	||																											||
	||	See, I have already told you that in case of kernel level threads our operating system					||
	||																											||
	||	will look these things as just threads.																	||
	||																											||
	||	Okay, will look these things as threads.																||
	||																											||
	||	It will not look at them as if they are processes which means in case if it wants to schedule some		||
	||																											||
	||	In case if it wants to schedule something. It will schedule a thread.									||
	||																											||
	||	Operating System, Right! It will schedule a thread in case if we are following kernel level threads. 	||
	||																											||
	 ============================================================================================================






1.
================================
<==>	USER LEVEL THREAD	<==>
================================
	 ====================================================================================================================
	||																													||
	||	Whereas, in case if																								||
	||																													||
	||	we are following user level threads it will just be scheduling a process.										||
	||																													||
	||	Okay.																											||
	||																													||
	||	And once it has scheduled some time.																			||
	||																													||
	||	Let us assume 10 ns to a particular process then our scheduling algorithm which will be implemented				||
	||																													||
	||	in our user program will be responsible for scheduling of threads within the process. Right!					||
	||																													||
	||	See, the idea is simple. Let us assume we are following user level threats over here. Right!					||
	||																													||
	||	In that case let us assume 10 ns has been assigned to this complete process. Right! now which					||
	||																													||
	||	thread should be using this 10 ns in what manner?																||
	||																													||
	||	Really depends on the code which is implemented here.															||
	||																													||
	||	Right! Our user process will be having a code, will have a small function which will say which thread among		||
	||																													||
	||	these threads should be using this time.																		||
	||																													||
	||	Okay. Let us assume first thread needs to use 2 ns																||
	||																													||
	||	Okay. Let																										||
	||																													||
	||	us assume this thread needs to use the next 2 ns.																||
	||																													||
	||	Likewise, these threads will be assigned some time. Right! and that will be implemented in our user program.	||
	||																													||
	||	If you are following user level threads. 																		||
	||																													||
	 ====================================================================================================================





2.
================================
<==>	KERNEL LEVEL THREAD	<==>
================================

	 ============================================================================================================================
	||																															||
	||	But coming to kernel level threads we don't have any such headache.														||
	||																															||
	||	No code will be present for all these things.																			||
	||																															||
	||	Either you take creation of thread or																					||
	||																															||
	||	you take context switching between threads or even if you take the scheduling of threads it will						||
	||																															||
	||	be performed by our operating system. Okay, it will be performed by our operating system which means our operating		||
	||																															||
	||	system will exclusively give some time for this particular thread.														||
	||																															||
	||	Okay.																													||
	||																															||
	||	During that time these threads will not be able to execute. Okay, once it is done										||
	||																															||
	||	our operating system will assign some time for this particular thread.													||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||																															||
	||	Okay. Let us assume that this thread while execution wants to perform													||
	||																															||
	||	IO.																														||
	||																															||
	||	Okay. So, it has made a system call our operating system saying that I need to perform IO. See							||
	||																															||
	||	let us assume we're following																							||
	||																															||
	||	kernel level threads over here.																							||
	||																															||
	||	Fine.																													||
	||																															||
	||	In that case, our operating system will know how many threads this process has and so it will only block				||
	||																															||
	||	this single thread. Right! it will only block this single thread.														||
	||																															||
	||	So, because of which these threads can definitely execute in case if they are given time.								||
	||																															||
	||	Okay.																													||
	||																															||
	||	See,																													||
	||																															||
	||	Which means these threads will definitely be considered by our scheduler												||
	||																															||
	||	while assigning TIME QUANTUM. Okay, only this thread will not be considered because only this thread is performing		||
	||																															||
	||	IO. Okay, it is performing IO. 																							||
	||																															||
	 ============================================================================================================================












I think you have got the difference between user level threads and kernel

level threads. Okay





















	63. Summary of Threads
	----------------------







Fine. Now, let me give you an overview of threads topic. 


SEE, ALWAYS A PROCESS WILL BE SINGLE THREADED, INITIALLY. OKAY


Now, as we keep on GETTING MORE TASKS for a PARTICULAR PROCESS we will be creating MORE THREADS.

Okay, where EVERY THREAD WILL BE PERFORMING EXACTLY A SINGLE TASK BY EXECUTING THIS CODE IN SOME SEQUENCE.


Okay, in some sequence.

Fine. Now who will create these threads.






That really depends on whether we are following USER LEVEL THREADS or KERNEL LEVEL THREADS.

1.	If you are following USER LEVEL THREADS these threads will be created by our USER PROGRAM. Right!

2.	Whereas, if we are following KERNEL LEVEL THREADS than these threads will be created by our KERNEL PROGRAM. 
	Right! KERNEL LEVEL THREADS, threads will be created by our KERNEL PROGRAM.

Fine.


================================
<==>	USER LEVEL THREAD	<==>
================================

Now,

1.	Since these threads are created by USER PROGRAM in case of USER LEVEL THREADS.
	
	-	Our operating system doesn't know any details about these threads.
	
		Okay.

	-	So, because of this our operating system will only be scheduling processes whereas it will not be scheduling

		threads. Right! it will not be scheduling threads, 


================================
<==>	KERNEL LEVEL THREAD	<==>
================================

2.	but coming to KERNEL LEVEL THREADS since our KERNEL has created these threads

	It will know exactly how many threads this process has.

	Right!

	So our scheduler will be scheduling threads in case of KERNEL LEVEL THREADS. It will not be scheduling process.

	Right!



See, I think you're getting the difference between SCHEDULING THREADS and SCHEDULING PROCESS.




See,

Let us assume that in our operating system code we are having scheduler.

Okay.

Now, in that scheduler function in case of kernel level threads we will be choosing a single thread

and it will be scheduling for the CPU.

Okay, it will be scheduling for the CPU.





But in case of user level threads it'll be just picking a single process.

Okay, it doesn't know any details about the threads.

Now within this process

How will we decide on which thread should be executing?



================================
<==>	USER LEVEL THREAD	<==>
================================

That really depends on the scheduler which is implemented inside our user code. 

1.
	Right! See, if we are following 

	USER LEVEL THREADS 

	we will be having scheduler function inside the USER CODE. 


================================
<==>	KERNEL LEVEL THREAD	<==>
================================

2.
	Whereas, if we are following

	KERNEL LEVEL THREADS

	We will not be having the scheduler function inside the USER CODE. Fine.




================================
<==>	USER LEVEL THREAD	<==>
================================

1.	So, creation of user level threads takes very less time comparing to kernel level threads because we

	don't need to call the operating system. 


================================
<==>	KERNEL LEVEL THREAD	<==>
================================

2.	Whereas, kernel level threads take more time because we need to

	make a system call and call the operating system.

	And so our operating system will be creating the threads. 


The same explanation even holds for context switching. Right!


================================
<==>	USER LEVEL THREAD	<==>
================================

1.	See, coming to user level threads our operating system doesn't know any details about these threads

	so context switching will be definitely performed by our user process.

	Which means we will be having scheduler function inside it which will perform the context switching 


================================
<==>	KERNEL LEVEL THREAD	<==>
================================	

2.	but	coming to kernel level threads...

	The context switching will be performed by our kernel. How? because of the system call made by a particular

	thread.

	Fine.



================================
<==>	KERNEL LEVEL THREAD	<==>
================================

1.

Now, the advantage of kernel level thread is that there is fair sharing of time quantum between the

threads of a process.

Right!

We can say in kernel level threads our operating system is scheduling a particular thread.

It is not scheduling a particular process.

So in case if we have, depending on the number of threads a process has

the time quantum will be allocated.

Okay, in kernel level threads 



================================
<==>	USER LEVEL THREAD	<==>
================================

2.

but that is not possible in user level threads.

Okay.

Which means in case if a process has least number of threads then those threads will be getting more time.

Whereas, in case if a process more number of threads

then every thread will be getting very less time. Okay

That's what will happen in case of

user level threads but that will not happen in kernel level threads.



================================
<==>	USER LEVEL THREAD	<==>
================================

1.

Now, another advantage is that in user level threads

In case if a thread has to be blocked, in case if a thread needs to be blocked because it needs to perform

I/O we will not be able to do that because our operating system doesn't know which thread is asking

for I/O. Okay, so it will just block this complete process.



So, because of this what's happening the level of concurrence is getting decreased. Right!



If a single thread is blocked

The complete process is blocked 


2.

================================
<==>	KERNEL LEVEL THREAD	<==>
================================

whereas in case of kernel level threads

That's not the case. Right!

Incase if a thread is asking for IO

Our operating system will only blocking that particular thread it can still schedule other

threads.

Okay, it can still schedule other threads. Please note down that point it is still scheduling the threads

it is not scheduling processes. Fine




















	Section 14: Bonus: How to proceed further
	=========================================

	64. Bonus : How to proceed further
	----------------------------------

My Other Udemy Special Coupon links

Operating Systems

OS Part 1

https://www.udemy.com/operating-systems-from-scratch-part1/?couponCode=DATABASE1BONUS

OS Part 2

https://www.udemy.com/operatingsystems/?couponCode=DATABASE1BONUS

OS Part 3

https://www.udemy.com/operating-systems-online-course/?couponCode=DBMSBONUS

OS Part 4

https://www.udemy.com/operating-systems-computer-science-course/?couponCode=DBMSBONUS

Database Part 1 :

https://www.udemy.com/course/database-management-systems/?couponCode=94C31E2CA1257033D01F

Database Part 2:

https://www.udemy.com/database-management-system-course/?couponCode=DATABASE1BONUS

Database Part 3 : SQL Interview Prep Course

https://www.udemy.com/course/sql-interview-preparation-course/?referralCode=7EAA8F45A7C6F9614CEC

Database Part 4 : Transactions

https://www.udemy.com/course/database-management-systems-transactions/?referralCode=B51634FEC5B364171387

Database Part 5 : Indexing, B Trees, B+ Trees

https://www.udemy.com/course/database-management-indexing-course-btree/?referralCode=51C169A3A5F4737E69D2


Computer Architecture and Organization Part 1

https://www.udemy.com/computer-architecture-computer-organization-course/?couponCode=OSBONUS

Computer Architecture Part 2 course

https://www.udemy.com/course/computer-architecture-organization-online-course/?referralCode=CD3DFFAC147CC8EB62EE

Theory of Computation

TOC Part 1

https://www.udemy.com/theory-of-computation-online-course/?couponCode=DBMS1BONUS	
















































=================================================================================
=	5.	Operating Systems Final Part (4): File Systems & Threads (10+ Hours)	=
=================================================================================


 ====================================
||	Section 12: Fork () system call	||
 ====================================


	53. Fork () system call explained
	---------------------------------

Fine. Now, let's see about fork
system call. Okay, fork system call. it is used by a process to create a copy of itself which means
the address space, the logical address space will be exactly same except process ID.
Now,
What do you mean by this is....
Let us assume that we have a process named as process P1. Right!
And you know that its process control block will be having heap, stack, code segment
data segment, set of files opened by this process, set of register, register values
this process has, all these things. Okay, it will have a lot of things.
That is fine.
Now, it will definitely have something called as program.
Right! it definitely has something called as program.
Now,
Let us assume there is in program
We have lot of lines of code.
Right! we have lot of lines of code out of which
let us assume there is something called as fork.
Okay, there is something called as fork.
Now, what it means is it is a system call.
Okay, it is a system call.
Now, what do we mean by system call? System call
is a function call which will be contacting the operating system.
Right!
It is a function call which is made on the operating system. Our operating system code, our operating system
kernel, let us assume I am taking the kernel and it will have a function called as fork.
Right! it will have a function called as fork and it will be having some lines of code. Right! it will be having some lines
of code.
Now, once I make the fork system call obviously I need to change the mode. Right! Right now I am in user mode.
In case if I am making a system call I will turn into kernel mode.
And this function of operating systems will execute in kernel mode. Right! it will execute in kernel mode. Now, because
of this execution
What will happen?
Because of the execution of this function what will happen? Right!
That's what we're going to see in this video.
Once I make a fork system call, this fork system call will create a copy of this process exactly. Right!
It will create a copy of this process which means in case if I am having process P1 then the same
process will be created in the RAM. Right! same process will be created in the RAM and it will also be having the
exact same thing.
For example, it will be having a heap segment. Right!
It will be exactly copied here.
It will be having a stack segment. it will be copied here.
Data segment which means the set of variables we have static variables, global variables.
All of them will be copied here.
Exactly same! In case if a= 3 here, here also a's value will become 3.
Okay.
And even the program which we have for this process will also be same, exactly same. Right!
See, I'm not showing all the things. I'm only showing you the code. Okay, program but understand
that the entire process control block will be exactly created over here. Right!
Except one thing that the process ID will be different between both the processes. Right! the process ID
will be different.
See, obviously process ID is a number, unique integer value which will be used to identify a process
uniquely.
Right!
So there is no point in having two processes with the same process ID. See, if you take a company
software company there will be an employee ID to uniquely identify an employee.
Right!
No two employees can have the same employee ID. The same happens here.
Process ID is used to uniquely identify a process so two processes cannot have the same process ID.
Okay.
So, let us assume that the process ID of this process is something like 1000 or 1003. Okay, let us
assume the process ID of this process is 5
Something like that.
Okay, only the process IDs will be different.
But apart from that all of them will be exactly same.
There is no difference.
Fine.
See, this is created. This process is called as parent process. Right! this process is called as parent
process. Whereas, this process which is created by the parent is what we mean by child process.
Right! child process.
I think the name is very logical. Okay, because this parent process has given birth to this child
child process. Fine
Now what will happen is.
Let me name this process as P2.
Okay.
Once the process has been created there it will not be any relation between both the processes.
Let us assume that in this process....
Once this process has been created with the fork system call I am changing the value of a variable something
like a= 5 to 6. Right! I am changing it.
If I do that this modification will not be reflected in this process.
No reflection will be done.
You can think of it like this is a separate program. This is a separate program. Okay
Once I have created, See, before creating this process once I make a fork system call it will be
exactly same.
Whatever I'm creating here will be exactly same as this process.
That's fine.
Now,
Both the processes are different processes.
Now, whatever I am doing it here will not be reflected here.
Also whatever modifications I make in this process.
It will not be reflected here.
See you know that.
This process will be having something called as program counter. Okay, program counter. Program counter
will always indicate the address of the next instruction
I need to execute. Right! address of the next instruction
I need to execute. See,
Let us assume that this fork system call is instruction number 1 not 3. Right! instruction number
1 not 3. Let us assume that, okay. This fork system call is instruction number 1 not 3 of
this process.
If this is instruction number 1 not 3 of this process obviously even this fork will be instruction
number 1 not 3 of this process.
Okay, because we are exactly copying it here. Fine
Now,
Once I create this process what this PC value will be? The PC value will be the address of next instruction.
Right!
Which means it will hold the address of instruction number 1 not 4. Right!
Why?
Because as of now we are executing instruction 1 not 3.
We have executed 1 not 3. Fine
Then next instruction I should be executing is 1 not 4.
So obviously a program counter will be having the address of instruction number 1 not 4.
Now, since when I'm creating this process I have exactly created the same process the address space will be same.
So, even this process will also be having the address of instruction number 1 not 4 in the program counter.
Okay, in the program counter instruction number 1 not 4. Always remember the point program counter
will not hold the address of current instruction. That is wrong.
Okay, it will not hold the address of current instruction. Program counter will always hold the address
of the next instruction to execute. This is instruction number 1 not 3. We are executing instruction
number 1 not 3.
Once we start executing instruction number 1 not 3 this program counter's address will change to address of instruction
number 1 not 4 because I need to execute instruction 1 not 4.
Okay. All these things we will see in computer architecture. Coming to program counter, don't need to worry
about it here and just try to understand the fork system call. Fine..... Now,
Since both these program counters are having the address of instruction number 1 not 4 both these
processes can start executing from instruction number 1 not 4. Okay, instruction number 1 not 4. Obviously
our CPU will be executing the instruction number which is present
which is pointed by the program counter. Okay Program counter is definitely pointing to instruction
number 1 not 4.
So, we need to definitely start executing from instruction number 1 not 4.
Both these processes will be executing from instruction number 1 not 4. Now one question I want to
ask you here is how both the processes will execute?
See, we are assuming that we have only one CPU. Okay, only one central processing unit. Now this
CPU can execute only one process at any given time. Okay
Now what will happen is both these processes will be executed concurrently from instruction number
1 not 4.
Okay, from instruction number 1 not 4.
What do you mean by concurrently?
Which means this process will be executed for some time and this process will be
scheduled and it will be executed for some time and then this process will be scheduled and it will be executed
for some time.
Okay.
In what order they will be executed, it really depends on scheduling
algorithm. Okay
We cannot predict it.
It really depends on how our scheduling algorithm has been developed.
Okay. Fine
So, understand that fork system call will create a copy of itself.
Fine.
And both these processes parent process and child process will start executing from the next instruction
of fork which created the child process.
Okay, this is the fork which created the child process.
Now after creating this process we will be executing from the next instruction of fork which created the
child process. Okay, we will be executing the next instruction of fork which created the child process. Fine
So, this is how fork system call
will work. Okay
I think you are not able to understand the system call exactly. What I will do is.....
I will take some problems. Okay, once I take the problems these concepts will become very clear
Okay.
But the important point you need to understand is we will start executing from the next instruction
of fork, not from the beginning. Okay
You might think that this process has been created just now.
So we need to start executing from the first line. That is wrong. Okay
We will start executing from the next line of fork.
Fine.
Now let's see
Why we study this fork system call?
Okay.
What is the purpose of it?
Okay.
We will see that. Fine, now let us assume we have
a server. Okay, we have a web
server. We have a web
server. Fine
And let us assume in this server, website facebook.com has been hosted. Okay
facebook.com has been hosted.
Fine.
Now
Millions of clients will be trying to access the server. Right! millions of clients will be trying to access
the server.
Now, one question I want to ask you is how many programs will we be installing in this server?
Okay, how many server programs?
See, there needs to run a server program something like Apache
In order to service the clients. Right! in case if am...... let us assume I have opened my mobile and
I am contacting the server. Okay
Now what should happen is once I ask for a web page this web server has to process my request.
Right! which means it needs to respond to my request.
Now, similarly there will be millions of clients who will be....
There will be millions of clients who will be trying to access the server at any given time. Okay
Now my question is how will the server be responding to all the clients? Okay
How it will happen?
For that, we can do it with the help of two things.
Okay
One thing is by using this fork system call. Another thing is by using threads.
Okay, we will see about threads a bit later but understand how it will happen with the help of fork
system call.
Okay.
The first point is the server program something like Apache software will be installed in this machine
Okay. Let me name this process as process P1. Okay, let me name this process as process
P1.
Now let us assume that at this point of time no client has requested to the server.
Okay. No client has requested to the server. In that case there will be exactly one copy of
our server program.
Right!
There will be exactly one copy of our server program.
Fine. Now, once..... Let us assume there is a person A who is contacting the
server.
Okay, who is contacting the server.
Now,
What
this program will do?
Okay.
What this server program will do?
See one thing is that this server program cannot directly service this client.
Why?
Because let us assume that when this server is servicing this client, some other client is trying to request.....
See, before this point
I want to add one point.
Okay.
Always remember that our server program will be in listen mode in case if it doesn't have any request.
Okay.
In case if it doesn't have any request. What do I mean by the listen mode?
Listen mode means that this program is waiting for some client.
It is just listening to the port.
Okay.
Just.........
Expecting the client.
That's what we mean by listen mode.
Okay.
Which means this process is expecting a client.
As of now there is no client.
Okay. Now, once this client makes a request what will happen is this process cannot directly service this
client.
It cannot do that.
Why?
Because in case if it does that..... See when this process is servicing this client some other process
can request the server. Right!
Now
During that time
this process will not be in listen mode. Okay
Always remember that our server program has to be in listen mode in order to respond to the
client. Okay, in case if it is not in
listen mode, it will not be able to listen to this client. Okay If it is not able to listen to this client
it will not be able to respond to this client.
Okay, but that should not happen.
A website should be able to respond to every client.
Okay.
Who is requesting him.
Fine.
So what we will do is it will not immediately service this client rather it will do something called
as fork system call.
Okay. It will do something called as fork system call.
Which means that a clone of this process will be created exactly like this.
Okay.
The process control block will be exactly like this.
Now what will happen is this process...
This process will be servicing the client.
Okay, this process will be servicing this client.
And this process will be in
listen mode.
Okay. It will be in listen mode which means that it will be waiting for the client.
Okay.
Know what will happen.... During this time when this
process is servicing this request, in case if a new client request from the
server
What will happen is this process will be creating another process using Fork system call.
And this process will be in listen mode and the child process which has been created just now by this
process will be servicing
this client. Okay, will be servicing this client.
Now, in case if immediately
one more client comes what will happen?
This process will again make a fork system call and a new process just like this will be created.
And that process will be servicing the client.
Whereas this process will be in
listen mode. Okay
This is how multiple processes are being created by our fork system call.
Okay. See, important point you need to understand here is all the programs are exactly same.
Okay, exactly same. Why all the programs can be exactly same here? Because here we are doing a repetitive
task.
Okay.
What is that repetitive task? In order to service the client, whether I service this client or this client or
this client.
The task is same.
Okay, what we should be doing? We should be listening to the client on which web page this client is requesting
for. Right!
Depending on that I need to fix the web page and give it to the client. Right!
That's what the function of this process.
Now the same task has to be done to millions of clients.
Okay, so what we will be doing is using fork system
call we will be creating the same process again and again and again so that it will be able to service
millions of clients.
Okay.
Why we are following fork system call here?
Because we are doing the same task again and again.
Which task? Just to service the client.
Okay. So this fork system call will be helpful when we are performing the same task again and again
and again in a repetitive fashion. Okay, during that time we can go for fork system call.
See this can also be done with the help of threads. Okay We will see that when we are seeing threads.
Fine.



	54. Problems on Fork ()
	-----------------------

Fine. Now, lets understand both these functions. Okay
Both these functions to understand how fork system call works. Initially
this function is making a fork system call. Okay, see let us assume this is a process, this is
a process. Okay
Both are different.
Fine.
Now because of this line
a new process will be created. Okay
See, I'm speaking about only this function. Okay, forget about this function.
Fine.
So, let us assume this is process P1. Fine
And since it has a fork system call because of this a new child process
will be created. Okay
A new child process will be created.
Now let me name this as instruction number 1.
This as instruction number 2.
Okay.
Now we have executed instruction number 1 for this program.
Fine.
And this program will have the exactly same code.
Fine, it will have the same code.
But one thing is that I will start executing from instruction number 2.
Okay.
Which means I will be executing from the next line of fork.
Okay.
Which created the child process for both the processes.
Now because of this what will happen is this process will be printing hi once.
Also this process will be printing hi once. Okay
Now which process will print hi first?
That really depends on the scheduling algorithm.
Okay.
In case our scheduling algorithm schedules this process first, it will
print hi first. Okay
Whereas, in case if our scheduling algorithm schedules
this process first then this process will be printing hi.
Okay. So the output of this function is
hi
hi
two times.
Fine.
Now what about this function?
What about this process?
Again there will be a parent process.
Let me name this as P1.
Fine.
Now initially it is having hi. Okay, print of hi.
Now because of this the parent process will be printing hi.
Fine.
The parent process will be printing hi.
So first line is executed.
What about the second line? Because of the second line a new process will be created.
Okay, a new process will be created. Fine
Now important point you need to understand is this child process will start executing from the
next line of fork.
Okay. Both parent and child will start executing from next line of fork.
So it will not be executing first line and second line. Okay, it will not be executing. Now, after second line we will start
executing.
But unfortunately we don't have any program after that. Okay
We can stop it.
What about here?
We have executed both the lines of program so we can stop it here.
Okay.
So the output of this program is single hi. Okay, single hi. See, here also we didn't execute this
line of code.
We started executing from the next line of code.
I think you're getting the point. Fine
Now, lets see what will happen to this process?
okay. As usual we have the parent process, Fine! and it will be having exactly three lines of code. Okay
First line, second line and third line. Fine Now because of the first line
A new process will be created by our operating system.
Okay, because this function will be executing in operating system because of this.....
this child process has been created. Fine.
And even this process will be having three lines of program. Okay, I have drawn it
very big.
Now this process will also be having three lines of code.
Fine, but here we will not be executing the first line because we......
This process has been created because of the first line.
Fine. Now we will be executing second line and third line of both the processes and which process
will execute first really depends on the scheduling algorithm.
Fine.
Now what about the second line?
Second line is also having fork
Okay.
So let me execute this process first.
Okay.
It really is arbitrary.
Fine.
So, first line
Second line,
Third line.
This process will also be having three lines.
Fine, but I will not be executing first line and second line for this process.
Why?
Because this process has been created by the second line.
And so we will start executing from the next line of fork which created it.
Which is third line. Right!
So both the lines will not be executing. Fine But we will be executing the third line of program.
Right! the third line of program will be printing
hi.
Okay.
will be printing hi.
Fine. Now, what will happen?
This is done we have executed all the lines.
Okay.
Now we need to execute all the lines of this process as well. Right! we have only executed two lines.
Fine.
So we will be executing the third line and third line will print a hi. Okay
Third line will print a hi. Fine
So this process is also done. Right! Now, what about this process?
We have executed only one line of this process. Right!
We need to execute the second line. Now because of the second line
a new process will be created.
Why?
Because it is fork.
Okay, it is fork. Fine.
So it will also be having three lines exactly. Fine! out of this
we will not be executing first line and second line because we need to start executing from the third line.
Fine.
And third line will print a hi. Okay, it will print a hi.
Fine.
Now, we have executed only two lines for this program.
We will be executing third line so because of this one more hi will be printed.
Okay
So the output of this program is four hi's. Okay See again....
The order in which these hi's are printed by the processors really depends on the scheduling algorithm.
Okay. I can either schedule this process or this process or this process.
That really depends on the scheduling algorithm.
Either way since all the processes have the same program all of them will be printing only
hi.
Okay. Fine



	55. Problem on Fork ()
	----------------------

Fine! Now, let's see this program.
So, we're having the parent process and it is having exactly four lines of program.
One, two, three, four.
Fine!
So, first line is a fork system call.
So, it will be definitely creating a child process.
Fine!
And it is also having exactly four lines of code. Fine! But we will not be executing the first line.
Fine!
Now, because of the second line,
new process will be created.
Fine!
Because it is also a fork system call.
And it will be having four lines of code. Out of which the first two lines will not be executed.
Okay? And the third line is also a fork system call.
Okay! So, because of this one more process will be created. See, all the processes needs to execute
four lines of code. Right?
Fine!
Now, what order they execute really depends on scheduling algorithm.
One two three four.
Fine!
We will not be executing the first three lines, because this process has been created by the third line.
Fine!
So, I will be
I will be executing the fourth line.
So, because of this a "Hi" will be printed, right?
"Hi" will be printed.
So, fine!
This process is completely done.
We have executed only three lines of this process.
So, we'll be executing the forth line, which will be printing a "Hi" Right?
See, here
we have executed only the two lines of program, okay!
So, we'll be executing the third line.
Third line is also a fork system call. So, a new process will be created. Okay?
And this also has four lines of program. Out of which we will not be executing the first three lines. Right?
Right? First three lines.
Fine!
So, we will be executing the fourth line because of which a "Hi" will be printed. Okay?
"Hi" will be printed. Fine!
So, this process is done, this process is done, and this process is done.
We didn't execute the fourth line of this program
or this process.
Right?
So, in case if we do that on more "Hi" will be printed, because the fourth line is printing "Hi"
Fine!
What about this?
We have executed only one line of the parent process. Right?
So, a second line will be creating a new child process. Fine?
It will also be having four lines of code, out of which we will not execute the first two lines.
Fine!
So, a third line will be creating a child process because it is a fork system call.
Fine! First three lines will not be executed. Fine? Because
of the forth line,
a
"Hi" will printed. Right?
"Hi"
will be printed. Fine! Now, what about the fourth line here.
We have executed only three line. Right?
So, we will be executing the fourth line. Fine! Fourth line is not a fork. Okay?
Fourth line is printing "Hi."
So, one more "Hi" will be printed because of this. Fine!
So, we have executed all the lines of this process.
We have also executed all the lines of this process, but we didn't complete the parent process and we
have the third line. Third line is also a fork system call.
So, your new process will be created and it will also be having exactly four lines of code.
We will not be executing the first three lines.
Fine! But we will be executing the fourth line because of which a "Hi" will be printed.
A "Hi" will be printed. Here,
we didn't execute the last line of the parent process, right?
Apart from that, we have executed all the processes.
Now, in case if we execute the forth line, "Hi" will be printed one more time.
Okay?
"Hi" will be printed one more time.
So, that's it. Right?
We have executed all the processes.
Now if you count the number of "Hi" we got, we have 1, 2, 3, 4, 5, 6, 7, 8.
Okay?
We have a total of eight "Hi."
Fine!
See, this is fine. One point I want to add here is, here we have three fork system calls.
Okay?
Here we have three fork system calls.
And so, we have a total of seven child processes, right? 1, 2, 3, 4, 5, 6,
7
We have a total of seven child processors. Whereas, in the previous video, we have already seen that in case
if we have two fork system calls, we will be getting a total of three child processes. Right?
Three child processes.
Similarly, if you take only one fork system call, then we will be getting exactly one child process. Right?
One child process.
Similarly, in case if we do four fork system calls, then we will be getting 15 child processes. Right?
And this pattern will keep going like this.
Right?
What I mean to say is, in case if you have
n
fork system calls overr here,
then we will be getting two power n minus 1 child processes. Right?
You can substitute any number you will get the answer.
For example for three fork system calls, we will be getting two power three minus one, which is seven child
processes. Right?
See, here we have added only the number of child processes.
Right?
If you add also the parent, then the number of processes we'll be getting will be one more.
We will be getting one more process, right?
In case if we add the parent, in that case it will become two power n.
We have a total of two power n processes in case if you have n fork system calls.
Okay/
Which means 15 plus 1 will become 16.
This is a total number of processes. If you want to count only the number of child processes, it is 2
power n minus 1. Right?
I think you're getting the point. Fine!



	56.	Disadvantages of using fork () for performing repetitive tasks
	------------------------------------------------------------------

Fine!
Now, let see the disadvantages of using fork system call.
Okay! see these disadvantages.
You will understand it better if we see threads.
Okay? If we see threads, but anyway I'm taking it right now.
I'm giving you a
overview.
Okay? Try to understand it.
See, here we have created multiple processes.
Multiple copies of the same process so that each one of them will be servicing a client. Right? For example,
Let us take our
server example.
This is how a single process will look like, right?
It will have heap memories, stack memory, data segment, where we will have the global variables, static variables.
Then, we will have code segment, where the real program or the
server program will be present.
Then, we will be having a set of registers which are open by a process that
we have set of files which are open by a process.
Lot of things, right?
But that's not important.
These four are the most important things.
What I mean to say is, here we are creating multiple copies of the same process.
And because of which we are achieving the task of
servicing multiple cracks at any given time.
Now, because of this the problem here is, I might want to go for context switching. What i will
do?
Let us assume I have created these many processes, right, by using fork system calls. In that case our CPU
will be executing all these processes concurrently, right? It will execute one process for some time,
Then, it will pre-emptive. It will perform context switching and then it will execute some other process.
It will perform some context switching and it will execute some other process, right?
Because of which, for every process switching, I need to do context switching, right?
And that time which we spent for context switching is an overhead and that has to be decreased. Right?
And we do that with the help of threads, which we will see later. But coming
to fork system call. If we use fork system call,
we cannot get rid of context switching. Right? See, here we are following the multi
programming. Right? Why am I saying that?
Because we have multiple processes and we are executing them with the help of a single CPU and we
will be switching processes.
Right? we will execute one process for some time, we will do context switching, and then we will execute another process
for some time like that. Right?
So, definitely we are following multiprogramming over here.
Now, you know that coming to multiprogramming, we will always come across context switching. Right?
Which is an overhead that is in case if we use threads,
We don't need to come across multi programming.
We can completely get rid of multi programming or
I will be coming across something called as multi threading.
The advantage with multi threading is,
there is no need for context switching. Right?
We will see that a bit later, but understand that here since we are having multiple processes, we need
to definitely do context switching for every process switching, right?
That is one of the disadvantages.
The second disadvantages is, there is a wastage of memory due to the maintenance of multiple copies of the
same process which means the same address space.
I have already told you, right?
If you take any two processes over here.
The address space will be exactly same. Right? Which means the code which we are
using to service that client will be exactly same. Right?
I am taking the server example which is satisfying the requests of multiple clients
at the same time by creating multiple processes.
Right? Now, all of them will be having the exactly the same code. Not only code,
most of them in this process control block will be exactly the same for all these processes. Right?
Now, why are you maintaining the same process again and again inside the RAM. Right? See, if you take
a RAM or random access memory, we are maintaining multiple copies of the same process let us assume P1.
Okay? We are maintaining multiple copies, and this process is servicing a client, this process is servicing a client.
Right? Because of which we are going to waste lot of memory because we are maintaining
the same copy of the process multiple times. Anyway,
while saying about threads, you will understand that how we can decrease the amount of memory over this
processes. Okay?
Which means, I will let you know a little bit later. See, one simple example
I can give you is,
the code for all these processes are same. Right?
So, I am having a code segment over here and the same code segment I am also maintaining it here.
The same code segment I am also maintaining it here like that, right?
But coming to threads, if we follow threads, we will maintain only one copy of the code segment for
all these things. Right? Which we will see that when we are seeing
about threads. See, these are disadvantages because of using fork system call.
If we use forksystem call, we will come across multiprogramming.
There is no other way because we have multiple processes and because of multiprogramming,
we are getting this a disadvantage,
which is context switching here. The second disadvantage is because the process control block is almost
same for all these processes.
Now, why are maintaining multiple copies of the same process control block?
Okay? that is another disadvantage. See, one point I want to add here is context switching can be eliminated
here because the process control block of all these processes are exactly same or almost same. Right?
They're almost same.
Which means if you take the code they will be exactly same for all these processes.
Similarly, if you take data, it will be almost same for all these processes, right?
Only some of them can vary a little bit.
Okay! We willsee that when we are seeing threads, but most of them will be almost same for all these processes
and only because of this we can git rid of context switching if we are following
threads. Right?
But in case if these processes are completely independent, then we cannot get
rid of context switching.
Let us assume whatever videos we have seen, we have seen lot of examples here, right? Let us assume
we have three processes named P1, P2, P3.
Now, all these processes are completely independent. Let us assume this is Microsoft Word, this is
MS Word, and let us assume this is Adobe Photoshop, let us assume this is some other
software something like Final Cut Pro.
Okay?
Now, all these software are completely independent.
Right? now, here we will execute this process for some time.
This process for some time and whenever they performing process switching,
I need to do context switching, right? Here
I cannot get rid of context switching because all these processes are completely independent. Right?
but the scenario here is completely different. Here
all these processes are independent of each other, right?
But here we are maintaining multiple copies of the same process.
Let us assume we have one copy of Apache Software.
Okay?
It is servicing one client.
Similarly, we have another copy of Apache Software, which is servicing another client. Client number
two. Let us assume another copy of Apache Software which is servicing another client,
which is client number three.
Okay? But here all these processes are almost same, right?
So, that's the reason I'm saying that here we can get rid of context switching because of using threads.
Anyway,
Here I cannot get rid of context switching.
Okay?
That's the difference.
Anyway, we'll see about this in detail when we are seeing about threads. Okay?
But understand, these two are the disadvantages of fork system call. 
